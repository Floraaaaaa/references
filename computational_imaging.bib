% Encoding: UTF-8

@Article{Monticone2015p793--821,
  author    = {Francesco Monticone and Andrea Al{\`{u}}},
  title     = {Leaky-Wave Theory, Techniques, and Applications: From Microwaves to Visible Frequencies},
  journal   = {Proceedings of the {IEEE}},
  year      = {2015},
  volume    = {103},
  number    = {5},
  pages     = {793--821},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/journals/pieee/MonticoneA15},
  doi       = {10.1109/JPROC.2015.2399419},
  file      = {Monticone2015p793--821.pdf:Monticone2015p793--821.pdf:PDF},
  keywords  = {rank3},
}

@Article{Fromenteze2015p194104,
  author   = {Fromenteze,Thomas and Yurduseven,Okan and Imani,Mohammadreza F. and Gollub,Jonah and Decroze,Cyril and Carsenat,David and Smith,David R.},
  title    = {Computational imaging using a mode-mixing cavity at microwave frequencies},
  journal  = {Applied Physics Letters},
  year     = {2015},
  volume   = {106},
  number   = {19},
  pages    = {194104},
  abstract = { We present a 3D computational imaging system based on a mode-mixing cavity at microwave frequencies. The core component of this system is an electrically large rectangular cavity with one corner re-shaped to catalyze mode mixing, often called a Sinai Billiard. The front side of the cavity is perforated with a grid of periodic apertures that sample the cavity modes and project them into the imaging scene. The radiated fields are scattered by the scene and are measured by low gain probe antennas. The complex radiation patterns generated by the cavity thus encode the scene information onto a set of frequency modes. Assuming the first Born approximation for scattering dynamics, the received signal is processed using computational methods to reconstruct a 3D image of the scene with resolution determined by the diffraction limit. The proposed mode-mixing cavity is simple to fabricate, exhibits low losses, and can generate highly diverse measurement modes. The imaging system demonstrated in this letter can find application in security screening and medical diagnostic imaging. },
  doi      = {10.1063/1.4921081},
  eprint   = {https://doi.org/10.1063/1.4921081},
  file     = {Fromenteze2015p194104.pdf:Fromenteze2015p194104.pdf:PDF},
  url      = { 
        https://doi.org/10.1063/1.4921081
    
},
}

@Article{Sun2013p844--847,
  author    = {Sun, B. and Edgar, M. P. and Bowman, R. and Vittert, L. E. and Welsh, S. and Bowman, A. and Padgett, M. J.},
  title     = {3D Computational Imaging with Single-Pixel Detectors},
  journal   = {Science},
  year      = {2013},
  volume    = {340},
  number    = {6134},
  pages     = {844--847},
  issn      = {0036-8075},
  abstract  = {Three-dimensional (3D) images can be captured by, for example, holographic imaging or stereoimaging techniques. To avoid using expensive optical components that are limited to specialized bands of wavelengths, Sun et al. (p. 844; see the Perspective by Faccio and Leach) projected pulses of randomly textured light onto an object. They were able to reconstruct an image of the 3D object by detecting the reflected light with several photodetectors without any need for lenses. The patterned light beams can thus in principle be substituted for light sources of any wavelength. Computational imaging enables retrieval of the spatial information of an object with the use of single-pixel detectors. By projecting a series of known random patterns and measuring the backscattered intensity, it is possible to reconstruct a two-dimensional (2D) image. We used several single-pixel detectors in different locations to capture the 3D form of an object. From each detector we derived a 2D image that appeared to be illuminated from a different direction, even though only a single digital projector was used for illumination. From the shading of the images, the surface gradients could be derived and the 3D object reconstructed. We compare our result to that obtained from a stereophotogrammetric system using multiple cameras. Our simplified approach to 3D imaging can readily be extended to nonvisible wavebands.},
  doi       = {10.1126/science.1234454},
  eprint    = {http://science.sciencemag.org/content/340/6134/844.full.pdf},
  file      = {Sun2013p844--847.pdf:Sun2013p844--847.pdf:PDF},
  keywords  = {rank3},
  publisher = {American Association for the Advancement of Science},
  url       = {http://science.sciencemag.org/content/340/6134/844},
}

@Article{Pulido-Mancera2016p2082--2092,
  author    = {Laura Pulido-Mancera and Thomas Fromenteze and Timothy Sleasman and Michael Boyarsky and Mohammadreza F. Imani and Matthew Reynolds and David Smith},
  title     = {Application of range migration algorithms to imaging with a dynamic metasurface antenna},
  journal   = {J. Opt. Soc. Am. B},
  year      = {2016},
  volume    = {33},
  number    = {10},
  pages     = {2082--2092},
  month     = {Oct},
  abstract  = {Dynamic metasurface antennas are planar structures that exhibit remarkable capabilities in controlling electromagnetic wavefronts, advantages that are particularly attractive for microwave imaging. These antennas exhibit strong frequency dispersion and produce rapidly varying radiation patterns. Such behavior presents unique challenges for integration with conventional imaging algorithms. We adapt the range migration algorithm (RMA) for use with dynamic metasurfaces and propose a preprocessing step that ultimately allows for expression of measurements in the spatial frequency domain, from which the fast Fourier transform can efficiently reconstruct the scene. Numerical studies illustrate imaging performance using conventional methods and the adapted RMA, demonstrating that the RMA can reconstruct images with comparable quality in a fraction of the time. The algorithm can be extended to a broad class of complex antennas for application in synthetic aperture radar and MIMO imaging.},
  doi       = {10.1364/JOSAB.33.002082},
  file      = {Pulido-Mancera2016p2082--2092.pdf:Pulido-Mancera2016p2082--2092.pdf:PDF},
  keywords  = {Image processing; Image reconstruction techniques; Image recognition, algorithms and filters ; Discrete Fourier transforms; Fast Fourier transforms; Image processing; Imaging systems; Imaging techniques; Synthetic aperture radar, rank3},
  publisher = {OSA},
  url       = {http://josab.osa.org/abstract.cfm?URI=josab-33-10-2082},
}

@Article{Lipworth2015p9343--9353,
  author    = {Guy Lipworth and Alec Rose and Okan Yurduseven and Vinay R. Gowda and Mohammadreza F. Imani and Hayrettin Odabasi and Parker Trofatter and Jonah Gollub and David R. Smith},
  title     = {Comprehensive simulation platform for a metamaterial imaging system},
  journal   = {Appl. Opt.},
  year      = {2015},
  volume    = {54},
  number    = {31},
  pages     = {9343--9353},
  month     = {Nov},
  abstract  = {Recently, a frequency-diverse, metamaterial-based aperture has been introduced in the context of microwave and millimeter wave imaging. The generic form of the aperture is that of a parallel plate waveguide, in which complementary metamaterial elements patterned into the upper plate couple energy from the waveguide mode to the scene. To reliably predict the imaging performance of such an aperture prior to fabrication and experiments, it is necessary to have an accurate forward model that predicts radiation from the aperture, a model for scattering from an arbitrary target in the scene, and a set of image reconstruction approaches that allow scene estimation from an arbitrary set of measurements. Here, we introduce a forward model in which the metamaterial elements are approximated as polarizable magnetic dipoles, excited by the fields propagating within the waveguide. The dipoles used in the model can have arbitrarily assigned polarizability characteristics. Alternatively, fields measured from actual metamaterial samples can be decomposed into a set of effective dipole radiators, allowing the performance of actual samples to be quantitatively modeled and compared with simulated apertures. To confirm the validity of our model, we simulate measurements and scene reconstructions with a virtual multiaperture imaging system operating in the K-band spectrum (18\&\#x2013;26.5\&\#xA0;GHz) and compare its performance with an experimental system.},
  doi       = {10.1364/AO.54.009343},
  file      = {Lipworth2015p9343--9353.pdf:Lipworth2015p9343--9353.pdf:PDF},
  keywords  = {Apertures; Coherence imaging; Image detection systems; Coherence imaging; Computational imaging ; Metamaterials; Aperture synthesis; Image quality; Image reconstruction; Millimeter wave imaging; Millimeter waves; Wave propagation, rank3},
  publisher = {OSA},
  url       = {http://ao.osa.org/abstract.cfm?URI=ao-54-31-9343},
}

@Article{Duran2015p14424--14433,
  author    = {V. Dur\'{a}n and F. Soldevila and E. Irles and P. Clemente and E. Tajahuerce and P. Andr\'{e}s and J. Lancis},
  title     = {Compressive imaging in scattering media},
  journal   = {Opt. Express},
  year      = {2015},
  volume    = {23},
  number    = {11},
  pages     = {14424--14433},
  month     = {Jun},
  abstract  = {One challenge that has long held the attention of scientists is that of clearly seeing objects hidden by turbid media, as smoke, fog or biological tissue, which has major implications in fields such as remote sensing or early diagnosis of diseases. Here, we combine structured incoherent illumination and bucket detection for imaging an absorbing object completely embedded in a scattering medium. A sequence of low-intensity microstructured light patterns is launched onto the object, whose image is accurately reconstructed through the light fluctuations measured by a single-pixel detector. Our technique is noninvasive, does not require coherent sources, raster scanning nor time-gated detection and benefits from the compressive sensing strategy. As a proof of concept, we experimentally retrieve the image of a transilluminated target both sandwiched between two holographic diffusers and embedded in a 6mm-thick sample of chicken breast.},
  doi       = {10.1364/OE.23.014424},
  file      = {Duran2015p14424--14433.pdf:Duran2015p14424--14433.pdf:PDF},
  keywords  = {Turbid media; Imaging through turbid media ; Computational imaging ; Digital micromirror devices; Imaging techniques; Inhomogeneous optical media; Multiple scattering; Scattering media; Turbid media},
  publisher = {OSA},
  url       = {http://www.opticsexpress.org/abstract.cfm?URI=oe-23-11-14424},
}

@PhdThesis{bucuci:tel-01765346,
  author      = {Bucuci, Stefania},
  title       = {{High resolution RCS imaging in anechoic chamber by introducing a random medium}},
  school      = {{Universit{\'e} Rennes 1}},
  year        = {2017},
  type        = {Theses},
  month       = Dec,
  file        = {bucuci\:tel-01765346.pdf:bucuci\:tel-01765346.pdf:PDF;BUCUCI_Stefania.pdf:https\://tel.archives-ouvertes.fr/tel-01765346/file/BUCUCI_Stefania.pdf:PDF},
  hal_id      = {tel-01765346},
  hal_version = {v1},
  keywords    = {Radar cross section ; Anechoic chamber ; Time reversal ; Reverberation chamber ; Random medium ; Microwave imaging ; Antennas ; Surface {\'e}quivalente radar ; Chambre an{\'e}cho{\"i}que ; Retournement temporel ; Chambre r{\'e}verb{\'e}rante ; Milieu diffusant ; Imagerie microonde ; Antennes, rank3},
  number      = {2017REN1S108},
  url         = {https://tel.archives-ouvertes.fr/tel-01765346},
}

@Article{Tajahuerce2014p16945--16955,
  author    = {Enrique Tajahuerce and Vicente Dur\'{a}n and Pere Clemente and Esther Irles and Fernando Soldevila and Pedro Andr\'{e}s and Jes\'{u}s Lancis},
  title     = {Image transmission through dynamic scattering media by single-pixel photodetection},
  journal   = {Opt. Express},
  year      = {2014},
  volume    = {22},
  number    = {14},
  pages     = {16945--16955},
  month     = {Jul},
  abstract  = {Smart control of light propagation through highly scattering media is a much desired goal with major technological implications. Since interaction of light with highly scattering media results in partial or complete depletion of ballistic photons, it is in principle impossible to transmit images through distances longer than the extinction length. Nevertheless, different methods for image transmission, focusing, and imaging through scattering media by means of wavefront control have been published over the past few years. In this paper we show that single-pixel optical systems, based on compressive detection, can also overcome the fundamental limitation imposed by multiple scattering to successfully transmit information. But, in contrast with the recently introduced schemes that use the transmission matrix technique, our approach does not require any a-priori calibration process that ultimately makes the present method suitable to use with dynamic scattering media. This represents an advantage over previous methods that rely on optical feedback wavefront control, especially for short speckle decorrelation times.},
  doi       = {10.1364/OE.22.016945},
  file      = {Tajahuerce2014p16945--16955.pdf:Tajahuerce2014p16945--16955.pdf:PDF},
  keywords  = {Turbid media; Spatial light modulators; Multiple scattering; Computational imaging ; Image processing; Image quality; Liquid crystal modulators; Scattering media; Spatial light modulators; Speckle patterns},
  publisher = {OSA},
  url       = {http://www.opticsexpress.org/abstract.cfm?URI=oe-22-14-16945},
}

@Article{Liutkus2014p5552,
  author    = {Liutkus, Antoine and Martina, David and Popoff, Sébastien and Chardon, Gilles and Katz, Ori and Lerosey, Geoffroy and Gigan, Sylvain and Daudet, Laurent and Carron, Igor},
  title     = {Imaging With Nature: Compressive Imaging Using a Multiply Scattering Medium},
  journal   = {Scientific Reports},
  year      = {2014},
  volume    = {4},
  pages     = {5552},
  month     = jul,
  file      = {Liutkus2014p5552.pdf:Liutkus2014p5552.pdf:PDF},
  publisher = {The Author(s)},
  url       = {http://dx.doi.org/10.1038/srep05552},
}

@Article{Cui2016pe16172,
  author    = {Cui, Tie-Jun and Liu, Shuo and Li, Lian-Lin},
  title     = {Information entropy of coding metasurface},
  journal   = {Light: Science \&Amp; Applications},
  year      = {2016},
  volume    = {5},
  pages     = {e16172},
  month     = nov,
  file      = {Cui2016pe16172.pdf:Cui2016pe16172.pdf:PDF},
  publisher = {The Author(s)},
  url       = {http://dx.doi.org/10.1038/lsa.2016.172},
}

@Article{Levoy2006p46-55,
  author   = {M. Levoy},
  title    = {Light Fields and Computational Imaging},
  journal  = {Computer},
  year     = {2006},
  volume   = {39},
  number   = {8},
  pages    = {46-55},
  month    = {Aug},
  issn     = {0018-9162},
  abstract = {A survey of the theory and practice of light field imaging emphasizes the devices researchers in computer graphics and computer vision have built to capture light fields photographically and the techniques they have developed to compute novel images from them},
  doi      = {10.1109/MC.2006.270},
  file     = {Levoy2006p46-55.pdf:Levoy2006p46-55.pdf:PDF},
  keywords = {computer graphics;computer vision;computational imaging;computer graphics;computer vision;light field imaging;Area measurement;Biology computing;Computer vision;Geometrical optics;Geophysics computing;Image analysis;Maxwell equations;Optical imaging;Solids;Wavelength measurement;Light field imaging;computational photography, rank3},
}

@Article{Kou2017p,
  author   = {Kou, Na and Li, Long and Tian, Shuncheng and Li, Yuanchang},
  title    = {Measurement Matrix Analysis and Radiation Improvement of a Metamaterial Aperture Antenna for Coherent Computational Imaging},
  journal  = {Applied Sciences},
  year     = {2017},
  volume   = {7},
  number   = {9},
  abstract = {A metamaterial aperture antenna (MAA) that generates frequency-diverse radiation field patterns has been introduced in the context of microwave wave imaging to perform compressive image reconstruction. This paper presents a new metamateriapl aperture design, which includes two kinds of metamaterial elements with random distribution. One is a high-Q resonant element whose resonant frequency is agile, and the other one is a low-Q element that has a high radiation efficiency across frequency band. Numerical simulations and measurements show that the radiation efficiency of up to 60% can be achieved for the MAA and the far-field patterns owns good orthogonality, when using the complementary electric-field-coupled (CELC) element and the complementary Jerusalem cross (CJC) element with a random distribution ratio of 4 to 1, which could be effectively used to reconstruct the target scattering scene.},
  doi      = {10.3390/app7090933},
  file     = {Kou2017p.pdf:Kou2017p.pdf:PDF},
  keywords = {rank3},
  url      = {http://www.mdpi.com/2076-3417/7/9/933},
}

@Article{Hunt2013p310--313,
  author    = {Hunt, John and Driscoll, Tom and Mrozack, Alex and Lipworth, Guy and Reynolds, Matthew and Brady, David and Smith, David R.},
  title     = {Metamaterial Apertures for Computational Imaging},
  journal   = {Science},
  year      = {2013},
  volume    = {339},
  number    = {6117},
  pages     = {310--313},
  issn      = {0036-8075},
  abstract  = {By leveraging metamaterials and compressive imaging, a low-profile aperture capable of microwave imaging without lenses, moving parts, or phase shifters is demonstrated. This designer aperture allows image compression to be performed on the physical hardware layer rather than in the postprocessing stage, thus averting the detector, storage, and transmission costs associated with full diffraction-limited sampling of a scene. A guided-wave metamaterial aperture is used to perform compressive image reconstruction at 10 frames per second of two-dimensional (range and angle) sparse still and video scenes at K-band (18 to 26 gigahertz) frequencies, using frequency diversity to avoid mechanical scanning. Image acquisition is accomplished with a 40:1 compression ratio.},
  doi       = {10.1126/science.1230054},
  eprint    = {http://science.sciencemag.org/content/339/6117/310.full.pdf},
  file      = {Hunt2013p310--313.pdf:Hunt2013p310--313.pdf:PDF},
  keywords  = {rank3},
  publisher = {American Association for the Advancement of Science},
  url       = {http://science.sciencemag.org/content/339/6117/310},
}

@Article{Lipworth2013p1603--1612,
  author    = {Guy Lipworth and Alex Mrozack and John Hunt and Daniel L. Marks and Tom Driscoll and David Brady and David R. Smith},
  title     = {Metamaterial apertures for coherent computational imaging on the physical layer},
  journal   = {J. Opt. Soc. Am. A},
  year      = {2013},
  volume    = {30},
  number    = {8},
  pages     = {1603--1612},
  month     = {Aug},
  abstract  = {We introduce the concept of a metamaterial aperture, in which an underlying reference mode interacts with a designed metamaterial surface to produce a series of complex field patterns. The resonant frequencies of the metamaterial elements are randomly distributed over a large bandwidth (18\&\#x2013;26\&\#xA0;GHz), such that the aperture produces a rapidly varying sequence of field patterns as a function of the input frequency. As the frequency of operation is scanned, different subsets of metamaterial elements become active, in turn varying the field patterns at the scene. Scene information can thus be indexed by frequency, with the overall effectiveness of the imaging scheme tied to the diversity of the generated field patterns. As the quality (Q-) factor of the metamaterial resonators increases, the number of distinct field patterns that can be generated increases\&\#x2014;improving scene estimation. In this work we provide the foundation for computational imaging with metamaterial apertures based on frequency diversity, and establish that for resonators with physically relevant Q-factors, there are potentially enough distinct measurements of a typical scene within a reasonable bandwidth to achieve diffraction-limited reconstructions of physical scenes.},
  doi       = {10.1364/JOSAA.30.001603},
  file      = {Lipworth2013p1603--1612.pdf:Lipworth2013p1603--1612.pdf:PDF},
  keywords  = {Inverse problems; Apertures; Image detection systems; Computational imaging ; Metamaterials; Compressive imaging; Diffraction limit; Diffractive optical elements; Guided waves; Optical components; Terahertz imaging},
  publisher = {OSA},
  url       = {http://josaa.osa.org/abstract.cfm?URI=josaa-30-8-1603},
}

@Article{Hunt2014p2109--2119,
  author    = {John Hunt and Jonah Gollub and Tom Driscoll and Guy Lipworth and Alex Mrozack and Matthew S. Reynolds and David J. Brady and David R. Smith},
  title     = {Metamaterial microwave holographic imaging system},
  journal   = {J. Opt. Soc. Am. A},
  year      = {2014},
  volume    = {31},
  number    = {10},
  pages     = {2109--2119},
  month     = {Oct},
  abstract  = {We demonstrate a microwave imaging system that combines advances in metamaterial aperture design with emerging computational imaging techniques. The flexibility inherent to guided-wave, complementary metamaterials enables the design of a planar antenna that illuminates a scene with dramatically varying radiation patterns as a function of frequency. As frequency is swept over the K-band (17.5\&\#x2013;26.5\&\#xA0;GHz), a sequence of pseudorandom radiation patterns interrogates a scene. Measurements of the return signal versus frequency are then acquired and the scene is reconstructed using computational imaging methods. The low-cost, frequency-diverse static aperture allows three-dimensional images to be formed without mechanical scanning or dynamic beam-forming elements. The metamaterial aperture is complementary to a variety of computational imaging schemes, and can be used in conjunction with other sensors to form a multifunctional imaging platform. We illustrate the potential of multisensor fusion by integrating an infrared structured-light and optical image sensor to accelerate the microwave scene reconstruction and to provide a simultaneous visualization of the scene.},
  doi       = {10.1364/JOSAA.31.002109},
  file      = {Hunt2014p2109--2119.pdf:Hunt2014p2109--2119.pdf:PDF},
  keywords  = {Imaging systems; Microwaves; Computational imaging ; Metamaterials; Image processing; Image quality; Imaging systems; Millimeter wave imaging; Optical elements; Synthetic aperture radar, rank3},
  publisher = {OSA},
  url       = {http://josaa.osa.org/abstract.cfm?URI=josaa-31-10-2109},
}

@Article{Kpre2017p1357–1363,
  author    = {Kpré, Ettien L. and Decroze, Cyril and Fromenteze, Thomas},
  title     = {MIMO radar pseudo-orthogonal waveform generation by a passive 1 × M mode-mixing microwave cavity},
  journal   = {International Journal of Microwave and Wireless Technologies},
  year      = {2017},
  volume    = {9},
  number    = {7},
  pages     = {1357–1363},
  doi       = {10.1017/S175907871700023X},
  file      = {Kpre2017p1357–1363.pdf:Kpre2017p1357–1363.pdf:PDF},
  keywords  = {rank3},
  publisher = {Cambridge University Press},
}

@InProceedings{Kpre2016p,
  author    = {E. L. Kpré and T. Fromenteze and C. Decroze},
  title     = {MIMO radar transmit array fed by a 1 #x00D7;M passive chaotic cavity},
  booktitle = {2016 10th European Conference on Antennas and Propagation (EuCAP)},
  year      = {2016},
  pages     = {1-5},
  month     = {April},
  abstract  = {It is well known that MIMO radar waveforms should be orthogonal to probe simultaneously the MIMO channel matrix H. This method is not easily implementable since it requires as much transmitter chains as antennas. Herein, a compressive technique is introduced to measure the channel information avoiding multiple waveforms generation. This technique is thus based on the generation of a single waveform to probe the channel by the mean of a passive chaotic component connected to the transmit array. Mathematical formulations are presented considering a device with uncorrelated transfer functions allowing the transmission of orthogonal waveforms. Simulation and experimental results are presented to highlight the advantages of such a technique.},
  doi       = {10.1109/EuCAP.2016.7481981},
  file      = {Kpre2016p.pdf:Kpre2016p.pdf:PDF},
  keywords  = {MIMO communication;MIMO radar;passive radar;radar transmitters;MIMO channel;MIMO radar transmit array;compressive technique;passive chaotic cavity;uncorrelated transfer functions;Cavity resonators;MIMO;MIMO radar;Radar antennas;Transfer functions;Transmitting antennas;MIMO Radar;passive chaotic microwave component},
}

@InProceedings{fromenteze:hal-01213875,
  author      = {Fromenteze, Thomas and Kpr{\'e}, Ettien Lazare and Decroze, Cyril and Carsenat, David},
  title       = {{Passive UWB Beamforming: a N to M Compression Study}},
  booktitle   = {{European Microwave Week 2015 - Eurad}},
  year        = {2015},
  address     = {Paris, France},
  month       = Sep,
  file        = {fromenteze\:hal-01213875.pdf:fromenteze\:hal-01213875.pdf:PDF;Fromenteze_EMW_2015_NtoM.pdf:https\://hal-unilim.archives-ouvertes.fr/hal-01213875/file/Fromenteze_EMW_2015_NtoM.pdf:PDF},
  hal_id      = {hal-01213875},
  hal_version = {v1},
  keywords    = {rank3},
  url         = {https://hal-unilim.archives-ouvertes.fr/hal-01213875},
}

@Article{Fromenteze2016p16760--16776,
  author    = {Thomas Fromenteze and Xiaojun Liu and Michael Boyarsky and Jonah Gollub and David R. Smith},
  title     = {Phaseless computational imaging with a radiating metasurface},
  journal   = {Opt. Express},
  year      = {2016},
  volume    = {24},
  number    = {15},
  pages     = {16760--16776},
  month     = {Jul},
  abstract  = {Computational imaging modalities support a simplification of the active architectures required in an imaging system and these approaches have been validated across the electromagnetic spectrum. Recent implementations have utilized pseudo-orthogonal radiation patterns to illuminate an object of interest\&\#x02014;notably, frequency-diverse metasurfaces have been exploited as fast and low-cost alternative to conventional coherent imaging systems. However, accurately measuring the complex-valued signals in the frequency domain can be burdensome, particularly for sub-centimeter wavelengths. Here, computational imaging is studied under the relaxed constraint of intensity-only measurements. A novel 3D imaging system is conceived based on \&\#x02018;phaseless\&\#x02019; and compressed measurements, with benefits from recent advances in the field of phase retrieval. In this paper, the methodology associated with this novel principle is described, studied, and experimentally demonstrated in the microwave range. A comparison of the estimated images from both complex valued and phaseless measurements are presented, verifying the fidelity of phaseless computational imaging.},
  doi       = {10.1364/OE.24.016760},
  file      = {Fromenteze2016p16760--16776.pdf:Fromenteze2016p16760--16776.pdf:PDF},
  keywords  = {Image processing; Imaging systems; Computational imaging; Discrete Fourier transforms; Imaging systems; Phase measurement; Phase retrieval; X ray imaging, rank3},
  publisher = {OSA},
  url       = {http://www.opticsexpress.org/abstract.cfm?URI=oe-24-15-16760},
}

@Article{Marks2016p899--912,
  author    = {Daniel L. Marks and Jonah Gollub and David R. Smith},
  title     = {Spatially resolving antenna arrays using frequency diversity},
  journal   = {J. Opt. Soc. Am. A},
  year      = {2016},
  volume    = {33},
  number    = {5},
  pages     = {899--912},
  month     = {May},
  abstract  = {Radio imaging devices and synthetic aperture radar typically use either mechanical scanning or phased arrays to illuminate a target with spatially varying radiation patterns. Mechanical scanning is unsuitable for many high-speed imaging applications, and phased arrays contain many active components and are technologically and cost prohibitive at millimeter and terahertz frequencies. We show that antennas deliberately designed to produce many different radiation patterns as the frequency is varied can reduce the number of active components necessary while still capturing high-quality images. This approach, called frequency-diversity imaging, can capture an entire two-dimensional image using only a single transmit and receive antenna with broadband illumination. We provide simple principles that ascertain whether a design is likely to achieve particular resolution specifications, and illustrate these principles with simulations.},
  doi       = {10.1364/JOSAA.33.000899},
  file      = {Marks2016p899--912.pdf:Marks2016p899--912.pdf:PDF},
  keywords  = {Imaging systems; Apertures; Electromagnetic optics ; Computed tomography; Fresnel diffraction; Magnetic resonance imaging; Phase shift; Propagation methods; Synthetic aperture radar},
  publisher = {OSA},
  url       = {http://josaa.osa.org/abstract.cfm?URI=josaa-33-5-899},
}

@Article{Yurduseven2015p97-107,
  author   = {O. Yurduseven, M. F. Imani, H. Odabasi, J. Gollub, G. Lipworth, A. Rose, and D. R. Smith,},
  title    = {Resolution of the Frequency Diverse Metamaterial Aperture Imager},
  journal  = {Progress In Electromagnetics Research},
  year     = {2015},
  volume   = {150},
  pages    = {97-107},
  file     = {Yurduseven2015p97-107.pdf:Yurduseven2015p97-107.pdf:PDF},
  keywords = {rank3},
}

@Article{Watts2014p605,
  author    = {Watts, Claire M. and Shrekenhamer, David and Montoya, John and Lipworth, Guy and Hunt, John and Sleasman, Timothy and Krishna, Sanjay and Smith, David R. and Padilla, Willie J.},
  title     = {Terahertz compressive imaging with metamaterial spatial light modulators},
  journal   = {Nature Photonics},
  year      = {2014},
  volume    = {8},
  pages     = {605},
  month     = jun,
  file      = {Watts2014p605.pdf:Watts2014p605.pdf:PDF},
  publisher = {Nature Publishing Group},
  url       = {http://dx.doi.org/10.1038/nphoton.2014.139},
}

@Article{Fromenteze2015p593-600,
  author   = {T. Fromenteze and C. Decroze and D. Carsenat},
  title    = {Waveform Coding for Passive Multiplexing: Application to Microwave Imaging},
  journal  = {IEEE Transactions on Antennas and Propagation},
  year     = {2015},
  volume   = {63},
  number   = {2},
  pages    = {593-600},
  month    = {Feb},
  issn     = {0018-926X},
  abstract = {This paper proposes a novel passive technique for the collection of microwave images. A compact component is developed that passively codes and sums the waves received by an antenna array to which it is connected, and produces a unique signal that contains all of the scene information. This technique of passive multiplexing simplifies the microwave reception chains for radar and beamforming systems (whose complexity and cost highly increase with the number of antennas) and does not require any active elements to achieve beamsteering. The preservation of the waveforms is ensured using orthogonal codes supplied by the propagation through the component's uncorrelated channels. Here we show a multiplexing technique in the physical layer that, besides being compact and passive, is compatible with all ultrawideband antennas, enabling its implementation in various fields.},
  doi      = {10.1109/TAP.2014.2382647},
  file     = {Fromenteze2015p593-600.pdf:Fromenteze2015p593-600.pdf:PDF},
  keywords = {antenna arrays;array signal processing;beam steering;microwave imaging;multiplexing;orthogonal codes;ultra wideband antennas;waveform analysis;antenna array;beamforming system;beamsteering;compact component;microwave imaging;microwave reception chain;orthogonal code;passive multiplexing technique;radar;ultrawideband antenna;uncorrelated channel;waveform coding;Array signal processing;Arrays;Correlation;Microwave imaging;Multiplexing;Noise;Beamforming;inverse problem;microwave imaging;passive technique;radar;ultrawideband (UWB)},
}
﻿

@Article{Gollub2017p,
  author                     = {Gollub, J. N. and Yurduseven, O. and Trofatter, K. P. and Arnitz, D. and Imani, M. F. and Sleasman, T. and Boyarsky, M. and Rose, A. and Pedross-Engel, A. and Odabasi, H. and Zvolensky, T. and Lipworth, G. and Brady, D. and Marks, D. L. and Reynolds, M. S. and Smith, D. R.},
  title                      = {{Large Metasurface Aperture for Millimeter Wave Computational Imaging at the Human-Scale}},
  journal                    = {{SCIENTIFIC REPORTS}},
  year                       = {{2017}},
  volume                     = {{7}},
  month                      = {{FEB 20}},
  issn                       = {{2045-2322}},
  abstract                   = {{We demonstrate a low-profile holographic imaging system at millimeter
   wavelengths based on an aperture composed of frequency-diverse
   metasurfaces. Utilizing measurements of spatially-diverse field
   patterns, diffraction-limited images of human-sized subjects are
   reconstructed. The system is driven by a single microwave source swept
   over a band of frequencies (17.5-26.5 GHz) and switched between a
   collection of transmit and receive metasurface panels. High fidelity
   image reconstruction requires a precise model for each field pattern
   generated by the aperture, as well as the manner in which the field
   scatters from objects in the scene. This constraint makes scaling of
   computational imaging systems inherently challenging for electrically
   large, coherent apertures. To meet the demanding requirements, we
   introduce computational methods and calibration approaches that enable
   rapid and accurate imaging performance.}},
  address                    = {{MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND}},
  affiliation                = {{Gollub, JN (Reprint Author), Duke Univ, Ctr Metamat \& Integrated Plasmon, Box 90291, Durham, NC 27708 USA. Gollub, JN (Reprint Author), Duke Univ, Dept Elect \& Comp Engn, Durham, NC 27708 USA. Gollub, J. N.; Yurduseven, O.; Trofatter, K. P.; Imani, M. F.; Sleasman, T.; Boyarsky, M.; Odabasi, H.; Zvolensky, T.; Lipworth, G.; Marks, D. L.; Smith, D. R., Duke Univ, Ctr Metamat \& Integrated Plasmon, Box 90291, Durham, NC 27708 USA. Gollub, J. N.; Yurduseven, O.; Trofatter, K. P.; Imani, M. F.; Sleasman, T.; Boyarsky, M.; Odabasi, H.; Zvolensky, T.; Lipworth, G.; Marks, D. L.; Smith, D. R., Duke Univ, Dept Elect \& Comp Engn, Durham, NC 27708 USA. Arnitz, D.; Reynolds, M. S., Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA. Rose, A., Evolv Technol, 200 West St, Waltham, MA 02451 USA. Reynolds, M. S., Univ Washington, Dept Comp Sci \& Engn, Seattle, WA 98195 USA.}},
  article-number             = {{42650}},
  author-email               = {{jonah.gollub@duke.edu}},
  cited-references           = {{Ahmed SS, 2011, IEEE T MICROW THEORY, V59, P3567, DOI 10.1109/TMTT.2011.2172812. Amin M. G., 2016, THROUGH THE WALL RAD. Boag A, 2001, IEEE T ANTENN PROPAG, V49, P666, DOI 10.1109/8.923329. Bond EJ, 2003, IEEE T ANTENN PROPAG, V51, P1690, DOI 10.1109/TAP.2003.815446. Brady D. J., 2009, OPTICAL IMAGING SPEC. BROWN WM, 1967, IEEE T AERO ELEC SYS, VAES3, P217, DOI 10.1109/TAES.1967.5408745. Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124. Chan WL, 2008, APPL PHYS LETT, V93, DOI 10.1063/1.2989126. Charvat G. L., 2012, IEEE RAD C. Dehmollaian M, 2008, IEEE T GEOSCI REMOTE, V46, P1589, DOI 10.1109/TGRS.2008.916212. Ding XM, 2015, ADV MATER, V27, P1195, DOI 10.1002/adma.201405047. Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582. Engheta N., 2006, METAMATERIALS PHYS E. Fenn A. J., 2000, Lincoln Laboratory Journal, V12, P321. Fergus R., 2006, RANDOM LENS IMAGING. Fromenteze T, 2015, APPL PHYS LETT, V106, DOI 10.1063/1.4921081. Furxhi O, 2014, OPT EXPRESS, V22, P16393, DOI 10.1364/OE.22.016393. GOLAY MJE, 1971, J OPT SOC AM, V61, P272, DOI 10.1364/JOSA.61.000272. Gregson S. F., 2007, PRINCIPLES PLANAR NE. Holloway CL, 2012, IEEE ANTENN PROPAG M, V54, P10, DOI 10.1109/MAP.2012.6230714. Hunt J, 2013, SCIENCE, V339, P310, DOI 10.1126/science.1230054. Imani F., 2016, J APPL PHYS, V120, DOI {[}DOI 10.1063/1.4964336, 10.1063/1.4964336]. JOY EB, 1972, IEEE T ANTENN PROPAG, VAP20, P253, DOI 10.1109/TAP.1972.1140193. Lipworth G, 2013, J OPT SOC AM A, V30, P1603, DOI 10.1364/JOSAA.30.001603. Liu C, 2003, PHYS MED BIOL, V48, P2437, DOI 10.1088/0031-9155/48/15/313. Liutkus A, 2014, SCI REP-UK, V4, DOI 10.1038/srep05552. Marks DL, 2016, J OPT SOC AM A, V33, P899, DOI 10.1364/JOSAA.33.000899. Montaldo G, 2005, IEEE T ULTRASON FERR, V52, P1489, DOI 10.1109/TUFFC.2005.1516021. Nikolova NK, 2011, IEEE MICROW MAG, V12, P78, DOI 10.1109/MMM.2011.942702. Russell ME, 1997, IEEE T MICROW THEORY, V45, P2444, DOI 10.1109/22.643858. Sheen DM, 2001, IEEE T MICROW THEORY, V49, P1581, DOI 10.1109/22.942570. Siebert W., 1986, CIRCUITS SIGNALS SYS. Skolnik M., 2008, RADAR HDB. Sleasman T, 2016, PHYS REV APPL, V6, DOI 10.1103/PhysRevApplied.6.054019. Sleasman T, 2016, J OPT SOC AM B, V33, P1098, DOI 10.1364/JOSAB.33.001098. Sleasman T, 2015, APPL PHYS LETT, V107, DOI 10.1063/1.4935941. Takhar D, 2006, PROC SPIE, V6065, DOI 10.1117/12.659602. Venkatesh S, 2016, OPT EXPRESS, V24, P8317, DOI 10.1364/OE.24.008317. Wang LB, 2016, SCI REP-UK, V6, DOI 10.1038/srep26959. Watts CM, 2014, NAT PHOTONICS, V8, P605, DOI {[}10.1038/NPHOTON.2014.139, 10.1038/nphoton.2014.139]. Xie YB, 2015, P NATL ACAD SCI USA, V112, P10595, DOI 10.1073/pnas.1502276112. YAGHJIAN AD, 1986, IEEE T ANTENN PROPAG, V34, P30, DOI 10.1109/TAP.1986.1143727. Yang HH, 2016, SCI REP-UK, V6, DOI 10.1038/srep35692. Yurduseven O, 2016, IET MICROW ANTENNA P, V10, P1174, DOI 10.1049/iet-map.2015.0836. Yurduseven O, 2016, IEEE ACCESS, V4, P2488, DOI 10.1109/ACCESS.2016.2570678. Yurduseven O, 2016, IEEE MICROW WIREL CO, V26, P367, DOI 10.1109/LMWC.2016.2548443. Yurduseven O, 2016, OPT EXPRESS, V24, P8907, DOI 10.1364/OE.24.008907. Yurduseven O, 2015, PROG ELECTROMAGN RES, V150, P97, DOI 10.2528/PIER14113002.}},
  da                         = {{2018-07-23}},
  doc-delivery-number        = {{EL1YP}},
  doi                        = {{10.1038/srep42650}},
  esi-highly-cited-paper     = {{Y}},
  esi-hot-paper              = {{N}},
  file                       = {Gollub2017p.pdf:Gollub2017p.pdf:PDF},
  funding-acknowledgement    = {{Department of Homeland Security, Science and Technology Directorate {[}HSHQDC-12-C-00049]}},
  funding-text               = {{This work was supported by the Department of Homeland Security, Science and Technology Directorate (Contract No. HSHQDC-12-C-00049). The published material represents the position of the author(s) and not necessarily that of the DHS.}},
  journal-iso                = {{Sci Rep}},
  keywords                   = {rank3},
  keywords-plus              = {{SYNTHETIC-APERTURE; METAMATERIAL APERTURES; BREAST-CANCER; RADAR; SENSOR; POLARIZATION; SCATTERING; RESOLUTION; ARRAYS; CAVITY}},
  language                   = {{English}},
  number-of-cited-references = {{48}},
  oa                         = {{gold}},
  orcid-numbers              = {{Odabasi, Hayrettin/0000-0002-8738-5892 Pedross-Engel, Andreas/0000-0001-9945-0682}},
  publisher                  = {{NATURE PUBLISHING GROUP}},
  research-areas             = {{Science \& Technology - Other Topics}},
  researcherid-numbers       = {{Odabasi, Hayrettin/C-8082-2018 }},
  times-cited                = {{29}},
  type                       = {{Article}},
  unique-id                  = {{ISI:000394417600001}},
  usage-count-last-180-days  = {{12}},
  usage-count-since-2013     = {{60}},
  web-of-science-categories  = {{Multidisciplinary Sciences}},
}

@InBook{Chen2017p328-,
  pages     = {328-},
  title     = {Resolution of Computational Imaging},
  publisher = {Wiley-IEEE Press},
  year      = {2017},
  author    = {Xudong Chen},
  isbn      = {9781119311997},
  abstract  = {This chapter discusses the resolution of an image that is obtained by solving inverse scattering problems, rather than to provide a comprehensive review of super‐resolution imaging theories and schemes. It explains the resolution of a traditional optical microscopy, which is a kind of instrumental imaging. The chapter introduces computational imaging, where images are generated by numerical reconstruction. Both the inverse source problem and inverse scattering problem are discussed. The chapter describes the Cramer‐Rao bound (CRB), which quantifies a lower bound on the variance of any unbiased estimator. The accuracy of computational imaging is quantified by the CRB. The chapter presents the resolution of image obtained by the Born Approximation (BA) that is applicable to weak scatterers. The analytical tool for the BA‐based imaging provides a deep insight into the resolution of computational imaging. The chapter illustrates the diffraction‐limited resolution, that is, half wavelength as a rule of thumb.},
  booktitle = {Computational Methods for Electromagnetic Inverse Scattering},
  doi       = {10.1002/9781119311997.ch10},
  keywords  = {Lenses;Microscopy;Optical imaging;Optical microscopy;Spatial resolution, rank3},
  url       = {https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=8410141},
}

@Article{Masia2018p112-120,
  author   = {B. Masia},
  title    = {Computational Imaging and Displays: Capturing and displaying richer representations of the world},
  journal  = {IEEE Computer Graphics and Applications},
  year     = {2018},
  volume   = {38},
  number   = {2},
  pages    = {112-120},
  month    = {Mar},
  issn     = {0272-1716},
  abstract = {Computational imaging techniques allow capturing richer, more complete representations of a scene through the introduction of novel computational algorithms, overcoming the limitations imposed by hardware and optics. The areas of application range from medical imaging to security, to areas in engineering, to name a few. Computational displays combine optics, hardware and computation to faithfully reproduce the world as seen by our eyes, something that current displays still cannot do. This article looks at a few examples of both, aiming to convey the power of the joint co-design of hardware and computational algorithms, also taking into account visual perception.},
  doi      = {10.1109/MCG.2018.021951638},
  keywords = {computer displays;visual perception;application range;computational displays;computational imaging techniques;medical imaging;visual perception;Biomedical imaging;Cameras;Dynamic range;Image reconstruction;Image resolution;Optics;applied perception;computational displays;computational imaging;computer graphics;high dynamic range imaging;stereoscopic displays, rank3},
}

@Article{Wu2018p3619-3631,
  author   = {Z. Wu and L. Zhang and H. Liu and N. Kou},
  title    = {Range Decoupling Algorithm for Accelerating Metamaterial Apertures-Based Computational Imaging},
  journal  = {IEEE Sensors Journal},
  year     = {2018},
  volume   = {18},
  number   = {9},
  pages    = {3619-3631},
  month    = {May},
  issn     = {1530-437X},
  abstract = {Metamaterial apertures-based computation imaging system enables interrogating the scene information with frequency-diverse complex radiation fields, reducing the complicated active components and mechanical scanning equipments. Nevertheless, when pursuing an accurate perception of the surrounding environment, the natural discretization of imaging volume would inevitably pose the massive amount of data and burdensome computation for the three-dimensional (3-D) image formation. In this paper, we propose a range decoupling algorithm to accelerate the image generation of metamaterial apertures imaging system operating in the far-field. The algorithm could achieve the dimension reduction through exploiting the local frequency coherence of the metamaterial apertures antenna radiation fields, allowing the scene to be decomposed into a number of range cells and reconstructed in a parallel fashion. In this sense, the crucial memory requirements and prohibitively high computation costs could be mitigated while the high-quality 3-D images are maintained. Extensive imaging simulations are conducted to illustrate the effectiveness of the proposed algorithm.},
  doi      = {10.1109/JSEN.2018.2815600},
  keywords = {antenna radiation patterns;aperture antennas;electromagnetic metamaterials;Metamaterial Apertures;burdensome computation;complicated active components;computation imaging system;crucial memory requirements;frequency-diverse complex radiation fields;high-quality 3D images;image generation;local frequency coherence;mechanical scanning equipments;metamaterial apertures antenna radiation fields;prohibitively high computation costs;range decoupling algorithm;scene information;three-dimensional image formation;Apertures;Image reconstruction;Imaging;Mathematical model;Metamaterials;Sensors;Three-dimensional displays;Metamaterial apertures;compressed sensing (CS);decoupling;inverse Fast Fourier Transform (iFFT);local coherence;parallelization},
}

@Article{Pedross-Engel2018p184-193,
  author   = {A. Pedross-Engel and D. Arnitz and J. N. Gollub and O. Yurduseven and K. P. Trofatter and M. F. Imani and T. Sleasman and M. Boyarsky and X. Fu and D. L. Marks and D. R. Smith and M. S. Reynolds},
  title    = {Orthogonal Coded Active Illumination for Millimeter Wave, Massive-MIMO Computational Imaging With Metasurface Antennas},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {2},
  pages    = {184-193},
  month    = {June},
  abstract = {Emerging metasurface antenna technology enables flexible and low cost massive multiple-input multiple-output (MIMO) millimeter-wave (mmW) imaging for applications such as personnel screening, weapon detection, reconnaissance, and remote sensing. This work proposes an orthogonal coded active illumination (OCAI) approach which utilizes simultaneous, mutually orthogonal coded transmit signals to illuminate the scene being imaged. It is shown that OCAI is robust to code amplitude and code phase imbalance introduced by imperfect transmitter (TX) and receiver (RX) hardware, while also mitigating common impairments of low cost direct-conversion receivers, such as RX self-jamming and DC offsets. The coding gain offered by this approach improves imager signal to noise ratio performance by up to 15 dB using codes of symbol length 32. We present validation images of resolution targets and a human-scale mannequin, obtained with a custom massive-MIMO mmW imager having 24 simultaneous TXs and 72 simultaneous RXs operating in the K-band (17.5 GHz to 26.5 GHz). The imager leverages both spatial coding via frequency diverse metasurface antennas, and temporal coding via OCAI of the scene.},
  doi      = {10.1109/TCI.2018.2808762},
  keywords = {MIMO communication;jamming;millimetre wave imaging;orthogonal codes;radio receivers;radio transmitters;weapons;OCAI;code phase imbalance;cost massive multiple-input multiple-output millimeter-wave imaging;custom massive-MIMO mmW imager;frequency 17.5 GHz to 26.5 GHz;frequency diverse metasurface antennas;low cost direct-conversion receivers;massive-MIMO computational imaging;metasurface antenna technology;millimeter wave;mutually orthogonal coded transmit signals;orthogonal coded active illumination approach;spatial coding;temporal coding;weapon detection;Antennas;Frequency modulation;Imaging;Lighting;MIMO communication;Receivers;Transmitters;Computational imaging;Imaging systems;MIMO;metasurface antennas;millimeter wave (mmW);orthogonal codes, rank3},
}

@Article{Marenzi2017p368-376,
  author   = {E. Marenzi and E. Torti and F. Leporati and E. Quevedo and G. M. Callicò},
  title    = {Block matching super-resolution parallel GPU implementation for computational imaging},
  journal  = {IEEE Transactions on Consumer Electronics},
  year     = {2017},
  volume   = {63},
  number   = {4},
  pages    = {368-376},
  month    = {November},
  issn     = {0098-3063},
  abstract = {This work presents the computational acceleration of a proprietary Super-Resolution (SR) algorithm (patented) for image and video enhancement. The considered algorithm is based on fusion SR techniques. The version proposed in this paper consists on the comparison of frames divided into Macro Blocks (MB) of fixed dimensions and on acquisition from a single camera. Due to its intensive computation, that limits its practical application in specific contexts where fast processing (even with real-time constraints) is necessary, the algorithm has been implemented in two platforms: OpenMP and GPU. Several tests have been conducted on seven popular image sequences and the results show a considerable improvement of the proposed solutions, in particular the Graphic Processing Units implementations. Consequently, it can be stated that GPUs represent an efficient solution to accelerate this type of algorithms to improve the perception of the image quality.},
  doi      = {10.1109/TCE.2017.015077},
  keywords = {cameras;coprocessors;graphics processing units;image enhancement;image matching;image resolution;image sequences;video signal processing;OpenMP;block matching;computational acceleration;computational imaging;fixed dimensions;fusion SR techniques;graphic processing unit implementations;image enhancement;image quality;image sequences;macro blocks;single camera;super-resolution parallel GPU implementation;video enhancement;Algorithm design and analysis;Cameras;Graphics processing units;Signal resolution;Spatial resolution;Image enhancement;Super-Resolution;motion estimation;parallelization},
}

@Article{Luo2018p1555-1566,
  author   = {Y. Luo and D. Ho and S. Mirabbasi},
  title    = {Exposure-Programmable CMOS Pixel With Selective Charge Storage and Code Memory for Computational Imaging},
  journal  = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  year     = {2018},
  volume   = {65},
  number   = {5},
  pages    = {1555-1566},
  month    = {May},
  issn     = {1549-8328},
  abstract = {Computational imaging, as a rapid emerging field, enables unprecedented photographic capability through the encoding of visual information. Currently, as exposure programming is not support by image sensors, computational cameras use off-chip components to accomplish exposure/encoding optical computations. In this paper, we present a complementary metal-oxide-semiconductor (CMOS) pixel structure with exposure encoding capabilities that enable on-chip computational imaging. As a proof-of-concept, a 10 × 10-pixel prototype chip is fabricated in a 0.13-μm 8-metal 1-poly CMOS process with shared pixel output wires and two 3.3-V power supplies. Each computational pixel is 12.1 μm × 12.2 μm with a fill factor of 33.2%. Measurement results confirm that at a frame rate of 60 f/s, the proposed pixel is capable of performing both temporal and spatial exposure encoding. The proposed pixel design paves a promising path to achieve on-chip temporal-spatial exposure encoding directly on the sensor focal plane for computational imaging.},
  doi      = {10.1109/TCSI.2017.2763822},
  keywords = {CMOS image sensors;focal planes;image coding;image resolution;microprocessor chips;0.13-μm 8-metal 1-poly CMOS process;10 × 10-pixel prototype chip;code memory;complementary metal-oxide-semiconductor pixel structure;computational cameras;computational pixel;encoding optical computations;exposure encoding capabilities;exposure optical computations;exposure programming;exposure-programmable CMOS pixel;image sensors;off-chip components;on-chip computational imaging;on-chip temporal-spatial exposure encoding;selective charge storage;sensor focal plane;shared pixel output wires;unprecedented photographic capability;visual information encoding;Cameras;Capacitors;Encoding;Image coding;Photodiodes;CMOS image sensor (CIS);Computational imaging;capacitive transimpedance amplifier (CTIA);coded exposure},
}

@Article{Zvolensky2017p9911-9918,
  author   = {T. Zvolensky and J. N. Gollub and D. L. Marks and D. R. Smith},
  title    = {Design and Analysis of a W-Band Metasurface-Based Computational Imaging System},
  journal  = {IEEE Access},
  year     = {2017},
  volume   = {5},
  pages    = {9911-9918},
  abstract = {We design and numerically analyze a coherent computational imaging system that utilizes a sparse detector array of planar, frequency-diverse, metasurface antennas designed to operate over the W-band frequency range (75-110 GHz). Each of the metasurface antennas consists of a parallel plate waveguide, into which a center coaxial feed is inserted into the lower plate, launching a cylindrical guided wave. A dense array of metamaterial resonators patterned into the upper plate couples energy from the waveguide to free space radiative modes. The resonance frequency of each element, determined by its specific geometry, can be positioned anywhere within the W-band. The geometry of each element is chosen to produce a resonance frequency selected randomly from the W-band. Since a random subset of elements is resonant at any given frequency, the metasurface antenna forms a sequence of spatially diverse radiation patterns as a function of the excitation frequency. We analyze the metasurface aperture as an imaging system, optimizing key parameters relevant to image quality and resolution, including: aperture size; density and quality factor of the metamaterial resonators; number of detectors and their spatial distribution; bandwidth; and the number of frequency samples. A point-spread function analysis is used to compare the metasurface imager with traditional synthetic aperture radar. The singular value spectrum corresponding to the system transfer function and the mean-square-error associated with reconstructed images are both metrics used to characterize the system performance.},
  doi      = {10.1109/ACCESS.2017.2703860},
  keywords = {microwave metamaterials;millimetre wave antenna arrays;millimetre wave resonators;W-band metasurface-based computational imaging system;center coaxial feed;cylindrical guided wave;diverse radiation patterns;frequency 75 GHz to 110 GHz;metamaterial resonators;parallel plate waveguide;planar frequency-diverse metasurface antennas;point-spread function analysis;reconstructed images;singular value spectrum;sparse detector array;system transfer function;Antenna radiation patterns;Apertures;Image reconstruction;Image resolution;Imaging;Metamaterials;Resonant frequency;Computational imaging;metamaterials;metasurface;millimeter-waves;sparse antenna array},
}

@Article{Huang2016p130-138,
  author   = {X. Huang and E. Uffelman and O. Cossairt and M. Walton and A. K. Katsaggelos},
  title    = {Computational Imaging for Cultural Heritage: Recent developments in spectral imaging, 3-D surface measurement, image relighting, and X-ray mapping},
  journal  = {IEEE Signal Processing Magazine},
  year     = {2016},
  volume   = {33},
  number   = {5},
  pages    = {130-138},
  month    = {Sept},
  issn     = {1053-5888},
  abstract = {Because art is inherently visual, the use of imaging has long been an important way to understand its structure, form, and history. Recently, new ways of engaging with objects from our shared cultural heritage are possible with advances in computation and imaging that allow scientists to analyze art noninvasively, historians to pose new social questions about the art, and the public to explore and interact with art in ways never before possible. There is a rich history in applying image processing techniques to conventional photographic images of works of art, many of which have been highlighted in previous special issues of IEEE Signal Processing Magazine (e.g., the 2008 and 2015 July issues). Building on these contributions, this article comprises a survey of techniques where computation is central to the image acquisition process. Known as computational imaging, the methods being pioneered in this field are increasingly relevant to cultural heritage applications because they leverage advances in image processing, acquisition, and display technologies that make scientific data readily comprehensible to a broad cohort of nontechnical researchers interested in understanding the visual content of art. Presently, only a small research community undertakes computational imaging of cultural heritage. Here we aim to introduce this growing new field to a larger research community by discussing: 1) the historic background of imaging of art, 2) the burgeoning present day community of researchers interested in computational imaging in the arts, and finally, 3) our vision for the future of this new field.},
  doi      = {10.1109/MSP.2016.2581847},
  keywords = {X-ray imaging;history;image processing;image sensors;photography;surface topography measurement;3D surface measurement;X-ray mapping;art works;computational imaging;cultural heritage;image processing techniques;image relighting;imaging historic background;photographic images;spectral imaging;Art;Cultural differences;Hyperspectral imaging;Imaging;Surface treatment;X-ray imaging},
}

@Article{Yurduseven2016p2488-2497,
  author   = {O. Yurduseven and J. N. Gollub and K. P. Trofatter and D. L. Marks and A. Rose and D. R. Smith},
  title    = {Software Calibration of a Frequency-Diverse, Multistatic, Computational Imaging System},
  journal  = {IEEE Access},
  year     = {2016},
  volume   = {4},
  pages    = {2488-2497},
  abstract = {We demonstrate a technique for calibrating a frequency-diverse, multistatic, computational imaging system. A frequency-diverse aperture enables an image to be reconstructed primarily from a set of scattered field measurements taken over a band of frequencies, avoiding mechanical scanning and active components. Since computational imaging systems crucially rely on the accuracy of a forward model that relates the measured and transmitted fields, deviations of the actual system from that model will rapidly degrade imaging performance. Here, we study the performance of a computational imaging system at microwave frequencies based on a set of frequency-diverse aperture antennas, or panels. We propose a calibration scheme that compares the measured versus simulated scattered field from a cylinder and calculates a compensating phase difference to be applied at each of the panels comprising the system. The calibration of the entire system needs be performed only once, avoiding a more laborious manual calibration step for each transmitting and receiving path. Imaging measurements performed using the system confirm the efficacy and importance of the calibration step.},
  doi      = {10.1109/ACCESS.2016.2570678},
  keywords = {aperture antennas;image reconstruction;active component;forward model accuracy;frequency-diverse aperture antennas;frequency-diverse multistatic computational imaging system;image reconstruction;imaging measurement;measured field;mechanical scanning;microwave frequency;phase difference;receiving path;scattered field measurement;simulated scattered field;software calibration;transmitted field;transmitting path;Antenna measurements;Calibration;Computational modeling;Frequency measurement;Image processing;Image reconstruction;Near field communication;Software development;Frequency-diversity;calibration;computational imaging;near-field;software},
}

@Article{Zilly2016p42-47,
  author   = {F. Zilly and M. Ziegler and J. Keinert and M. Schoberl and S. Foessel},
  title    = {Computational Imaging for Stop-Motion Animated Video Productions},
  journal  = {SMPTE Motion Imaging Journal},
  year     = {2016},
  volume   = {125},
  number   = {1},
  pages    = {42-47},
  month    = {January},
  issn     = {1545-0279},
  abstract = {Creating movies using stop-motion technology remains a fascinating approach for storytelling even in the era of digital cinema. A huge number of professional and semiprofessional clips that were produced as fan art can be watched on Internet video platforms and serve as testimonial for the unbroken interest in unleashing creative potential using this technology. However, producing content using stop motion remains a cumbersome task that raises production costs, especially for full-length movies. Consequently, a trend can be observed even for successful television series that were originally produced using stop motion in which the production scheme was changed to computer animation. Against this background, we propose a production scheme for stop-motion-animated movies that has the potential to lower the production costs while increasing the quality of the resulting content. By using a static multicamera array and algorithms from the field of computational imaging, our technology allows artistic effects to be created in the post-production that are difficult to realize using conventional stop-motion production methods. Our approach allows changing the depth of field, smoothly moving the camera along virtual camera paths, and upsampling the frame rate of the stop-motion video in high quality. All effects are computed and applied in post-production, while all intrinsic and extrinsic parameters of the cameras remain static during the whole production. To demonstrate the practicability, results are shown from a stop-motion video that has been produced using the proposed approach.},
  doi      = {10.5594/j18663},
}

@Article{Mitra2014p1909-1921,
  author   = {K. Mitra and O. S. Cossairt and A. Veeraraghavan},
  title    = {A Framework for Analysis of Computational Imaging Systems: Role of Signal Prior, Sensor Noise and Multiplexing},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2014},
  volume   = {36},
  number   = {10},
  pages    = {1909-1921},
  month    = {Oct},
  issn     = {0162-8828},
  abstract = {Over the last decade, a number of computational imaging (CI) systems have been proposed for tasks such as motion deblurring, defocus deblurring and multispectral imaging. These techniques increase the amount of light reaching the sensor via multiplexing and then undo the deleterious effects of multiplexing by appropriate reconstruction algorithms. Given the widespread appeal and the considerable enthusiasm generated by these techniques, a detailed performance analysis of the benefits conferred by this approach is important. Unfortunately, a detailed analysis of CI has proven to be a challenging problem because performance depends equally on three components: (1) the optical multiplexing, (2) the noise characteristics of the sensor, and (3) the reconstruction algorithm which typically uses signal priors. A few recent papers [12], [30], [49] have performed analysis taking multiplexing and noise characteristics into account. However, analysis of CI systems under state-of-the-art reconstruction algorithms, most of which exploit signal prior models, has proven to be unwieldy. In this paper, we present a comprehensive analysis framework incorporating all three components. In order to perform this analysis, we model the signal priors using a Gaussian Mixture Model (GMM). A GMM prior confers two unique characteristics. First, GMM satisfies the universal approximation property which says that any prior density function can be approximated to any fidelity using a GMM with appropriate number of mixtures. Second, a GMM prior lends itself to analytical tractability allowing us to derive simple expressions for the `minimum mean square error' (MMSE) which we use as a metric to characterize the performance of CI systems. We use our framework to analyze several previously proposed CI techniques (focal sweep, flutter shutter, parabolic exposure, etc.), giving conclusive answer to the question: `How much performance gain is due to use of a signal prior and how much is due to multipl- xing? Our analysis also clearly shows that multiplexing provides significant performance gains above and beyond the gains obtained due to use of signal priors.},
  doi      = {10.1109/TPAMI.2014.2313118},
  keywords = {Gaussian processes;approximation theory;image reconstruction;least mean squares methods;mixture models;multiplexing;GMM;Gaussian mixture model;MMSE;analytical tractability;computational imaging systems;defocus deblurring;flutter shutter;focal sweep;minimum mean square error;motion deblurring;multispectral imaging;noise characteristics;optical multiplexing;parabolic exposure;performance analysis;reconstruction algorithms;sensor noise;signal prior;universal approximation property;Analytical models;Cameras;Gain;Multiplexing;Noise;Photonics;Computational imaging;Gaussian mixture model (GMM);extended depth-of-field (EDOF);motion deblurring},
}

@Article{Cossairt2013p447-458,
  author   = {O. Cossairt and M. Gupta and S. K. Nayar},
  title    = {When Does Computational Imaging Improve Performance?},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2013},
  volume   = {22},
  number   = {2},
  pages    = {447-458},
  month    = {Feb},
  issn     = {1057-7149},
  abstract = {A number of computational imaging techniques are introduced to improve image quality by increasing light throughput. These techniques use optical coding to measure a stronger signal level. However, the performance of these techniques is limited by the decoding step, which amplifies noise. Although it is well understood that optical coding can increase performance at low light levels, little is known about the quantitative performance advantage of computational imaging in general settings. In this paper, we derive the performance bounds for various computational imaging techniques. We then discuss the implications of these bounds for several real-world scenarios (e.g., illumination conditions, scene properties, and sensor noise characteristics). Our results show that computational imaging techniques do not provide a significant performance advantage when imaging with illumination that is brighter than typical daylight. These results can be readily used by practitioners to design the most suitable imaging systems given the application at hand.},
  doi      = {10.1109/TIP.2012.2216538},
  keywords = {decoding;deconvolution;digital photography;image coding;image denoising;image restoration;computational imaging techniques;computational photography;decoding;deconvolution;denoising;image quality improvement;image restoration;noise amplification;optical coding;stronger signal level measurement;Cameras;Lighting;Multiplexing;Performance gain;Signal to noise ratio;Computational imaging;computational photography;deconvolution;defocus deblurring;denoising;extended depth of field;image priors;image restoration;motion deblurring;multiplexing},
}

@Article{Njuguna2012p727-736,
  author   = {R. Njuguna and V. Gruev},
  title    = {Low Power Programmable Current Mode Computational Imaging Sensor},
  journal  = {IEEE Sensors Journal},
  year     = {2012},
  volume   = {12},
  number   = {4},
  pages    = {727-736},
  month    = {April},
  issn     = {1530-437X},
  abstract = {A linear current mode computational image sensor is presented in this paper. The sensor monolithically combines current mode imaging elements with current mode digitally programmable analog computational circuitry at the focal plane. The pixel is based on a switchless paradigm and allows for reduced spatial and temporal noise imaging. The imaging array is composed of 128-by-109 pixels. The image sensor provides a noise-corrected image in conjunction with a convolved image in parallel at 50 fps and 50 mW. The maximum measured SNR is 44 dB, maximum FPN of saturated value (after DDS) is 0.22%, and DR is 55 dB.},
  doi      = {10.1109/JSEN.2011.2158579},
  keywords = {CMOS analogue integrated circuits;CMOS image sensors;focal planes;image denoising;low-power electronics;programmable circuits;sensor arrays;convolved image;current mode digitally programmable analog computational circuit;current mode imaging element;focal plane;imaging array;low power programmable current mode computational imaging sensor;noise figure 44 dB;noise-corrected image;power 50 mW;spatial noise imaging;switchless paradigm;temporal noise imaging;Arrays;Image processing;Imaging;Kernel;Photodiodes;Pixel;Transistors;Analog computation;CMOS image sensors;current mode;linear response;low power sensors},
}

@Article{Wang2011p1033-1043,
  author   = {L. Wang and K. C. L. Wong and H. Zhang and H. Liu and P. Shi},
  title    = {Noninvasive Computational Imaging of Cardiac Electrophysiology for 3-D Infarct},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2011},
  volume   = {58},
  number   = {4},
  pages    = {1033-1043},
  month    = {April},
  issn     = {0018-9294},
  abstract = {Myocardial infarction (MI) creates electrophysiologically altered substrates that are responsible for ventricular ar rhythmias, such as tachycardia and fibrillation. The presence, size, location, and composition of infarct scar bear significant prognostic and therapeutic implications for individual subjects. We have developed a statistical physiological model-constrained framework that uses noninvasive body-surface-potential data and tomographic images to estimate subject-specific transmembrane potential (TMP) dynamics inside the 3-D myocardium. In this paper, we adapt this framework for the purpose of noninvasive imaging, detection, and quantification of 3-D scar mass for postMI patients: the framework requires no prior knowledge of MI and converges to final subject-specific TMP estimates after several passes of estimation with intermediate feedback; based on the primary features of the estimated spatiotemporal TMP dynamics, we provide 3-D imaging of scar tissue and quantitative evaluation of scar location and extent. Phantom experiments were performed on a computational model of realistic heart-torso geometry, considering 87 transmural infarct scars of different sizes and locations inside the myocardium, and 12 compact infarct scars (extent between 10% and 30%) at different transmural depths. Real data experiments were carried out on BSP and magnetic resonance imaging (MRI) data from four postMI patients, validated by gold standards and existing results. This framework shows unique advantage of noninvasive, quantitative, computational imaging of subject-specific TMP dynamics and infarct mass of the 3-D myocardium, with the potential to reflect details in the spatial structure and tissue composition/heterogeneity of 3-D infarct scar.},
  doi      = {10.1109/TBME.2010.2099226},
  keywords = {bioelectric potentials;biomedical MRI;biomembranes;cardiology;diseases;medical disorders;medical image processing;phantoms;3D infarct;3D myocardium;3D scar mass;BSP;cardiac electrophysiology;fibrillation;magnetic resonance imaging;myocardial infarction;noninvasive body surface potential data;noninvasive computational imaging;noninvasive imaging;phantom experiments;postMI patients;spatiotemporal TMP dynamics;statistical physiological model;subject-specific TMP estimates;subject-specific transmembrane potential;tachycardia;tomographic images;ventricular arrhythmias;Computational modeling;Electric potential;Estimation;Imaging;Myocardium;Three dimensional displays;Torso;Body surface potential (BSP);cardiac electrophysiological imaging;myocardial infarction (MI);transmembrane potential (TMP);Algorithms;Body Surface Potential Mapping;Computer Simulation;Heart Conduction System;Heart Ventricles;Humans;Imaging, Three-Dimensional;Models, Cardiovascular;Reproducibility of Results;Sensitivity and Specificity},
}

@Article{Aeron2017p144-145,
  author   = {S. Aeron and E. L. Miller and M. Crawford and A. Malcom and A. Reigber and J. Chanussot},
  title    = {Guest Editorial Computational Imaging for Earth Sciences},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {144-145},
  month    = {June},
  issn     = {2333-9403},
  abstract = {The papers in this special section focused on computational imaging for the earth sciences market. From the core of the earth to the farthest reaches of our planets magnetic ﬁelds, the earth sciences are concerned with all aspects of monitoring, exploring, explaining, and exploiting of natural events and resources in the geosphere. Revolutions in computational imaging over the past two decades have had profound implications across this ﬁeld, bringing new modalities into common use and impacting application domains from weather monitoring and prediction, subsurface sensing, seismic imaging and exploration, to the production of minerals, oil and gas. In all these areas, reliable information extraction by collecting and processing sensor data increasingly hinges on integrated sensor design, system modeling, and efﬁcient computational methods. The scope of such models and methods have more recently integrated statistical pattern recognition nd machine learning systems to account for variability that cannot be completely captured by physical models or simulation. Enabling most all of these processing methods are concomitant developments in optimization theory both in Euclidean spaces as well as on more general manifolds. This special issue solicited relevant contributions from researchers in signal and image processing, inverse problems, machine learning, and related areas as applied to problems of image formation and analysis arising in the context of earth science applications covering the wide range of application domains.},
  doi      = {10.1109/TCI.2017.2694978},
  keywords = {Computational modeling;Earth;Imaging;Magnetic cores;Magnetic domains;Special issues and sections},
}

@Article{Nguyen2018p241-256,
  author   = {H. N. Nguyen and V. Paveau and C. Cauchois and C. Kervrann},
  title    = {A Variational Method for Dejittering Large Fluorescence Line Scanner Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {2},
  pages    = {241-256},
  month    = {June},
  abstract = {We propose a variational method dedicated to jitter correction of large fluorescence scanner images. Our method consists in minimizing a global energy functional to estimate a dense displacement field representing the spatially-varying jitter. The computational approach is based on a half-quadratic splitting of the energy functional, which decouples the realignment data term and the dedicated differential-based regularizer. The resulting problem amounts to alternatively solving two convex and nonconvex optimization subproblems with appropriate algorithms. Experimental results on artificial and large real fluorescence images demonstrate that our method is not only capable to handle large displacements but is also efficient in terms of subpixel precision without inducing additional intensity artifacts.},
  doi      = {10.1109/TCI.2018.2818017},
  keywords = {concave programming;fluorescence;image restoration;jitter;differential-based regularizer;fluorescence line scanner image dejittering;fluorescence scanner images;half-quadratic splitting;image reconstruction;image restoration;jitter correction;nonconvex optimization subproblems;realignment data term;spatially-varying jitter;Estimation;Image resolution;Image restoration;Imaging;Jitter;Optimization;Synchronization;Dejittering;fluorescence scanner;optimization;proximal algorithm;quadratic relaxation;regularization;variational method},
}

@Article{Liu2018p219-227,
  author   = {Z. Liu and D. Lesselier and Y. Zhong},
  title    = {Electromagnetic Imaging of Damages in Fibered Layered Laminates via Equivalence Theory},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {2},
  pages    = {219-227},
  month    = {June},
  abstract = {Electromagnetic nondestructive testing of damaged multilayer fiber-reinforced laminates is of concern. Each layer involves periodically positioned circular cylindrical fibers embedded within a matrix medium. Missing, displaced, shrunk, expanded fibers as well as circular inclusions inside a fiber are modeled as properly designed equivalent sources inside the undamaged structure. Then, the location of damages is retrieved via simply searching for such equivalent sources. A sparsity-constrained solution as well as classical algorithms including truncated singular value decomposition, multiple signal classification, and basic matching pursuit are considered, and their pros and cons are illustrated by numerical results in various configurations.},
  doi      = {10.1109/TCI.2018.2814821},
  keywords = {fibre reinforced composites;inclusions;iterative methods;laminates;materials science computing;nondestructive testing;signal classification;singular value decomposition;basic matching pursuit;circular cylindrical fibers;circular inclusions;damaged multilayer fiber;electromagnetic imaging;electromagnetic nondestructive testing;equivalence theory;expanded fibers;fibered layered laminates;signal classification;singular value decomposition;sparsity-constrained solution;Imaging;Laminates;Matching pursuit algorithms;Multiple signal classification;Receivers;Scattering;Singular value decomposition;Electromagnetic nondestructive testing;basic matching pursuit;computational modeling;imaging;inverse source problem;multiple signal classification;periodic fibered laminates;singular value decomposition;sparsity, rank3},
}

@Article{Latham2018p271-283,
  author   = {S. J. Latham and A. M. Kingston and B. Recur and G. R. Myers and O. Delgado-Friedrichs and A. P. Sheppard},
  title    = {Reprojection Alignment for Trajectory Perturbation Estimation in Microtomography},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {2},
  pages    = {271-283},
  month    = {June},
  abstract = {For standard laboratory microtomography systems, acquired radiographs do not always adhere to the strict geometrical assumptions of the reconstruction algorithm. The consequence of this geometrical inconsistency is that the reconstructed tomogram contains motion artifacts, e.g., blurring, streaking, double-edges. To achieve a motion-artifact-free tomographic reconstruction, one must estimate, and subsequently correct for, the per-radiograph experimental geometry parameters. In this paper, we examine the use of re-projection alignment (RA) to estimate per-radiograph geometry. Our simulations evaluate how the convergence properties of RA vary with: motion-type (smooth versus random), trajectory (helical versus discrete-sampling `space-filling' trajectories) and tomogram resolution. The idealized simulations demonstrate for the space-filling trajectory that RA convergence rate and accuracy is invariant with regard to the motion-type and that the per-projection motions can be estimated to less than 0.25 pixel mean absolute error by performing a single quarter-resolution RA iteration followed by a single half-resolution RA iteration. The direct impact is that, for the space-filling trajectory, one can incorporate RA in an iterative multi-grid reconstruction scheme with only a single RA iteration per multi-grid resolution step. We also find that for either trajectory, slowly varying vertical errors cannot be reliably estimated by employing the RA method alone; such errors are indistinguishable from a trajectory of different pitch. This has minimal effect in practice because RA can be combined with reference frame correction which is effective for correcting low-frequency errors.},
  doi      = {10.1109/TCI.2018.2811945},
  keywords = {computerised tomography;diagnostic radiography;image reconstruction;image resolution;iterative methods;medical image processing;RA method;convergence properties;discrete-sampling;iterative multigrid reconstruction scheme;motion-artifact-free tomographic reconstruction;motion-type;multigrid resolution step;per-projection motions;per-radiograph experimental geometry parameters;per-radiograph geometry;pixel mean absolute error;reconstructed tomogram;reconstruction algorithm;reprojection alignment;single RA iteration;single half-resolution RA iteration;single quarter-resolution RA iteration;space-filling trajectory;standard laboratory microtomography systems;tomogram resolution;trajectory perturbation estimation;Correlation;Geometry;Image reconstruction;Radiography;Tomography;Trajectory;Image quality;X-ray tomography;image reconstruction;motion artifacts;trajectory optimization},
}

@Article{Eldaly2018p194-205,
  author   = {A. K. Eldaly and Y. Altmann and A. Perperidis and N. Krstajić and T. R. Choudhary and K. Dhaliwal and S. McLaughlin},
  title    = {Deconvolution and Restoration of Optical Endomicroscopy Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {2},
  pages    = {194-205},
  month    = {June},
  abstract = {Optical endomicroscopy (OEM) is an emerging technology platform with preclinical and clinical imaging applications. Pulmonary OEM via fibre bundles has the potential to provide in vivo, in situ molecular signatures of disease such as infection and inflammation. However,a enhancing the quality of data acquired by this technique for better visualization and subsequent analysis remains a challenging problem. Cross coupling between fiber cores and sparse sampling by imaging fiber bundles are the main reasons for image degradation, and poor detection performance (i.e., inflammation, bacteria, etc.). In this paper, we address the problem of deconvolution and restoration of OEM data. We propose a hierarchical Bayesian model to solve this problem and compare three estimation algorithms to exploit the resulting joint posterior distribution. The first method is based on Markov chain Monte Carlo methods, however, it exhibits a relatively long computational time. The second and third algorithms deal with this issue and are based on a variational Bayes approach and an alternating direction method of multipliers algorithm, respectively. Results on both synthetic and real datasets illustrate the effectiveness of the proposed methods for restoration of OEM images.},
  doi      = {10.1109/TCI.2018.2811939},
  keywords = {Bayes methods;Markov processes;Monte Carlo methods;biological tissues;biomedical optical imaging;compressed sensing;deconvolution;diseases;endoscopes;image restoration;medical image processing;Markov chain Monte Carlo methods;OEM data;OEM images;alternating direction method;detection performance;fiber bundles;fiber cores;fibre bundles;hierarchical Bayesian model;image degradation;molecular disease signatures;multipliers algorithm;optical endomicroscopy image deconvolution;optical endomicroscopy image restoration;posterior distribution;preclinical imaging applications;pulmonary OEM;sparse sampling;Bayes methods;Couplings;Deconvolution;Image restoration;Optical imaging;Optical endomicroscopy;bayesian models;deconvolution;image restoration;irregular sampling},
}

@Article{Rousset2018p284-294,
  author   = {F. Rousset and F. Peyrin and N. Ducros},
  title    = {A Semi Nonnegative Matrix Factorization Technique for Pattern Generalization in Single-Pixel Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {2},
  pages    = {284-294},
  month    = {June},
  abstract = {A single-pixel camera is a computational imaging device that only requires a single point detector to capture the image of a scene. This device measures the inner product of the scene and the spatial light modulator patterns. The image of the scene can be recovered through postprocessing the measurements obtained for a set of different patterns. Independent of the strategy used for image recovery, real acquisitions require the spatial light modulator patterns to be positive. In addition, the dark current measured in the absence of modulation must be rejected. To date, both experimental issues have been addressed empirically. In this paper, we solve these from a general perspective. Indeed, we propose to seek positive patterns that are linear combinations of the desired patterns (with negative values), and the linear transformation matrices are chosen to reject the dark current. We refer to the problem of finding the positive patterns and the linear combinations as “pattern generalization.” To the best of our knowledge, this is the first time that this problem has been introduced. In addition, we show that pattern generalization can be solved using a semi nonnegative matrix factorization algorithm. The data obtained from simulations demonstrate that our approach performs similarly to or better than conventional methods, while using fewer measurements.},
  doi      = {10.1109/TCI.2018.2811910},
  keywords = {cameras;image resolution;matrix algebra;spatial light modulators;computational imaging device;image recovery;linear transformation matrices;pattern generalization;positive patterns;seminonnegative matrix factorization technique;single point detector;single-pixel camera;single-pixel imaging;spatial light modulator patterns;Cameras;Current measurement;Dark current;Detectors;Modulation;Time measurement;Computational imaging;adaptive acquisition;positivity constraint;semi nonnegative matrix factorization;single-pixel camera;wavelets},
}

@Article{Takala2018p228-240,
  author   = {M. Takala and D. Us and S. Pursiainen},
  title    = {Multigrid-Based Inversion for Volumetric Radar Imaging With Asteroid Interior Reconstruction as a Potential Application},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {2},
  pages    = {228-240},
  month    = {June},
  abstract = {This study concentrates on advancing mathematical and computational methodology for radar tomography imaging in which the unknown volumetric velocity distribution of a wave within a bounded domain is to be reconstructed. Our goal is to enable effective simulation and inversion of a large amount of full-wave data within a realistic 2-D or 3-D geometry. For propagating and inverting the wave, we present a rigorous multigrid-based forward approach that utilizes the finite-difference time-domain method and a nested finite element grid structure. We also introduce and validate a multigrid-based inversion algorithm that allows regularization of the unknown distribution through a coarse-to-fine inversion scheme. Using this approach, sparse signals can be effectively inverted, as the coarse fluctuations are reconstructed before the finer ones. Furthermore, the number of nonzero entries in the system matrix can be compressed and, thus, the inversion procedure can be speeded up. As the test scenario, we investigate satellite-based asteroid interior reconstruction. We use both full-wave and projected wave data and estimate the accuracy of the inversion under different error sources: noise and positioning inaccuracies. The results suggest that the present inversion technique allows recovering the interior with a single satellite recording backscattering data. Robust results can be achieved, when the peak-to-peak signal-to-noise ratio is above 10 dB. Furthermore, the robustness for the deep interior part can be enhanced if two satellites can be utilized in the measurements.},
  doi      = {10.1109/TCI.2018.2811908},
  keywords = {finite difference time-domain analysis;geometry;inverse problems;radar imaging;tomography;3-D geometry;asteroid interior reconstruction;bounded domain;coarse-to-fine inversion scheme;computational methodology;deep interior part;finite-difference time-domain method;full-wave data;inversion technique;mathematical methodology;multigrid-based inversion algorithm;nested finite element grid structure;peak-to-peak signal-to-noise ratio;radar tomography imaging;rigorous multigrid-based forward approach;single satellite recording backscattering data;unknown volumetric velocity distribution;volumetric radar imaging;Computational modeling;Image reconstruction;Permittivity;Radar imaging;Solar system;Tomography;Multigrid methods;asteroids;biomedical imaging;microw-ave tomography;radio tomography},
}

@Article{Blinder2018p206-218,
  author   = {D. Blinder and C. Schretter and H. Ottevaere and A. Munteanu and P. Schelkens},
  title    = {Unitary Transforms Using Time-Frequency Warping for Digital Holograms of Deep Scenes},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {2},
  pages    = {206-218},
  month    = {June},
  abstract = {With the advent of ultrahigh-resolution holographic displays, viewing macroscopic deep scenes with large viewing angles becomes a possibility. These deep holograms possess different signal properties in contrast with common applications where the scene content is assumed to lie around a planar slice. Therefore, the conventional approach of refocusing at a fixed depth is ineffective. There is a need for an efficient invertible transformation that is able to account for the wide depth range of macroscopic three-dimensional scenes. To this end, we derive necessary invertibility conditions for the diffraction from nonplanar surfaces for symmetric light propagation kernels, such as Fresnel diffraction. We construct a unitary transform for modeling deep holographic scenes using a generalization of linear canonical transforms. From the symplectic properties of the time-frequency domain, we obtain invertibility conditions of the transforms depending on surface shape, hologram bandwidth, and wavelength. These transforms can be subsequently combined with other sparsifying transforms for compression. Experiments demonstrate one application in lossy coding of holograms by implementing a computationally efficient subset of the transforms for piecewise depth profiles that is combined with the JPEG 2000 codec. Results show improved reconstruction quality. A significant visual gain is observed as the depth information is well preserved under identical encoding rates in contrast to using Fresnel propagation at a fixed depth. This paper shows that it is possible to effectively represent holograms of variable-depth scenes and our local adaptive transform leads to a practical holographic compression framework.},
  doi      = {10.1109/TCI.2018.2813167},
  keywords = {data compression;holography;image coding;image reconstruction;image representation;transforms;Fresnel diffraction;Fresnel propagation;depth information;digital holograms;efficient invertible transformation;hologram bandwidth;linear canonical transforms;macroscopic deep scenes;nonplanar surfaces;practical holographic compression framework;symmetric light propagation kernels;symplectic properties;three-dimensional scenes;time-frequency domain;time-frequency warping;ultrahigh-resolution holographic displays;unitary transforms;variable-depth scenes;wide depth range;Computational modeling;Diffraction;Encoding;Imaging;Surface waves;Wavelet transforms;Computer Graphics;Holography;Transform Coding;Transforms},
}

@Article{Li2018p257-270,
  author   = {Y. Li},
  title    = {Optimization for Blob-Based Image Reconstruction With Generalized Kaiser #x2013;Bessel Basis Functions},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {2},
  pages    = {257-270},
  month    = {June},
  abstract = {Generalized Kaiser-Bessel radial basis functions are frequently used in tomographic reconstructions, and the parameter selection can significantly impact both the qualitative and quantitative image characteristics. Currently, the blob parameters are simply selected based on the first-order approximation of a uniform object. To obtain optimal images, a detailed investigation and optimization of blob parameters is needed. In this paper, we aim at optimizing the parameters of the basis functions for optimal image representation and image reconstruction. We first represent the unknown radiotracer activity distribution as the coefficients of blob basis functions on a Bravais lattice from crystallography. We point out that the optimal sampling lattice is just the reciprocal of the lattice that achieves highest packing of equally sized spheres. Based on multidimensional sampling theorem and the Kepler conjecture (proven by Thomas C. Hales), we obtain that the body-centered cubic (BCC) and hexagonal close-packing lattices are optimal in terms of either reducing computational cost at similar image quality or improving image quality at the same computational cost. To optimize the blob parameters, we formulate two new image quality metrics-total harmonic distortion (THD) and minimum approximation error (MAE) based on the theory of approximation-to analytically characterize the blob representation errors of a nonzero uniform object and an arbitrary object, respectively. The MAE is formulated in terms of the power spectral density of an imaging object, and we use it for object-dependent blob parameter optimization. We validate the THD and MAE through numerical examples using homogeneous and heterogeneous objects, respectively. We also present 3-D blob-based image reconstructions using BCC lattice with different shape parameters to show the usefulness of the proposed optimization.},
  doi      = {10.1109/TCI.2018.2796302},
  keywords = {approximation theory;computerised tomography;harmonic distortion;image reconstruction;image representation;medical image processing;BCC lattice;Bravais lattice;Generalized Kaiser-Bessel radial basis functions;MAE;blob basis functions;blob parameters;blob representation errors;body-centered cubic;close-packing lattices;hexagonal close-packing lattices;image quality metrics;image reconstruction;imaging object;minimum approximation error;nonzero uniform object;object-dependent blob parameter optimization;optimal image representation;optimal sampling lattice;parameter selection;qualitative image characteristics;quantitative image characteristics;shape parameters;similar image quality;tomographic reconstructions;total harmonic distortion;unknown radiotracer activity distribution;FCC;Image quality;Image reconstruction;Lattices;Optimization;Tomography;Kaiser–Bessel radial basis function;blob;body-centered cubic (BCC) lattice;face-centered cubic (FCC) lattice;lattice;optimization;simple cubic (SC) lattice;tomographic reconstruction},
}

@Article{Seyyedi2018p137-146,
  author   = {S. Seyyedi and M. Wieczorek and F. Pfeiffer and T. Lasser},
  title    = {Incorporating a Noise Reduction Technique Into X-Ray Tensor Tomography},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {137-146},
  month    = {March},
  abstract = {X-ray tensor tomography (XTT) is a novel imaging modality for the three-dimensional reconstruction of X-ray scattering tensors from dark-field images obtained in a grating interferometry setup. The two-dimensional dark-field images measured in XTT are degraded by noise effects, such as detector readout noise and insufficient photon statistics, and consequently, the three-dimensional volumes reconstructed from this data exhibit noise artifacts. In this paper, we investigate the best way to incorporate a denoising technique into the XTT reconstruction pipeline, i.e., the popular total variation denoising technique. We propose two different schemes of including denoising in the reconstruction process, one using a column block-parallel iterative scheme and one using a whole-system approach. In addition, we compare the results when using a simple denoising approach applied either before or after reconstruction. The effectiveness is evaluated qualitatively and quantitatively based on datasets from an industrial sample and a clinical sample. The results clearly demonstrate the superiority of including denoising in the reconstruction process, along with slight advantages of the whole-system approach.},
  doi      = {10.1109/TCI.2018.2794740},
  keywords = {X-ray imaging;X-ray scattering;computerised tomography;image denoising;image reconstruction;iterative methods;tensors;X-ray scattering tensors;X-ray tensor tomography;XTT reconstruction pipeline;column block-parallel iterative scheme;dark-field images;denoising approach;detector readout noise;grating interferometry setup;imaging modality;noise artifacts;noise effects;noise reduction technique;photon statistics;reconstruction process;three-dimensional reconstruction;three-dimensional volumes;total variation denoising technique;whole-system approach;Gratings;Image reconstruction;Imaging;Noise reduction;Scattering;Tensile stress;X-ray imaging;Computed tomography;X-ray diffraction;image denoising;image reconstruction;iterative algorithms},
}

@Article{Ahmaderaghi2018p46-59,
  author   = {B. Ahmaderaghi and F. Kurugollu and J. M. D. Rincon and A. Bouridane},
  title    = {Blind Image Watermark Detection Algorithm Based on Discrete Shearlet Transform Using Statistical Decision Theory},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {46-59},
  month    = {March},
  abstract = {Blind watermarking targets the challenging recovery of the watermark when the host is not available during the detection stage. This paper proposes Discrete Shearlet Transform (DST) as a new embedding domain for blind image watermarking. Our novel DST blind watermark detection system uses a nonadditive scheme based on the statistical decision theory. It first computes the Probability Density Function (PDF) of the DST coefficients modeled as a Laplacian distribution. The resulting likelihood ratio is compared with a decision threshold calculated using Neyman-Pearson criterion to minimize the missed detection subject to a fixed false alarm probability. Our method is evaluated in terms of imperceptibility, robustness, and payload against different attacks (Gaussian noise, blurring, cropping, compression, and rotation) using 30 standard grayscale images covering different characteristics (smooth, more complex with a lot of edges, and high detail textured regions). The proposed method shows greater windowing flexibility with more sensitive to directional and anisotropic features when compared against discrete wavelet and contourlets.},
  doi      = {10.1109/TCI.2018.2794065},
  keywords = {Laplace transforms;blind source separation;decision theory;discrete wavelet transforms;image watermarking;probability;DST blind watermark detection system;Discrete Shearlet Transform;Neyman-Pearson criterion;Probability Density Function;blind image watermark detection algorithm;blind image watermarking;discrete wavelet;statistical decision theory;Discrete Fourier transforms;Discrete cosine transforms;Discrete wavelet transforms;Image edge detection;Robustness;Watermarking;Contourlet transform (CT);Discrete Shearlet Transform (DST);Discrete Wavelet Transform (DWT);digital image watermarking;frequency domain;laplacian distribution},
}

@Article{Mathew2018p147-159,
  author   = {R. S. Mathew and J. S. Paul},
  title    = {Sparsity Promoting Adaptive Regularization for Compressed Sensing Parallel MRI},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {147-159},
  month    = {March},
  abstract = {Low sampling density and reduced signal-to-noise ratio resulting from accelerated magnetic resonance data acquisition calls for sparsity promoting regularization for improved reconstruction. The simplest optimization strategy relies on thresholded Landweber algorithm that results in reconstructions with slow rate of convergence. A varying threshold can accelerate the rate of convergence, but does not guarantee low steady-state errors. In this paper, we propose a statistical approach to optimize the tradeoff between steady-state reconstruction error and speed of convergence, by iteratively adapting the regularization parameter. Analogous to the generalized discrepancy principle that implicates the nonnegativity of discrepancy level (absolute difference between l2-norms of consistency and perturbation errors) as provided by regularized reconstruction, the proposed method of adaptation entails reduction of the discrepancy level in l1-norm of the consistency and sparse approximation errors. In discrete form, this is deduced from the convergence properties of Landweber updates soft thresholded using monotonically decreasing thresholds. With very large number of iterations, the thresholds approach a lower bound determined by the noise level and adaptation function. Further improvements in image quality can be achieved by separately adapting the thresholds in each wavelet subband. Application of adaptive regularization combined with over-relaxation to parallel MRI shows significant improvements in both speed and image quality.},
  doi      = {10.1109/TCI.2017.2787911},
  keywords = {biomedical MRI;compressed sensing;data acquisition;image reconstruction;image sampling;image segmentation;medical image processing;optimisation;statistical analysis;Landweber updates;Sparsity promoting adaptive regularization;accelerated magnetic resonance data acquisition;compressed sensing;convergence properties;discrepancy level;generalized discrepancy principle;image quality;l2-norms;low sampling density;noise level;parallel MRI;perturbation errors;reduced signal-to-noise ratio;regularization parameter;regularized reconstruction;simplest optimization strategy;sparse approximation errors;statistical approach;steady-state reconstruction error;thresholded Landweber algorithm;Convergence;Image reconstruction;Steady-state;Wavelet coefficients;Consistency error;discrepancy level;generalized discrepancy principle (GDP);sparse approximation error;thresholded Landweber (TL)},
}

@Article{Ma2018p60-72,
  author   = {K. Ma and Z. Duanmu and H. Yeganeh and Z. Wang},
  title    = {Multi-Exposure Image Fusion by Optimizing A Structural Similarity Index},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {60-72},
  month    = {March},
  abstract = {We propose a multi-exposure image fusion (MEF) algorithm by optimizing a novel objective quality measure, namely the color MEF structural similarity (MEF-SSIMc) index. The design philosophy we introduce here is substantially different from existing ones. Instead of pre-defining a systematic computational structure for MEF (e.g., multiresolution transformation and transform domain fusion followed by image reconstruction), we directly operate in the space of all images, searching for the image that optimizes MEF-SSIMc. Specifically, we first construct the MEF-SSIMc index by improving upon and expanding the application scope of the existing MEF-SSIM algorithm. We then describe a gradient ascent-based algorithm, which starts from any initial point in the space of all possible images and iteratively moves towards the direction that improves MEF-SSIMc until convergence. Numerical and subjective experiments demonstrate that the proposed algorithm consistently produces better quality fused images both visually and in terms of MEF-SSIMc. The final high quality fused image appears to have little dependence on the initial image. The proposed optimization framework is readily extensible to construct better MEF algorithms when better objective quality models for MEF are available.},
  doi      = {10.1109/TCI.2017.2786138},
  keywords = {gradient methods;image colour analysis;image enhancement;image fusion;MEF algorithms;MEF-SSIMc;color MEF structural similarity index;final high quality fused image;gradient ascent-based algorithm;multi-exposure image fusion algorithm;objective quality measure;optimization framework;optimizes MEF-SSIM;Algorithm design and analysis;Heuristic algorithms;Image color analysis;Image fusion;Imaging;Indexes;Optimization;Multi-exposure image fusion (MEF);gradient ascent;perceptual optimization;structural similarity (SSIM)},
}

@Article{Shu2018p172-180,
  author   = {X. Shu and X. Wu},
  title    = {Real-Time High-Fidelity Compression for Extremely High Frame Rate Video Cameras},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {172-180},
  month    = {March},
  abstract = {The single most debilitating bottleneck for sustained capturing of ultrahigh speed high-resolution video is the limited bandwidth of the on-camera mass storage device. We propose a novel downsampling-based real-time compression algorithms together with a suited camera architecture to overcome the bandwidth problem. The encoder generates and embeds into the compression code stream some useful side information to assist the decompression at the decoder end. The fidelity of recovered videos is made scalable to the decoder complexity, ranging from real-time decoding for instant playback at lesser quality to offline high-quality reconstruction by sophisticated sparsity and learning-based recovery algorithms, which are aided by the side information.},
  doi      = {10.1109/TCI.2017.2783686},
  keywords = {data compression;decoding;image reconstruction;image resolution;video cameras;video codecs;video coding;camera architecture;compression code;decoder complexity;downsampling;extremely high frame rate video cameras;high-quality reconstruction;learning-based recovery algorithms;on-camera mass storage device;real-time compression algorithms;real-time high-fidelity compression;ultrahigh speed high-resolution video;Bandwidth;Decoding;Image coding;Image sensors;Streaming media;Throughput;High frame rate video;image/video compression;real-time imaging},
}

@Article{Wacks2018p125-136,
  author   = {S. Wacks and B. Yazıcı},
  title    = {Doppler-DPCA and Doppler-ATI: Novel SAR Modalities for Imaging of Moving Targets Using Ultra-Narrowband Waveforms},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {125-136},
  month    = {March},
  abstract = {This paper introduces two novel imaging modalities: Doppler displaced phase center antenna (Doppler-DPCA) and Doppler along track interferometry (Doppler-ATI). The DPCA and ATI techniques have the distinct advantage of removing the response from stationary targets (clutter). We develop DPCA and ATI techniques in Doppler synthetic aperture radar (Doppler-SAR) paradigm to image moving targets embedded in clutter. Doppler-SAR uses ultra-narrowband continuous waveforms (UNCW) to reconstruct high-resolution SAR images. We consider a two-channel bistatic configuration with a stationary antenna transmitting UNCW and two receiving antennas moving along an arbitrary trajectory in tandem. We introduced the theory for Doppler-DPCA and Doppler-ATI. We derive an interferometric phase model and develop equations of velocity mapping. While conventional wideband SAR DPCA and ATI use range difference, Doppler-DPCA and Doppler-ATI use high-resolution temporal Doppler difference in imaging of moving targets. We present numerical results to demonstrate our theory. These novel modalities can be used for applications requiring high signal-to-noise ratio, long-range, low-power, and low payload such as microsatellites and uninhabited aerial vehicles; passive imaging using sources of opportunity, such as TV and radio stations; and in applications requiring spectrum efficiency.},
  doi      = {10.1109/TCI.2017.2782639},
  keywords = {Doppler radar;image reconstruction;image resolution;radar antennas;radar clutter;radar imaging;radar interferometry;receiving antennas;synthetic aperture radar;Doppler along track interferometry;Doppler displaced phase center antenna;Doppler synthetic aperture radar paradigm;Doppler-ATI;Doppler-DPCA;Doppler-SAR;UNCW;high-resolution SAR images;high-resolution temporal Doppler difference;image moving targets;imaging modalities;phase center antenna;receiving antennas;ultra-narrowband continuous waveforms;Doppler effect;Imaging;Mathematical model;Radar imaging;Receiving antennas;Synthetic aperture radar;Wideband;Moving target imaging;along track interferometry;displaced phase center antenna;synthetic aperture radar;ultranarrow band waveforms, rank3},
}

@Article{Elgendy2018p99-111,
  author   = {O. A. Elgendy and S. H. Chan},
  title    = {Optimal Threshold Design for Quanta Image Sensor},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {99-111},
  month    = {March},
  abstract = {Quanta image sensor is a binary imaging device envisioned to be the next generation image sensor after CCD and CMOS. Equipped with a massive number of single photon detectors, the sensor has a threshold q above which the number of arriving photons will trigger a binary response “1”, or “0” otherwise. Existing methods in the device literature typically assume that q = 1 uniformly. We argue that a spatial-temporally varying threshold can significantly improve the signal-to-noise ratio of the reconstructed image. In this paper, we present an optimal threshold design framework. We make two contributions. First, we derive a set of oracle results to theoretically inform the maximally achievable performance. We show that the oracle threshold should match exactly with the underlying pixel intensity. Second, we show that around the oracle threshold there exists a set of thresholds that give asymptotically unbiased reconstructions. The asymptotic unbiasedness has a phase transition behavior which allows us to develop a practical threshold update scheme using a bisection method. Experimentally, the new threshold design method achieves better rate of convergence than existing methods.},
  doi      = {10.1109/TCI.2017.2781185},
  keywords = {CCD image sensors;CMOS image sensors;image reconstruction;image resolution;CCD;CMOS;arriving photons;binary imaging device;binary response;bisection method;device literature;next generation image sensor;optimal threshold design framework;oracle threshold;pixel intensity;quanta image sensor;reconstructed image;signal-to-noise ratio;single photon detectors;threshold design method;Detectors;Dynamic range;Image reconstruction;Image sensors;Photonics;Prototypes;Quanta image sensor (QIS);binary quantization;high dynamic range;maximum likelihood;single-photon imaging},
}

@Article{Thouvenin2018p32-45,
  author   = {P. A. Thouvenin and N. Dobigeon and J. Y. Tourneret},
  title    = {A Hierarchical Bayesian Model Accounting for Endmember Variability and Abrupt Spectral Changes to Unmix Multitemporal Hyperspectral Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {32-45},
  month    = {March},
  abstract = {Hyperspectral unmixing is a blind source separation problem that consists in estimating the reference spectral signatures contained in a hyperspectral image, as well as their relative contribution to each pixel according to a given mixture model. In practice, the process is further complexified by the inherent spectral variability of the observed scene and the possible presence of outliers. More specifically, multitemporal hyperspectral images, i.e., sequences of hyperspectral images acquired over the same area at different time instants, are likely to simultaneously exhibit moderate endmember variability and abrupt spectral changes either due to outliers or to significant time intervals between consecutive acquisitions. Unless properly accounted for, these two perturbations can significantly affect the unmixing process. In this context, we propose a new unmixing model for multitemporal hyperspectral images accounting for smooth temporal variations, construed as spectral variability, and abrupt spectral changes interpreted as outliers. The proposed hierarchical Bayesian model is inferred using a Markov chain Monte Carlo method allowing the posterior of interest to be sampled and Bayesian estimators to be approximated. A comparison with unmixing techniques from the literature on synthetic and real data allows the interest of the proposed approach to be appreciated.},
  doi      = {10.1109/TCI.2017.2777484},
  keywords = {Bayes methods;Markov processes;Monte Carlo methods;hyperspectral imaging;image processing;remote sensing;spectral analysis;Bayesian estimators;Markov chain Monte Carlo method;blind source separation problem;hierarchical Bayesian model accounting;hyperspectral image;hyperspectral unmixing;mixture model;moderate endmember variability;multitemporal hyperspectral images;reference spectral signatures;spectral variability;unmixing model;Bayes methods;Hyperspectral imaging;Imaging;Markov processes;Mixture models;Monte Carlo methods;Hyperspectral imagery;Markov chain Monte-Carlo (MCMC) methods;endmember variability;multitemporal images},
}

@Article{Godaliyadda2018p1-16,
  author   = {G. M. D. P. Godaliyadda and D. H. Ye and M. D. Uchic and M. A. Groeber and G. T. Buzzard and C. A. Bouman},
  title    = {A Framework for Dynamic Image Sampling Based on Supervised Learning},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {1-16},
  month    = {March},
  abstract = {Sparse sampling schemes can broadly be classified into two main categories: static sampling where the sampling pattern is predetermined, and dynamic sampling where each new measurement location is selected based on information obtained from previous measurements. Dynamic sampling methods are particularly appropriate for pointwise imaging methods, in which pixels are measured sequentially in arbitrary order. Examples of pointwise imaging schemes include certain implementations of atomic force microscopy, electron back scatter diffraction, and synchrotron X-ray imaging. In these pointwise imaging applications, dynamic sparse sampling methods have the potential to dramatically reduce the number of measurements required to achieve a desired level of fidelity. However, the existing dynamic sampling methods tend to be computationally expensive and are, therefore, too slow for many practical applications. In this paper, we present a framework for dynamic sampling based on machine learning techniques, which we call a supervised learning approach for dynamic sampling (SLADS). In each step of SLADS, the objective is to find the pixel that maximizes the expected reduction in distortion (ERD) given previous measurements. SLADS is fast because we use a simple regression function to compute the ERD, and it is accurate because the regression function is trained using datasets that are representative of the specific application. In addition, we introduce an approximate method to terminate dynamic sampling at a desired level of distortion. We then extend our algorithm to incorporate multiple measurements at each step, which we call groupwise SLADS. Finally, we present results on computationally generated synthetic data and experimentally collected data to demonstrate a dramatic improvement over state-of-the-art static sampling methods},
  doi      = {10.1109/TCI.2017.2777482},
  keywords = {image reconstruction;image sampling;learning (artificial intelligence);dynamic image sampling;dynamic sparse sampling methods;pointwise imaging applications;pointwise imaging methods;pointwise imaging schemes;sampling pattern;sparse sampling schemes;static sampling methods;synchrotron X-ray imaging;Distortion;Distortion measurement;Heuristic algorithms;Image reconstruction;Imaging;Sampling methods;Supervised learning;Dynamic sampling;adaptive sampling;electron microscopy;smart sampling;sparse sampling;spectroscopy},
}

@Article{Yoon2018p112-124,
  author   = {S. Yoon and S. A. Mäkiharju and J. A. Fessler and S. L. Ceccio},
  title    = {Image Reconstruction for Limited-Angle Electron Beam X-Ray Computed Tomography With Energy-Integrating Detectors for Multiphase Flows},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {112-124},
  month    = {March},
  abstract = {We propose a new iterative X-ray computed tomography (CT) reconstruction algorithm for electron beam X-ray tomography of multiphase flows in metal pipes. This application uses limited-angle projections due to the fixed configuration, and semiconductor-type energy-integrating detectors. For the data-fitting objective function, the proposed method incorporates a nonlinear Gaussian model with object-dependent variance to approximate the compound Poisson distribution, and a dual material decomposition based on images of the volume fractions of metal (titanium) and liquid (water). The volume fraction-based material decomposition enables us to use a maximum sum constraint that helps address the ill-posed nature of the problem. Two different regularizers, ℓ0 norm and edge-preserving hyperbola regularizers, are applied differently on each volume fraction image based on the characteristics of objects in each image. A synthetic phantom simulation illustrates that the proposed algorithm enables the aforementioned CT system to achieve high quality images by minimizing artifacts induced by limited-angle data and beam hardening.},
  doi      = {10.1109/TCI.2017.2775603},
  keywords = {Poisson distribution;computerised tomography;image reconstruction;iterative methods;medical image processing;multiphase flow;phantoms;Poisson distribution;beam hardening;data-fitting objective function;dual material decomposition;edge-preserving hyperbola regularizers;image reconstruction;iterative X-ray computed tomography reconstruction algorithm;limited-angle data;limited-angle electron beam X-ray computed tomography;limited-angle projections;metal pipes;multiphase flows;nonlinear Gaussian model;object-dependent variance;semiconductor-type energy-integrating detectors;synthetic phantom simulation;Compounds;Computed tomography;Detectors;Electron beams;Photonics;Reconstruction algorithms;X-ray imaging;Electron beam X-ray tomography (EBXT);compound Poisson distribution;limited-angle tomography;statistical reconstruction},
}

@Article{Neut2018p160-171,
  author   = {J. van der Neut and J. Brackenhoff and M. Staring and L. Zhang and S. de Ridder and E. Slob and K. Wapenaar},
  title    = {Single- and Double-Sided Marchenko Imaging Conditions in Acoustic Media},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {160-171},
  month    = {March},
  abstract = {In acoustic reflector imaging, we deploy sources and receivers outside a volume to collect a multisource, multioffset reflection response in order to retrieve the internal reflectivity of that volume. It has been shown that Green's functions inside the volume can be retrieved by single-sided wavefield focusing of the acquired reflection data, using so-called focusing functions, which can be computed by solving a multidimensional Marchenko equation. Besides the reflection data, this methodology requires a background model of the propagation velocity. We present several imaging conditions to retrieve the internal reflectivity of an acoustic medium with correct amplitudes and without artifacts, using the Green's functions and focusing functions that are derived from the Marchenko equation. We distinguish three types of imaging: 1) imaging by deconvolution, 2) imaging by double focusing, and 3) imaging by cross correlation. In all cases, reflectors can be approached either from above or from below. Imaging by deconvolution or double focusing requires single-sided illumination (meaning that sources and receivers are deployed at a single boundary above the volume only), whereas imaging by cross correlation requires double-sided illumination (meaning that sources and receivers are placed at two boundaries enclosing the volume). In order to achieve double-sided illumination, the required reflection response at the lower boundary can either be physically recorded or it can be retrieved from the reflection response at the upper boundary. When imaging by deconvolution or double focusing, the internal reflectivity is retrieved solely from primary reflections. When imaging by cross correlation, multiple reflections are focused at the image points, such that they contribute physically to the retrieved reflectivity values. This special feature can be beneficial for imaging weakly illuminated sections of strongly heterogeneous media.},
  doi      = {10.1109/TCI.2017.2772440},
  keywords = {geophysical image processing;geophysical techniques;seismic waves;seismology;Green's functions;acoustic media;acoustic reflector imaging;deconvolution;double-sided Marchenko imaging conditions;double-sided illumination;multidimensional Marchenko equation;receivers;single-sided Marchenko imaging conditions;single-sided illumination;single-sided wavefield;Acoustics;Deconvolution;Focusing;Green's function methods;Mathematical model;Receivers;Image representation;acoustic signal processing},
}

@Article{Idier2018p87-98,
  author   = {J. Idier and S. Labouesse and M. Allain and P. Liu and S. Bourguignon and A. Sentenac},
  title    = {On the Superresolution Capacity of Imagers Using Unknown Speckle Illuminations},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {87-98},
  month    = {March},
  abstract = {Speckle-based imaging consists of forming a super-resolved reconstruction of an unknown sample from low-resolution images obtained under random inhomogeneous illuminations (speckles). In a blind context, where the illuminations are unknown, we study the intrinsic capacity of speckle-based imagers to recover spatial frequencies outside the frequency support of the data, with minimal assumptions about the sample. We demonstrate that, under physically realistic conditions, the covariance of the data has a super-resolution power corresponding to the squared magnitude of the imager point spread function. This theoretical result is important for many practical imaging systems such as acoustic and electromagnetic tomographs, fluorescence and photoacoustic microscopes, or synthetic aperture radar imaging. A numerical validation is presented in the case of fluorescence microscopy.},
  doi      = {10.1109/TCI.2017.2771729},
  keywords = {image reconstruction;image resolution;speckle;acoustic tomograph;blind context;electromagnetic tomograph;fluorescence microscope;frequency support;imager point spread function;imaging systems;intrinsic capacity;low-resolution images;minimal assumptions;photoacoustic microscope;physically realistic conditions;random inhomogeneous illuminations;spatial frequencies;speckle illuminations;super-resolution power;super-resolved reconstruction;superresolution capacity;synthetic aperture radar imaging;Lighting;Microscopy;Optical microscopy;Spatial resolution;Speckle;Multi-illumination imaging;cutoff frequency;high resolution;optical microscopy;photoacoustic imaging;second-order statistics;synthetic aperture radar, rank3},
}

@Article{Liu2018p73-86,
  author   = {H. Y. Liu and D. Liu and H. Mansour and P. T. Boufounos and L. Waller and U. S. Kamilov},
  title    = {SEAGLE: Sparsity-Driven Image Reconstruction Under Multiple Scattering},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {73-86},
  month    = {March},
  abstract = {Multiple scattering of an electromagnetic wave as it passes through an object is a fundamental problem that limits the performance of current imaging systems. In this paper, we describe a new technique-called Series Expansion with Accelerated Gradient Descent on the Lippmann-Schwinger Equation-for robust imaging under multiple scattering based on a combination of an iterative forward model and a total variation regularizer. The proposed method can account for multiple scattering, which makes it advantageous in applications where single scattering approximations are inaccurate. Specifically, the method relies on a series expansion of the scattered wave with an accelerated-gradient method. This expansion guarantees the convergence of the forward model even for strongly scattering objects. One of our key insights is that it is possible to obtain an explicit formula for computing the gradient of an iterative forward model with respect to the unknown object, thus enabling fast image reconstruction with the state-of-the-art fast iterative shrinkage/thresholding algorithm. The proposed method is validated on diffraction tomography, where complex electric field is captured at different illumination angles.},
  doi      = {10.1109/TCI.2017.2764461},
  keywords = {gradient methods;image reconstruction;iterative methods;Lippmann-Schwinger equation;accelerated-gradient method;diffraction tomography;fast image reconstruction;illumination angles;iterative forward model;iterative shrinkage/thresholding algorithm;multiple scattering;robust imaging;scattered wave;scattering objects;series expansion with accelerated gradient descent;single scattering approximations;Computational modeling;Image reconstruction;Mathematical model;Permittivity;Scattering;Tomography;Diffraction tomography;computational imaging;nonconvex optimization;sparse optimization;total variation, rank3},
}

@Article{Bettens2017p592-604,
  author   = {S. Bettens and C. Schretter and N. Deligiannis and P. Schelkens},
  title    = {Bounds and Conditions for Compressive Digital Holography Using Wavelet Sparsifying Bases},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {592-604},
  month    = {Dec},
  abstract = {Numerous experiments have been conducted with success in the field of compressive digital holography, but the theory to determine optimal measurement conditions is lagging behind. In contrast to a prior study that expects object wavefields to be sparse in the spatial domain, we investigate how the configuration of the interferometer influences the reconstruction of wavefields that are sparse in a multiresolution orthogonal wavelet basis. In particular, we derive expressions for the coherence between the free-space wave propagation operator and the basis functions of a Shannon multiresolution representation as a function of the wavelength, the propagation distance, the image sensor's pixel pitch, and the scale of the basis functions. These expressions reveal that the coherence as a function of the Fresnel number is subject to specific scaling and translating rules as the scale of the basis functions changes. For a multiresolution orthogonal wavelet representation and digital holograms that are recorded in the near field, we deduce subsequently the optimal configuration of the interferometer and we show by means of hypothesis testing that the associated phase transition bound coincides with the weak threshold for block-sparse compressive sensing with a block length of 2, which is an optimal bound for the class of complex-valued compressive sensing problems. By means of experiments with a USAF 1951 resolution target and an angle grid, we validate our findings and demonstrate that the reconstructed object wavefields are resilient to sparsity defects and additive noise.},
  doi      = {10.1109/TCI.2017.2761742},
  keywords = {compressed sensing;holography;image coding;image reconstruction;image resolution;interferometers;wavelet transforms;Fresnel number;Shannon multiresolution representation;block-sparse compressive sensing;compressive digital holography;free-space wave propagation operator;image sensor;interferometer;multiresolution orthogonal wavelet representation;object wavefield reconstruction;Compressed sensing;Holography;Image reconstruction;Spatial resolution;Compressive sensing;coherence;digital holography;fresnel number;orthogonal wavelet transforms;phase transition diagrams},
}

@Article{Curtis2017p953-965,
  author   = {C. Curtis and B. R. Lavoie and E. Fear},
  title    = {An Analysis of the Assumptions Inherent to Near-Field Beamforming for Biomedical Applications},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {953-965},
  month    = {Dec},
  abstract = {Microwave imaging for biomedical applications is a growing field that shows promise in early patient studies. Interpretation of preclinical imaging results is difficult, in part due to an incomplete understanding of the imaging operator. In this paper, near-field beamforming is demonstrated to be analogous to synthetic aperture radar, and both imaging methods are shown to depend on several simplifying assumptions. The influence of these assumptions is analyzed using analytical and simulated models, and the results are confirmed in an experimental setup. These observations are further explored in application to simulations of realistic breast models as well as patient data.},
  doi      = {10.1109/TCI.2017.2756022},
  keywords = {array signal processing;medical image processing;microwave imaging;radar imaging;synthetic aperture radar;biomedical applications;microwave imaging;near-field beamforming;patient data;preclinical imaging;synthetic aperture radar;Analytical models;Array signal processing;Biological system modeling;Breast;Data models;Microwave imaging;Radar imaging;Synthetic aperture radar;Ultra wideband radar;Microwave breast imaging;UWB radar;near-field microwave imaging;patient scans},
}

@Article{Zhou2017p822-836,
  author   = {X. Zhou and S. Prasad},
  title    = {Domain Adaptation for Robust Classification of Disparate Hyperspectral Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {822-836},
  month    = {Dec},
  abstract = {A major difficulty of remote sensing image classification comes from the lack of quality training data. In this paper, we propose a domain adaptation algorithm to alleviate this problem by leveraging labeled data from an auxiliary data source. The proposed approach aims to align the class distributions of two domains while enhancing their discriminability. Separate transformations are used to project data from the source and target domains into a latent space where the ratio of within-class distance to between-class distance is minimized. A probabilistic framework is presented such that the transformation for each domain is iteratively optimized through an alternating maximizing algorithm. The proposed method is optimized with a distance-based objective function that ensures preservation of stochastic neighborhood and discriminative information of both source and target data in the latent space. The proposed method can be used in original or transformed spaces, and to illustrate this, we provide results of this method in a space generated by the wavelet scattering transform, which imparts further robustness. Additionally, a challenging hyperspectral dataset is introduced for evaluating domain adaptation algorithms. We investigate the proposed method under three domain adaptation scenarios, and experimental results with real-word hyperspectral datasets demonstrate the efficacy of the proposed method compared to conventional domain adaptation approaches.},
  doi      = {10.1109/TCI.2017.2752150},
  keywords = {geophysical image processing;hyperspectral imaging;image classification;remote sensing;stochastic processes;wavelet transforms;disparate hyperspectral images classification;domain adaptation algorithm;hyperspectral dataset;remote sensing image classification;stochastic neighborhood preservation;wavelet scattering transform;Hyperspectral imaging;Linear programming;Measurement;Probabilistic logic;Transforms;Domain adaptation;classification;hyperspectral image;scattering;transformation learning},
}

@Article{Xu2017p940-952,
  author   = {G. Xu and L. Yang and G. Bi and M. Xing},
  title    = {Enhanced ISAR Imaging and Motion Estimation With Parametric and Dynamic Sparse Bayesian Learning},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {940-952},
  month    = {Dec},
  abstract = {This paper is focused on high-resolution inverse synthetic aperture radar (ISAR) imaging and motion estimation of maneuvering targets from compressively sampled echo data. Herein, a local structural sparse Bayesian learning (LS-SBL) algorithm is proposed by exploiting the joint sparsity pattern of adjacent scatterers. A structured prior by modeling the neighboring correlation or dependence is utilized to encode the joint sparsity pattern. Meanwhile, a parametric dictionary with unknown rotational parameters is constructed to represent the target maneuverability. The solution to the LS-SBL algorithm is decomposed into iterations between sparse imaging and dictionary learning. In sparse imaging, an expectation-maximization method is employed for ISAR image formation and hyperparameter estimation by using a predesigned dictionary. In dictionary learning, an efficient approach of rotational parameter estimation is presented to dynamically update the parametric dictionary. Due to the exploitation of joint sparsity pattern, enhanced performance of ISAR image reconstruction can be achieved by effectively preserving the target structure. In addition, the cross-range scaled ISAR image is obtainable by extracting the target geometry, which benefits from the rotational motion estimation. Finally, experiments on simulated and measured data demonstrate the effectiveness of the proposed algorithm.},
  doi      = {10.1109/TCI.2017.2750330},
  keywords = {Bayes methods;expectation-maximisation algorithm;image reconstruction;image resolution;iterative methods;least squares approximations;motion estimation;parameter estimation;radar imaging;radar resolution;synthetic aperture radar;ISAR image reconstruction;LS-SBL algorithm;compressively sampled echo data;cross-range scaled ISAR image formation;dictionary learning;dynamic sparse Bayesian learning;expectation-maximization method;high-resolution inverse synthetic aperture radar imaging;hyperparameter estimation;joint sparsity pattern;local structural sparse Bayesian learning algorithm;neighboring correlation;parametric Bayesian learning;parametric dictionary;predesigned dictionary;rotational motion estimation;rotational parameter estimation;sparse imaging;target geometry;target maneuverability;target structure;unknown rotational parameters;Machine learning;Motion estimation;Radar imaging;Synthetic aperture radar;Compressed sampling;dictionary learning;inverse synthetic aperture radar (ISAR);sparse Bayesian learning (SBL);structured prior},
}

@Article{Fablet2017p647-657,
  author   = {R. Fablet and P. H. Viet and R. Lguensat},
  title    = {Data-Driven Models for the Spatio-Temporal Interpolation of Satellite-Derived SST Fields},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {647-657},
  month    = {Dec},
  abstract = {Satellite-derived products are of key importance for the high-resolution monitoring of the ocean surface on a global scale. Due to the sensitivity of spaceborne sensors to the atmospheric conditions as well as the associated spatio-temporal sampling, ocean remote sensing data may be subject to high-missing data rates. The spatio-temporal interpolation of these data remains a key challenge to deliver L4 gridded products to end-users. Whereas operational products mostly rely on model-driven approaches, especially optimal interpolation based on Gaussian process priors, the availability of large-scale observation and simulation datasets calls for the development of novel data-driven models. This study investigates such models. We extend the recently introduced analog data assimilation to high-dimensional spatio-temporal fields using a multiscale patch-based decomposition. Using an observing system simulation experiment for sea surface temperature, we demonstrate the relevance of the proposed data-driven scheme for the real missing data patterns of the high-resolution infrared METOP sensor. It has resulted in a significant improvement w.r.t. state-of-the-art techniques in terms of interpolation error (about 50% of relative gain) and spectral characteristics for horizontal scales smaller than 100 km. We further discuss the key features and parameterizations of the proposed data-driven approach as well as its relevance with respect to classical interpolation techniques.},
  doi      = {10.1109/TCI.2017.2749184},
  keywords = {Gaussian processes;atmospheric techniques;data assimilation;interpolation;ocean temperature;spatiotemporal phenomena;Gaussian process priors;L4 gridded products;SST fields;analog data assimilation;associated spatio-temporal sampling;classical interpolation techniques;data patterns;data-driven approach;global scale;high-dimensional spatio-temporal fields;high-missing data rates;high-resolution infrared METOP sensor;high-resolution monitoring;horizontal scales;interpolation error;large-scale observation;model-driven approaches;novel data-driven models;observing system simulation experiment;ocean remote sensing data;ocean surface;operational products;optimal interpolation;satellite-derived products;sea surface temperature;simulation datasets;spaceborne sensors;spatio-temporal interpolation;spectral characteristics;Computational modeling;Data assimilation;Data models;Interpolation;Principal component analysis;Sea surface;Analog and exemplar-based models;data assimilation;multi-scale decomposition;ocean remtote sensing data;optimal interpolation;patch-based representation},
}

@Article{Thanikachalam2017p580-591,
  author   = {N. Thanikachalam and L. Baboulaz and D. Firmenich and S. Süsstrunk and M. Vetterli},
  title    = {Handheld Reflectance Acquisition of Paintings},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {580-591},
  month    = {Dec},
  abstract = {Relightable photographs are alternatives to traditional photographs as they provide a richer viewing experience. However, the complex acquisition systems of existing techniques have restricted its usage to specialized setups. We introduce an easy-to-use and affordable solution for using smartphones to acquire the reflectance of paintings and similar almost-planar objects like tablets, engravings and textile. Our goal is to enable interactive relighting of such artifacts by everyone. In our approach, we nonuniformly sample the reflectance functions by moving the LED light of a smartphone, and simultaneously, tracking the position of the smartphone by using its camera. We then propose a compressive-sensing-based approach for reconstructing the light transport matrix from the nonuniformly sampled data. As shown with experiments, we accurately reconstruct the light transport matrix that can then be used to create relightable photographs.},
  doi      = {10.1109/TCI.2017.2749182},
  keywords = {art;compressed sensing;image reconstruction;photography;smart phones;LED light;almost-planar objects;complex acquisition systems;compressive-sensing-based approach;handheld reflectance acquisition;interactive relighting;light transport matrix;paintings;reflectance functions;relightable photographs;smartphone;Cameras;Image reconstruction;Light emitting diodes;Lighting;Mobile communication;Smart phones;Trajectory;compressive sensing;computational relighting;image-based relighting;light transport matrix;mobile imaging;nonuniform sampling},
}

@Article{Wen2017p566-579,
  author   = {F. Wen and L. Pei and Y. Yang and W. Yu and P. Liu},
  title    = {Efficient and Robust Recovery of Sparse Signal and Image Using Generalized Nonconvex Regularization},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {566-579},
  month    = {Dec},
  abstract = {This paper addresses the robust reconstruction problem of a sparse signal from compressed measurements. We propose a robust formulation for sparse reconstruction that employs the 11-norm as the loss function for the residual error and utilizes a generalized nonconvex penalty for sparsity inducing. The 11-loss is less sensitive to outliers in the measurements than the popular 12-loss, while the nonconvex penalty has the capability of ameliorating the bias problem of the popular convex LASSO penalty and thus can yield more accurate recovery. To solve this nonconvex and nonsmooth minimization formulation efficiently, we propose a first-order algorithm based on alternating direction method of multipliers. A smoothing strategy on the 11-loss function has been used in deriving the new algorithm to make it convergent. Further, a sufficient condition for the convergence of the new algorithm has been provided for generalized nonconvex regularization. In comparison with several state-of-the-art algorithms, the new algorithm showed better performance in numerical experiments in recovering sparse signals and compressible images. The new algorithm scales well for large-scale problems, as often encountered in image processing.},
  doi      = {10.1109/TCI.2017.2744626},
  keywords = {concave programming;convex programming;image reconstruction;iterative methods;minimisation;optimisation;signal reconstruction;bias problem;compressed measurements;compressible images;convex LASSO penalty;first-order algorithm;generalized nonconvex penalty;generalized nonconvex regularization;image recovery;nonconvex minimization formulation;nonsmooth minimization formulation;residual error;robust formulation;robust reconstruction problem;sparse reconstruction;sparse signal recovery;Image coding;Image reconstruction;Robustness;Smoothing methods;Alternating direction method;compressive sensing;impulsive noise;nonconvex regularization;robust sparse recovery},
}

@Article{Mousavi2017p774-782,
  author   = {S. R. Mousavi and H. Rivaz and A. Sadeghi-Naini and G. J. Czarnota and A. Samani},
  title    = {Breast Ultrasound Elastography Using Full Inversion-Based Elastic Modulus Reconstruction},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {774-782},
  month    = {Dec},
  abstract = {Several cancer types, including breast cancer, are associated with tissue structural changes that yield tissue stiffening. Clinical breast examination (CBE) is a physical examination of the breast to find palpable breast tumors. This test lacks accuracy necessary for effective assessment and diagnosis of breast cancer. To develop an effective breast cancer diagnostic technique, an imaging method is proposed that maps the distribution of breast tissue relative elasticity modulus. Unlike CBE, this technique is quantitative; hence, it is expected that its accuracy is independent of the physician's experience. The proposed technique is a quasi-static elastography technique which uses radiofrequency data acquired through ultrasound imaging to determine both axial and lateral tissue displacements resulting from tissue mechanical stimulation. These displacements serve as input data for elastography image reconstruction. The reconstruction technique is developed using a full inversion framework where elastic tissue deformation equations are inverted using an iterative process. Each iteration in this process involves stress computation using finite-element analysis followed by updating elastic modulus until convergence is achieved. The proposed technique was validated by two tissue mimicking phantom studies before it was successfully applied to a clinical case. The two independent phantom studies demonstrated the robustness of the proposed method demonstrated by reconstruction errors of less than 12%. Elastic modulus images of the clinical case were compared to corresponding B-modes images where cancerous areas were identified as hypo-echoic areas. This comparison indicated marked tissue stiffening in those areas. Results obtained from the phantom and patient studies conducted in this study indicate that the proposed method is reasonably accurate; hence, the technique can be potentially used for quantitative assessment of breast cancer. The elastici- y reconstruction algorithm developed in this work can be easily implemented on clinical ultrasound systems with no requirement to any additional hardware attachment for mechanical stimulation or data acquisition. As such, it can be applied as a low cost and potentially widely available technology for breast cancer diagnosis.},
  doi      = {10.1109/TCI.2017.2741422},
  keywords = {biomechanics;biomedical ultrasonics;cancer;deformation;elastic moduli;elasticity;finite element analysis;image reconstruction;mammography;medical image processing;phantoms;tumours;ultrasonic imaging;B-modes images;breast cancer diagnostic technique;breast tissue relative elasticity modulus;breast tumors;breast ultrasound elastography;cancer types;clinical breast examination;clinical ultrasound systems;elastic modulus images;elastic tissue deformation equations;elastography image reconstruction;finite element analysis;full inversion-based elastic modulus reconstruction;quasistatic elastography technique;tissue mechanical stimulation;tissue mimicking phantom studies;tissue stiffening;tissue structural changes;ultrasound imaging;Breast cancer;Elastography;Image reconstruction;Breast;data inversion;finite element;ultrasound elastography},
}

@Article{Hossain2017p928-939,
  author   = {M. D. Hossain and A. S. Mohan},
  title    = {Cancer Detection in Highly Dense Breasts Using Coherently Focused Time-Reversal Microwave Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {928-939},
  month    = {Dec},
  abstract = {Detection of tumors in highly dense breasts is a critical but challenging issue for early-stage breast cancer detection. We present the application of coherent focusing for time-reversal (TR) microwave imaging in beamspace for the detection and localization of multiple tumors in highly dense 3-D breast phantoms. We propose a novel coherent beamspace time reversal maximum likelihood (C-B-TR-ML) technique to obtain accurate tumor locations with reduced computational burden. To compare the performance, the coherent beamspace processing is also extended for conventional decomposition of the TR operator (DORT) and TR-MUSIC algorithms. A novel hybrid technique involving time of arrival and entropy is also proposed for early-time artifact removal as well as for estimating the Green's function of an equivalent virtual medium required for the TR operation. Finite-difference time-domain computations on anatomically realistic 3-D numerical breast phantoms are used to obtain the backscattered data. The results demonstrate the superior capabilities of the proposed C-B-TR-ML microwave-imaging technique in detecting and localizing multiple tumors embedded inside highly dense breast phantoms.},
  doi      = {10.1109/TCI.2017.2737947},
  keywords = {Green's function methods;cancer;finite difference time-domain analysis;mammography;maximum likelihood estimation;medical image processing;microwave imaging;phantoms;tumours;3D numerical breast phantoms;C-B-TR-ML microwave imaging technique;DORT algorithmns;Green function;TR-MUSIC algorithm;TR-MUSIC algorithms;artifact removal;breast cancer detection;coherent beamspace processing;coherent beamspace time reversal maximum likelihood;coherently focused time-reversal microwave imaging;decomposition-of-the-TR operator;finite-difference time-domain computations;tumor locations;Breast;Clutter;Dielectrics;Microwave imaging;Microwave theory and techniques;Tumors;Beamspace;DORT;TR-MUSIC;breast cancer;coherent focusing;entropy;green's function;highly dense breasts;maximum likelihood;microwave imaging;multiple tumors;time of arrival;time reversal},
}

@Article{Barkan2017p551-565,
  author   = {O. Barkan and J. Weill and S. Dekel and A. Averbuch},
  title    = {A Mathematical Model for Adaptive Computed Tomography Sensing},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {551-565},
  month    = {Dec},
  abstract = {One of the main challenges in computed tomography (CT) is how to balance between the amount of radiation the patient is exposed to during scan time and the quality of the reconstructed CT image. We propose a mathematical model for adaptive CT sensing whose goal is to reduce dosage levels while maintaining high image quality at the same time. The adaptive algorithm iterates between selective limited sensing and improved reconstruction, with the goal of applying only the dose level required for sufficient image quality. The theoretical foundation of the algorithm is nonlinear Ridgelet approximation and a discrete form of Ridgelet analysis is used to compute the selective acquisition steps that best capture the image edges. We show experimental results where for the same number of line projections, the adaptive model produces higher image quality, when compared with standard limited angle, nonadaptive sensing algorithms.},
  doi      = {10.1109/TCI.2017.2736788},
  keywords = {computerised tomography;image reconstruction;medical image processing;CT image reconstruction;adaptive CT sensing;adaptive algorithm;adaptive algorithm iterates;computed tomography;dose level;image edges;image quality;mathematical model;nonadaptive sensing algorithms;nonlinear Ridgelet approximation;Adaptation models;Computed tomography;Image quality;Image reconstruction;Sensors;Transforms;Adaptive compressed sensing;adaptive CT acquisition;contour analysis;low dose CT;multiresolution analysis;nonlinear approximation;ridgelets;wavelets},
}

@Article{Cao2017p1008-1019,
  author   = {Y. Cao and H. Qi and J. Kato and K. Li},
  title    = {Hash Ranking With Weighted Asymmetric Distance for Image Search},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {1008-1019},
  month    = {Dec},
  abstract = {Image search can be viewed as a problem of large-scale approximate nearest neighbor (ANN) search in image feature space. Hash ranking methods have been widely used for ANN search because of their two benefits: less memory usage and high search efficiency. Generally, the hash ranking methods face two problems: binary encoding and binary code ranking. This paper focuses on the latter. In existing work, the ranking of binary hash codes is usually implemented based on Hamming distance or asymmetric distance. Hamming distance easily leads to confusing ranking when different candidate points share the same Hamming distance to the query point. Therefore, recent work prefers the asymmetric distance to Hamming distance. When computing asymmetric distance, it is necessary to give reasonable query-independent values. These values are usually approximated by average values of sample candidate points in existing methods. However, when the distribution of candidate points is not uniform, average values are meaningless, leading to wrong ranking results. To address this problem, we propose two kinds of weighted asymmetric distance algorithms, namely, the Otsu threshold based algorithm (WoRank) and the score calculation based algorithm (WsRank) in this paper. The processes of these two proposed algorithms are similar, consisting of two steps. In the first step, we compute the query-independent values on each bit in accordance with corresponding distribution of candidate points to reduce the approximation error. In the second step, we compute bitwise weights in consideration of each bit's discriminative power to further improve the retrieval accuracy. The differences between WoRank and WsRank are the computation methods of query-independent values and bitwise weights. To evaluate the proposed algorithms, we conduct a large number of experiments on four well-known datasets, namely, SIFT, CIFAR-10, MNIST, and NUS-WIDE. The results show that the proposed algorithms can achieve up to 2- % performance gains over Hamming distance based ranking and 13% over the existing asymmetric distance based ranking. We also find WoRank is suitable for feature dataset (SIFT), while WsRank is suitable for image datasets.},
  doi      = {10.1109/TCI.2017.2736980},
  keywords = {Hamming codes;binary codes;content-based retrieval;encoding;feature extraction;file organisation;image classification;image retrieval;ANN search;Hamming distance;Otsu threshold;approximate nearest neighbor search;binary code ranking;binary encoding;binary hash codes;hash ranking;image feature space;image search;query-independent values;retrieval accuracy;weighted asymmetric distance algorithms;Approximation algorithms;Binary codes;Databases;Encoding;Hamming distance;Image color analysis;Search problems;Approximate nearest neighbor search;asymmetric distance;bitwise weight;query-independent value},
}

@Article{Lin2017p738-748,
  author   = {Y. Lin and A. Ortega},
  title    = {Object-Based High Contrast Traveltime Tomography},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {738-748},
  month    = {Dec},
  abstract = {We consider a traveltime tomography problem that involves detection of high-velocity structures in a homogeneous medium. If we only have limited measurements, this problem becomes an under-determined inverse problem and a common approach would be using prior information to guide the reconstruction process. We restrict the possible velocity into discrete values and model it as a discrete nonlinear inverse problem. However, typical iterative linearized reconstruction algorithms on grid-spacing model usually have very poor reconstruction results in the presence of high-contrast boundaries. The reason is that the travel path bends significantly near the boundary, making it very difficult to infer the travel path and velocity value from measured traveltime. To handle this scenario, we propose an object-based approach to model high-velocity structures by predefined convex objects. Compared to the typical grid-spacing model, which has variables that are proportional to the number of cells, our approach has an advantage that the number of unknown variables in the system is proportional to the number of objects, which greatly decreases the problem dimension. We have developed a fast algorithm to provide an estimate of the appearance probability of high-velocity structures in the region of interest. Simulations show that our method can efficiently sample the model parameter space, and provide more robust reconstruction results for the scenario where the number of measurements is limited.},
  doi      = {10.1109/TCI.2017.2726353},
  keywords = {image colour analysis;image reconstruction;image segmentation;inverse problems;iterative methods;object detection;tomography;discrete nonlinear inverse problem;grid-spacing model;high-velocity structure detection;inverse problem;iterative linearized reconstruction algorithms;object-based high contrast traveltime tomography;reconstruction process;region of interest;Geophysical measurements;Image reconstruction;Inverse problems;Tomography;Velocity measurement;Bayesian image reconstruction;traveltime tomography},
}

@Article{Aggrawal2018p17-31,
  author   = {H. O. Aggrawal and M. S. Andersen and S. D. Rose and E. Y. Sidky},
  title    = {A Convex Reconstruction Model for X-Ray Tomographic Imaging With Uncertain Flat-Fields},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2018},
  volume   = {4},
  number   = {1},
  pages    = {17-31},
  month    = {March},
  abstract = {Classical methods for X-ray computed tomography are based on the assumption that the X-ray source intensity is known, but in practice, the intensity is measured and hence uncertain. Under normal operating conditions, when the exposure time is sufficiently high, this kind of uncertainty typically has a negligible effect on the reconstruction quality. However, in time- or dose-limited applications such as dynamic CT, this uncertainty may cause severe and systematic artifacts known as ring artifacts. By carefully modeling the measurement process and by taking uncertainties into account, we derive a new convex model that leads to improved reconstructions despite poor quality measurements. We demonstrate the effectiveness of the methodology based on simulated and real datasets.},
  doi      = {10.1109/TCI.2017.2723246},
  keywords = {computerised tomography;image reconstruction;medical image processing;X-ray computed tomography;X-ray source intensity;X-ray tomographic imaging;convex reconstruction model;dose-limited applications;dynamic CT;image reconstruction quality;ring artifacts;Computed tomography;Detectors;Estimation error;Image reconstruction;Measurement uncertainty;Random variables;X-ray imaging;Low intensity;reconstruction methods;ring artifacts;x-ray computed tomography},
}

@Article{Ongie2017p535-550,
  author   = {G. Ongie and M. Jacob},
  title    = {A Fast Algorithm for Convolutional Structured Low-Rank Matrix Recovery},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {535-550},
  month    = {Dec},
  abstract = {Fourier-domain structured low-rank matrix priors are emerging as powerful alternatives to traditional image recovery methods such as total variation and wavelet regularization. These priors specify that a convolutional structured matrix, i.e., Toeplitz, Hankel, or their multilevel generalizations, built from Fourier data of the image should be low-rank. The main challenge in applying these schemes to large-scale problems is the computational complexity and memory demand resulting from lifting the image data to a large-scale matrix. We introduce a fast and memory-efficient approach called the generic iterative reweighted annihilation filter algorithm that exploits the convolutional structure of the lifted matrix to work in the original unlifted domain, thus considerably reducing the complexity. Our experiments on the recovery of images from undersampled Fourier measurements show that the resulting algorithm is considerably faster than previously proposed algorithms and can accommodate much larger problem sizes than previously studied.},
  doi      = {10.1109/TCI.2017.2721819},
  keywords = {Fourier analysis;computational complexity;convolution;image filtering;image reconstruction;iterative methods;matrix algebra;Fourier measurements;Fourier-domain structured low-rank matrix;computational complexity;convolutional structure;image data;image recovery;iterative reweighted annihilation filter algorithm;large-scale matrix;low-rank matrix recovery;Approximation algorithms;Convolution;Image reconstruction;Jacobian matrices;Magnetic resonance imaging;Transmission line matrix methods;Annihilating filter;MRI reconstruction;compressed sensing;finite rate of innovation;multi-level Toeplitz matrices;structured low-rank matrix recovery},
}

@Article{Odinaka2017p506-521,
  author   = {I. Odinaka and J. A. O'Sullivan and D. G. Politte and K. P. MacCabe and Y. Kaganovsky and J. A. Greenberg and M. Lakshmanan and K. Krishnamurthy and A. J. Kapadia and L. Carin and D. J. Brady},
  title    = {Joint System and Algorithm Design for Computationally Efficient Fan Beam Coded Aperture X-Ray Coherent Scatter Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {506-521},
  month    = {Dec},
  abstract = {In x-ray coherent scatter tomography, tomographic measurements of the forward scatter distribution are used to infer scatter densities within a volume. A radiopaque 2D pattern placed between the object and the detector array enables the disambiguation between different scatter events. The use of a fan beam source illumination to speed up data acquisition relative to a pencil beam presents computational challenges. To facilitate the use of iterative algorithms based on a penalized Poisson log-likelihood function, efficient computational implementation of the forward and backward models are needed. Our proposed implementation exploits physical symmetries and structural properties of the system and suggests a joint system-algorithm design, where the system design choices are influenced by computational considerations, and in turn lead to reduced reconstruction time. Computational-time speedups of approximately 146 and 32 are achieved in the computation of the forward and backward models, respectively. Results validating the forward model and reconstruction algorithm are presented on simulated analytic and Monte Carlo data.},
  doi      = {10.1109/TCI.2017.2721742},
  keywords = {Monte Carlo methods;Poisson distribution;computerised tomography;data acquisition;image reconstruction;iterative methods;medical image processing;Monte Carlo data;X-ray coherent scatter tomography;detector array;fan beam coded aperture X-ray coherent scatter;fan beam source illumination;forward scatter distribution;image reconstruction algorithm;iterative algorithms;joint system-algorithm design;penalized Poisson log-likelihood function;pencil beam;Apertures;Computational modeling;Detectors;Photonics;X-ray imaging},
}

@Article{Caldas2017p485-492,
  author   = {L. C. Caldas and P. C. Greco and C. C. Pagani and L. A. Baccalá},
  title    = {Acoustic Imaging of In-Duct Aeroengine Noise Sources Using Rotating Beamforming and Phased Arrays},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {485-492},
  month    = {Sept},
  abstract = {An in-duct rotating beamforming technique, using a wall-mounted array of microphones placed within a long duct, was developed for locating broadband noise sources from an aeroengine fan. The technique was experimentally implemented at the recently constructed long-duct low-speed fan rig test facility at the University of São Paulo in Brazil. The test rig has a 16-bladed fan rotor and 14-vaned stator, with speed up to 4250 r/min and a maximum 0.1 Mach number mean axial flow speed. Here, we describe the beamforming details with an emphasis on the mandatory coordinate change to a rotating reference frame for a frequency domain virtual rotating microphone technique. Example sound source maps are presented revealing clear noise blade signatures together with simulated point spread function maps using modal steering vectors at six different frequencies that characterize the beamformer.},
  doi      = {10.1109/TCI.2017.2721744},
  keywords = {Mach number;acoustic imaging;acoustic noise;aeroacoustics;aerospace engines;array signal processing;condition monitoring;mechanical engineering computing;Brazil;Mach number;acoustic imaging;in-duct aeroengine noise sources;phased arrays;rotating beamforming arrays;Acoustic arrays;Acoustics;Array signal processing;Imaging;Microphone arrays;Aeroacoustic;array signal processing;fan noise;in-duct beamforming;power spectral density;rotating acoustic imaging},
}

@Article{Rahman2017p837-852,
  author   = {S. Rahman and A. Robles-Kelly},
  title    = {Estimating Reflectance Parameters, Light Direction, and Shape From a Single Multispectral Image},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {837-852},
  month    = {Dec},
  abstract = {This paper presents a novel approach for estimating the light direction, shape, and reflectance parameters from a single multispectral image. We start from a general formulation that hinges in the notion that the light reflected from an object can be deemed to be a linear combination of specular and diffuse reflections. This permits the recovery of the reflection parameters through an iterative optimization scheme, which we render well posed by adopting a novel reparameterization that reduces the number of degrees of freedom in the cost function. With the estimated specular reflectance parameters, we recover the single point light source position from specular highlights by applying two novel constraints, coplanarity and Kullback-Leibler divergence. Then, by integrating the knowledge of light source and diffuse reflectance parameters, we recover shape of the scene from the diffuse component. Our approach is quite general in nature and can be applied to a family of reflectance models that are based on the Fresnel reflection theory. We demonstrate the utility of our method on synthetic and real world imagery. We also compare our results to several alternatives in the literature.},
  doi      = {10.1109/TCI.2017.2717788},
  keywords = {computer vision;image colour analysis;iterative methods;light reflection;light sources;optimisation;reflectivity;Fresnel reflection theory;Kullback-Leibler divergence;computer vision;coplanarity;diffuse reflections;iterative optimization;light direction;light source position;multispectral image;reparameterization;specular reflectance parameters;specular reflections;Calibration;Light sources;Rough surfaces;Surface roughness;Light direction;multispectral image;reflectance parameters;shape},
}

@Article{Hog2017p811-821,
  author   = {M. Hog and N. Sabater and B. Vandame and V. Drazic},
  title    = {An Image Rendering Pipeline for Focused Plenoptic Cameras},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {811-821},
  month    = {Dec},
  abstract = {In this paper, we present a complete processing pipeline for focused plenoptic cameras. In particular, we propose 1) a new algorithm for microlens center calibration fully in the Fourier domain, 2) a novel algorithm for depth map computation using a stereo focal stack, and 3) a depth-based rendering algorithm that is able to refocus at a particular depth or to create all-in-focus images. The proposed algorithms are fast, accurate, and do not need to generate subaperture images or epipolar plane images which is capital for focused plenoptic cameras. Also, the resolution of the resulting depth map is the same as the rendered image. We show results of our pipeline on Georgiev's dataset and real images captured with different Raytrix cameras.},
  doi      = {10.1109/TCI.2017.2710906},
  keywords = {Fourier analysis;calibration;cameras;image reconstruction;image resolution;image sensors;microlenses;rendering (computer graphics);stereo image processing;Fourier domain;Georgiev dataset;Raytrix cameras;all-in-focus images;depth map computation;epipolar plane images;focused plenoptic cameras;image rendering pipeline;microlens center calibration;stereo focal stack;subaperture images;Calibration;Cameras;Lenses;Microoptics;Rendering (computer graphics);Calibration;depth estimation;plenoptic cameras;refocusing},
}

@Article{Mathew2017p891-900,
  author   = {R. S. Mathew and J. S. Paul},
  title    = {A Frequency-Dependent Regularization for Autocalibrating Parallel MRI Using the Generalized Discrepancy Principle},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {891-900},
  month    = {Dec},
  abstract = {This paper quantitatively evaluates regularized GRAPPA SPIRiT reconstruction in autocalibrating parallel MRI and develops a frequency-dependent regularization (FDR) aimed at achieving higher SNR with reduced penalty on image resolution. The latter is achieved by imposing an upper limit on the extent of regularization for each k -space location. The procedure starts with selection of a suitable truncation parameter, followed by perturbation of the AutoCalibrating Signal (ACS) lines using addition of white Gaussian noise samples of a predetermined variance. The noise variance chosen is such that first-order perturbation rules apply. In each perturbation step, the regularized solutions are estimated using a first-order update of singular values, and conditions stipulated by the generalized discrepancy principle (GDP) with regards to the norms of calibration and perturbation errors. The procedure is stopped at the crossover limit, once the GDP conditions are violated. The crossover information yields an upper limit for perturbation, enabling computation of an error bound as the difference between k-spaces estimated with filter weights from calibrations performed on original and the perturbed ACS lines at cross-over. Imposition of an upper limit on the extent of regularization is achieved by matching this error bound to the difference in k-spaces reconstructed with varying offsets of regularization from that of a reference. Furthermore, the crossover distance defined in terms of difference between minimum singular values of the initial and crossover calibration matrices serves as a proxy indicator of the achievable reduction in reconstruction error using regularization.},
  doi      = {10.1109/TCI.2017.2707979},
  keywords = {Gaussian noise;biomedical MRI;image reconstruction;image sampling;medical image processing;GRAPPA SPIRiT reconstruction;autocalibrating signal lines;frequency-dependent regularization;generalized discrepancy principle;parallel MRI autocalibration;reconstruction error;white Gaussian noise;Acceleration;Calibration;Economic indicators;Filtering theory;Image reconstruction;Magnetic resonance imaging;Cross-over distance;GRAPPA;SPIRiT;frequency dependent regularization (FDR);generalized discrepancy principle (GDP)},
}

@Article{Rapp2017p445-459,
  author   = {J. Rapp and V. K. Goyal},
  title    = {A Few Photons Among Many: Unmixing Signal and Noise for Photon-Efficient Active Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {445-459},
  month    = {Sept},
  abstract = {Conventional LIDAR systems require hundreds or thousands of photon detections per pixel to form accurate depth and reflectivity images. Recent photon-efficient computational imaging methods are remarkably effective with only 1.0 to 3.0 detected photons per pixel, but they are not demonstrated at signal-to-background ratio (SBR) below 1.0 because their imaging accuracies degrade significantly in the presence of high background noise. We introduce a new approach to depth and reflectivity estimation that emphasizes the unmixing of contributions from signal and noise sources. At each pixel in an image, short-duration range gates are adaptively determined and applied to remove detections likely to be due to noise. For pixels with too few detections to perform this censoring accurately, data are combined from neighboring pixels to improve depth estimates, where the neighborhood formation is also adaptive to scene content. Algorithm performance is demonstrated on experimental data at varying levels of noise. Results show improved performance of both reflectivity and depth estimates over state-of-the-art methods, especially at low SBR. In particular, accurate imaging is demonstrated with SBR as low as 0.04. This validation of a photon-efficient, noise-tolerant method demonstrates the viability of rapid, long-range, and low-power LIDAR imaging.},
  doi      = {10.1109/TCI.2017.2706028},
  keywords = {optical radar;radar imaging;LIDAR systems;SBR;depth estimates;neighboring pixels;photon detections;photon-efficient active imaging;photon-efficient computational imaging methods;short-duration range gates;Detectors;Imaging;Laser radar;Lighting;Maximum likelihood estimation;Photonics;3-D imaging;3d-reconstruction;LIDAR;Poisson processes;computational imaging;depth cameras;lidar;low-light imaging;photon counting;photon-counting;poisson-processes;ranging;time-of-flight imaging},
}

@Article{Schmiester2017p671-681,
  author   = {L. Schmiester and M. Möddel and W. Erb and T. Knopp},
  title    = {Direct Image Reconstruction of Lissajous-Type Magnetic Particle Imaging Data Using Chebyshev-Based Matrix Compression},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {671-681},
  month    = {Dec},
  abstract = {Image reconstruction in magnetic particle imaging (MPI) is done using an algebraic approach for Lissajous-type measurement sequences. By solving a large linear system of equations, the spatial distribution of magnetic nanoparticles can be determined. Despite the use of iterative solvers that converge rapidly, the size of the MPI system matrix leads to reconstruction times that are typically much longer than the actual data acquisition time. For this reason, matrix compression techniques have been introduced that transform the MPI system matrix into a sparse domain and then utilize this sparsity for accelerated reconstruction. Within this work, we investigate the Chebyshev transformation for matrix compression and show that it can provide better reconstruction results for high compression rates than the commonly applied Cosine transformation. By reducing the number of coefficients per matrix row to one, it is even possible to derive a direct reconstruction method that obviates the usage of iterative solvers.},
  doi      = {10.1109/TCI.2017.2706058},
  keywords = {Chebyshev approximation;image coding;image reconstruction;magnetic particles;matrix algebra;medical image processing;nanoparticles;Chebyshev transformation;Lissajous-type magnetic particle imaging data;Lissajous-type measurement sequences;MPI system matrix;algebraic approach;direct image reconstruction;magnetic nanoparticles;matrix compression techniques;medical imaging;spatial distribution;Chebyshev approximation;Image reconstruction;Magnetic resonance imaging;Sparse matrices;Trajectory;Two dimensional displays;Biomedical imaging;data compression;image reconstruction},
}

@Article{Lee2017p783-797,
  author   = {C. C. Lee and W. L. Hwang},
  title    = {Mixture of Gaussian Blur Kernel Representation for Blind Image Restoration},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {783-797},
  month    = {Dec},
  abstract = {Blind image restoration is a nonconvex problem involving the restoration of images using unknown blur kernels. The success of the restoration process depends on three factors: first, the amount of prior information concerning the image and blur kernel; second, the algorithm used to perform restoration; and third, the initial guesses made by the algorithm. Prior information of an image can often be used to restore the sharpness of edges. In contrast, there is no consensus concerning the use of prior information in the restoration of images from blur kernels, due to the complex nature of image blurring processes. In this paper, we model a blur kernel as a linear combination of basic two-dimensional (2-D) patterns. To illustrate this process, we constructed a dictionary comprising atoms of Gaussian functions derived from the Kronecker product of 1-D Gaussian sequences. Our results show that the proposed method is more robust than other state-of-the-art methods in a noisy environment, due to its increased signal-to-noise ratio (ISNR). This approach also proved more stable than the other methods, due to the steady increase in ISNR as the number of iterations is increased.},
  doi      = {10.1109/TCI.2017.2706062},
  keywords = {Gaussian processes;blind source separation;image representation;image restoration;1D Gaussian sequences;2D patterns;Gaussian blur kernel representation;Gaussian functions;Kronecker product;blind image restoration;edge sharpness;image blurring processes;increased signal-to-noise ratio;nonconvex problem;Adaptation models;Cameras;Image restoration;TV;Blind image deblurring;blind deconvolution;total variation},
}

@Article{Betcke2017p710-721,
  author   = {M. M. Betcke and B. T. Cox and N. Huynh and E. Z. Zhang and P. C. Beard and S. R. Arridge},
  title    = {Acoustic Wave Field Reconstruction From Compressed Measurements With Application in Photoacoustic Tomography},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {710-721},
  month    = {Dec},
  abstract = {We present a method for the recovery of compressively sensed acoustic fields using patterned, instead of point-by-point, detection. From a limited number of such compressed measurements, we propose to reconstruct the field on the sensor plane in each time step independently assuming its sparsity in a Curvelet frame. A modification of the Curvelet frame is proposed to account for the smoothing effects of data acquisition and motivated by a frequency domain model for photoacoustic tomography. An ADMM type algorithm, split augmented Lagrangian shrinkage algorithm, is used to recover the pointwise data in each individual time step from the patterned measurements. For photoacoustic applications, the photoacoustic image of the initial pressure is reconstructed using time reversal in k-Wave Toolbox.},
  doi      = {10.1109/TCI.2017.2706029},
  keywords = {acoustic tomography;compressed sensing;data acquisition;frequency-domain analysis;image reconstruction;photoacoustic effect;ADMM type algorithm;acoustic wave field reconstruction;compressed measurements;compressively sensed acoustic fields;curvelet frame;data acquisition;frequency domain model;individual time step;k-Wave Toolbox;patterned measurements;photoacoustic applications;photoacoustic image reconstruction;photoacoustic tomography;pointwise data recovery;sensor plane;smoothing effects;split augmented Lagrangian shrinkage algorithm;time reversal;Acoustics;Detectors;Image coding;Image reconstruction;Time measurement;Tomography;ADMM methods;L1 minimization;compressed sensing;curvelet frame;photoacoustic tomography},
}

@Article{Aguerrebere2017p633-646,
  author   = {C. Aguerrebere and A. Almansa and J. Delon and Y. Gousseau and P. Musé},
  title    = {A Bayesian Hyperprior Approach for Joint Image Denoising and Interpolation, With an Application to HDR Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {633-646},
  month    = {Dec},
  abstract = {Recently, impressive denoising results have been achieved by Bayesian approaches which assume Gaussian models for the image patches. This improvement in performance can be attributed to the use of per-patch models. Unfortunately such an approach is particularly unstable for most inverse problems beyond denoising. In this paper, we propose the use of a hyperprior to model image patches, in order to stabilize the estimation procedure. There are two main advantages to the proposed restoration scheme: First, it is adapted to diagonal degradation matrices, and in particular to missing data problems (e.g., inpainting of missing pixels or zooming). Second, it can deal with signal dependent noise models, particularly suited to digital cameras. As such, the scheme is especially adapted to computational photography. In order to illustrate this point, we provide an application to high dynamic range imaging from a single image taken with a modified sensor, which shows the effectiveness of the proposed scheme.},
  doi      = {10.1109/TCI.2017.2704439},
  keywords = {Bayes methods;Gaussian processes;cameras;filtering theory;image denoising;image enhancement;image reconstruction;image resolution;image restoration;interpolation;inverse problems;Bayesian approaches;Gaussian models;HDR imaging;computational photography;diagonal degradation matrices;high dynamic range imaging;image patches;inverse problems;joint image denoising;per-patch models;restoration scheme;signal dependent noise models;Bayes methods;Computational modeling;Image restoration;Inverse problems;Noise reduction;Bayesian restoration;conjugate distributions;gaussian mixture models;hierarchical models;high dynamic range imaging;hyper-prior;maximum a posteriori;non-local patch-based restoration;single shot HDR, rank3},
}

@Article{Altmann2017p460-471,
  author   = {Y. Altmann and R. Aspden and M. Padgett and S. McLaughlin},
  title    = {A Bayesian Approach to Denoising of Single-Photon Binary Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {460-471},
  month    = {Sept},
  abstract = {This paper discusses new methods for processing images in the photon-limited regime where the number of photons per pixel is binary. We present a new Bayesian denoising method for binary, single-photon images. Each pixel measurement is assumed to follow a Bernoulli distribution whose mean is related by a nonlinear function to the underlying intensity value to be recovered. Adopting a Bayesian approach, we assign the unknown intensity field a smoothness promoting spatial and potentially temporal prior while enforcing the positivity of the intensity. A stochastic simulation method is then used to sample the resulting joint posterior distribution and estimate the unknown intensity, as well as the regularization parameters. We show that this new unsupervised denoising method can also be used to analyze images corrupted by Poisson noise. The proposed algorithm is compared to state-of-the art denoising techniques dedicated to photon-limited images using synthetic and real single-photon measurements. The results presented illustrate the potential benefits of the proposed methodology for photon-limited imaging, in particular with non photon-number resolving detectors.},
  doi      = {10.1109/TCI.2017.2703900},
  keywords = {Bayes methods;image denoising;statistical distributions;stochastic processes;Bayesian approach;Bayesian denoising method;Bernoulli distribution;Poisson noise;image analysis;image processing;joint posterior distribution;nonlinear function;photon-limited imaging;pixel measurement;regularization parameter;single-photon binary image denoising;single-photon measurement;spatial prior;stochastic simulation method;temporal prior;unsupervised denoising method;Bayes methods;Computational modeling;Detectors;Image resolution;Imaging;Noise reduction;Photonics;Bayesian estimation;Markov chain Monte Carlo methods;Photon-limited imaging;image denoising;single-photon detection},
}

@Article{Dai2017p432-444,
  author   = {Q. Dai and E. Pouyet and O. Cossairt and M. Walton and A. K. Katsaggelos},
  title    = {Spatial-Spectral Representation for X-Ray Fluorescence Image Super-Resolution},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {432-444},
  month    = {Sept},
  abstract = {X-ray fluorescence (XRF) scanning of works of art is becoming an increasing popular nondestructive analytical method. The high quality XRF spectra is necessary to obtain significant information on both major and minor elements used for characterization and provenance analysis. However, there is a tradeoff between the spatial resolution of an XRF scan and the signal-to-noise ratio (SNR) of each pixel's spectrum, due to the limited scanning time. In this project, we propose an XRF image super-resolution method to address this tradeoff; thus, obtaining a high spatial resolution XRF scan with high SNR. We fuse a low-resolution XRF image and a conventional RGB high-resolution image into a product of both high spatial and high spectral resolution XRF image. There is no guarantee of a one to one mapping between XRF spectrum and RGB color since, for instance, paintings with hidden layers cannot be detected in visible but can in X-ray wavelengths. We separate the XRF image into the visible and nonvisible components. The spatial resolution of the visible component is increased utilizing the high-resolution RGB image, whereas the spatial resolution of the non-visible component is increased using a total variation super-resolution method. Finally, the visible and nonvisible components are combined to obtain the final result.},
  doi      = {10.1109/TCI.2017.2703987},
  keywords = {X-ray emission spectra;X-ray fluorescence analysis;fluorescence;image colour analysis;image representation;image resolution;RGB high-resolution image;X-ray fluorescence image super-resolution;XRF scanning;XRF spectra;signal-to-noise ratio;spatial-spectral representation;Hyperspectral imaging;Signal resolution;Signal to noise ratio;Spatial resolution;X-ray imaging;Spatial-spectral;X-ray fluorescence;super-resolution, rank3},
}

@Article{Altmann2017p658-670,
  author   = {Y. Altmann and A. Maccarone and A. McCarthy and G. Newstadt and G. S. Buller and S. McLaughlin and A. Hero},
  title    = {Robust Spectral Unmixing of Sparse Multispectral Lidar Waveforms Using Gamma Markov Random Fields},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {658-670},
  month    = {Dec},
  abstract = {This paper presents a new Bayesian spectral unmixing algorithm to analyze remote scenes sensed via sparse multispectral Lidar measurements. To a first approximation, in the presence of a target, each Lidar waveform consists of a main peak, whose position depends on the target distance and whose amplitude depends on the wavelength of the laser source considered (i.e., on the target reflectivity). Besides, these temporal responses are usually assumed to be corrupted by Poisson noise in the low photon count regime. When considering multiple wavelengths, it becomes possible to use spectral information in order to identify and quantify the main materials in the scene, in addition to estimation of the Lidar-based range profiles. Due to its anomaly detection capability, the proposed hierarchical Bayesian model, coupled with an efficient Markov chain Monte Carlo algorithm, allows robust estimation of depth images together with abundance and outlier maps associated with the observed three-dimensional scene. The proposed methodology is illustrated via experiments conducted with real multispectral Lidar data acquired in a controlled environment. The results demonstrate the possibility to unmix spectral responses constructed from extremely sparse photon counts (less than 10 photons per pixel and band).},
  doi      = {10.1109/TCI.2017.2703144},
  keywords = {Bayes methods;Markov processes;Monte Carlo methods;optical radar;photon counting;radar imaging;remote sensing by laser beam;Bayesian spectral unmixing algorithm;Markov chain Monte Carlo algorithm;Poisson noise;anomaly detection capability;gamma Markov random fields;hierarchical Bayesian model;laser source;lidar-based range profiles;low photon count regime;robust estimation;sparse multispectral lidar waveforms;target reflectivity;Bayes methods;Imaging;Laser radar;Photonics;Robustness;Three-dimensional displays;Anomaly detection;Markov chain Monte Carlo;depth imaging;multispectral Lidar;robust spectral unmixing},
}
{Marnissi2017p722-737,
  author   = {Y. Marnissi and Y. Zheng and E. Chouzenoux and J. C. Pesquet},
  title    = {A Variational Bayesian Approach for Image Restoration } # 8212;Application to Image Deblurring With Poisson #{8211;Gaussian Noise},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {722-737},
  month    = {Dec},
  abstract = {In this paper, a methodology is investigated for signal recovery in the presence of non-Gaussian noise. In contrast with regularized minimization approaches often adopted in the literature, in our algorithm the regularization parameter is reliably estimated from the observations. As the posterior density of the unknown parameters is analytically intractable, the estimation problem is derived in a variational Bayesian framework where the goal is to provide a good approximation to the posterior distribution in order to compute posterior mean estimates. Moreover, a majorization technique is employed to circumvent the difficulties raised by the intricate forms of the non-Gaussian likelihood and of the prior density. We demonstrate the potential of the proposed approach through comparisons with state-of-the-art techniques that are specifically tailored to signal recovery in the presence of mixed Poisson-Gaussian noise. Results show that the proposed approach is efficient and achieves performance comparable with other methods where the regularization parameter is manually tuned from the ground truth.},
  doi      = {10.1109/TCI.2017.2700203},
  keywords = {Bayes methods;Gaussian noise;expectation-maximisation algorithm;image denoising;image restoration;maximum likelihood estimation;stochastic processes;estimation problem;image deblurring;image restoration-application;majorization technique;mixed Poisson-Gaussian noise;nonGaussian likelihood;nonGaussian noise;posterior density;posterior distribution;posterior mean estimates;regularization parameter;regularized minimization approaches;signal recovery;state-of-the-art techniques;variational Bayesian approach;variational Bayesian framework;Bayes methods;Degradation;Image restoration;Inverse problems;Minimization;Parameter estimation;Inverse problems;majorization;minimization;non-Gaussian noise;parameter estimation;restoration;variational Bayesian methods},
}

@Article{Mignard-Debise2017p798-810,
  author   = {L. Mignard-Debise and J. Restrepo and I. Ihrke},
  title    = {A Unifying First-Order Model for Light-Field Cameras: The Equivalent Camera Array},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {798-810},
  month    = {Dec},
  abstract = {Light-field photography is an extension of traditional photography that enables among other effects refocusing, viewpoint change, and aperture synthesis of still images by digital postprocessing. It achieves this capability by recording 4-dimensional radiance information rather than 2-dimensional integrated sensor irradiance. Consequently, optical design tools need to change in order to design these new devices. In this paper, we propose an optical first-order model that abstracts the architecture of any light-field camera as an equivalent camera array. This model enables a comparison between different designs and allows for a simulation of the effects of parameter modifications to a design. We present equations for optical properties such as the depth of field, the angle of view, as well as important parameters for algorithmic performance such as the triangulation baseline. We provide an experimental validation of our model by measuring the properties of a real light-field camera. We are able to extract unknown physical parameters of the system such as the focal length of the main lens.},
  doi      = {10.1109/TCI.2017.2699427},
  keywords = {cameras;image sensors;optical design techniques;photography;4-dimensional radiance information;equivalent camera array;light-field camera;light-field photography;optical design tools;optical first-order model;traditional photography;Calibration;Cameras;Lenses;Mathematical model;Optical imaging;Optical sensors;Computational optics;light-field imaging},
}

@Article{Ginosar2017p421-431,
  author   = {S. Ginosar and K. Rakelly and S. M. Sachs and B. Yin and C. Lee and P. Krähenbühl and A. A. Efros},
  title    = {A Century of Portraits: A Visual Historical Record of American High School Yearbooks},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {421-431},
  month    = {Sept},
  abstract = {Imagery offers a rich description of our world and communicates a volume and type of information that cannot be captured by text alone. Since the invention of the camera, an ever-increasing number of photographs document our “visual culture” complementing historical texts. Currently, this treasure trove of knowledge can only be analyzed manually by historians, and only at small scale. In this paper, we perform automated analysis on a large-scale historical image dataset. Our main contributions are: 1) A publicly available dataset of 168,055 (37,921 frontal-facing) American high school yearbook portraits. 2) Weakly supervised data-driven techniques to discover historical visual trends in fashion and identify date-specific visual patterns. 3) A classifier to predict when a portrait was taken, with median error of 4 years for women and 6 for men. 4) A new method for discovering and displaying the visual elements used by the classifier to perform the dating task, finding that they correspond to the tell-tale fashions of each era.},
  doi      = {10.1109/TCI.2017.2699865},
  keywords = {computer vision;data mining;history;image classification;learning (artificial intelligence);American high school yearbooks;automated large-scale historical image dataset analysis;camera;classifier;date-specific visual pattern;historical text;historical visual trend discovery;imagery;photographs;portraits;supervised data-driven technique;tell-tale fashion;visual culture;visual historical record;Data mining;Machine learning;Market research;Social factors;Statistics;Visualization;Data mining;deep learning;historical data;image dating},
}

@Article{Huang2017p763-773,
  author   = {J. Huang and M. Sun and J. Ma and Y. Chi},
  title    = {Super-Resolution Image Reconstruction for High-Density Three-Dimensional Single-Molecule Microscopy},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {763-773},
  month    = {Dec},
  abstract = {Single-molecule localization based super-resolution microscopy, by localizing a sparse subset of stochastically activated emitters in each frame, achieves subdiffraction-limit spatial resolution. Its temporal resolution, however, is constrained by the maximal density of activated emitters that can be successfully reconstructed. The state-of-the-art three-dimensional (3-D) reconstruction algorithm based on compressed sensing suffers from high computational complexity and gridding error due to model mismatch. In this paper, we propose a novel super-resolution algorithm for 3-D image reconstruction, dubbed TVSTORM, which promotes the sparsity of activated emitters without discretizing their locations. Several strategies are pursued to improve the reconstruction quality under the Poisson noise model, and reduce the computational time by an order-of-magnitude. Numerical results on both simulated and cell imaging data are provided to validate the favorable performance of the proposed algorithm.},
  doi      = {10.1109/TCI.2017.2699425},
  keywords = {compressed sensing;computational complexity;image reconstruction;image resolution;optical microscopy;stochastic processes;3D image reconstruction;Poisson noise model;cell imaging data;compressed sensing;computational complexity;high-density three-dimensional single-molecule microscopy;single-molecule localization;stochastically activated emitters;subdiffraction-limit spatial resolution;superresolution image reconstruction;superresolution microscopy;temporal resolution;Image reconstruction;Microscopy;Signal resolution;Spatial resolution;Three-dimensional displays;Image reconstruction;sparse inverse problems;superresolution;total-variation norm},
}

@Article{Kumar2017p264-274,
  author   = {R. Kumar and O. López and D. Davis and A. Y. Aravkin and F. J. Herrmann},
  title    = {Beating Level-Set Methods for 5-D Seismic Data Interpolation: A Primal-Dual Alternating Approach},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {264-274},
  month    = {June},
  abstract = {Acquisition cost is a crucial bottleneck for seismic workflows, and low-rank formulations for data interpolation allow practitioners to “fill in” data volumes from critically subsampled data acquired in the field. Tremendous size of seismic data volumes required for seismic processing remains a major challenge for these techniques. Residual-constrained formulations require less parameter tuning when the target noise floor is known. We propose a new approach to solve residual constrained formulations for interpolation. We represent the data volume in a compressed manner using low-rank matrix factors, and build a block-coordinate algorithm with constrained convex subproblems that are solved with a primal-dual splitting scheme. The develop optimization framework works on the whole seismic temporal frequency slices and does not require windowing or nontrivial sorting of seismic data. The new approach is competitive with state of the art level-set algorithms that interchange the role of objectives with constraints. We use the new algorithm to successfully interpolate a large scale 5-D seismic data volume (upto 1010 data points), generated from the geologically complex synthetic 3-D Compass velocity model, where 80% of the data have been removed. We also develop a robust extension of the primal-dual approach to deal with the outliers (or noise) in the data.},
  doi      = {10.1109/TCI.2017.2693966},
  keywords = {data acquisition;interpolation;matrix algebra;seismology;5D seismic data interpolation;acquisition cost;block-coordinate algorithm;critically subsampled data;data interpolation;data volumes;level-set methods;low-rank formulations;low-rank matrix factors;primal-dual alternating approach;primal-dual approach;residual-constrained formulations;seismic data;seismic data volumes;seismic processing;seismic temporal frequency slices;seismic workflows;velocity model;Imaging;Interpolation;Optimization;Receivers;Symmetric matrices;Tensile stress;Three-dimensional displays;Alternating minimization;matrix completion;primal-dual splitting;seismic data;seismic trace interpolation},
}

@Article{Ravishankar2017p694-709,
  author   = {S. Ravishankar and R. R. Nadakuditi and J. A. Fessler},
  title    = {Efficient Sum of Outer Products Dictionary Learning (SOUP-DIL) and Its Application to Inverse Problems},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {694-709},
  month    = {Dec},
  abstract = {The sparsity of signals in a transform domain or dictionary has been exploited in applications, such as compression, denoising, and inverse problems. More recently, data-driven adaptation of synthesis dictionaries has shown promise compared to analytical dictionary models. However, dictionary learning problems are typically nonconvex and NP-hard, and the usual alternating minimization approaches for these problems are often computationally expensive, with the computations dominated by the NP-hard synthesis sparse coding step. This paper exploits the ideas that drive algorithms such as K-SVD, and investigates in detail efficient methods for aggregate sparsity penalized dictionary learning by first approximating the data with a sum of sparse rank-one matrices (outer products) and then using a block coordinate descent approach to estimate the unknowns. The resulting block coordinate descent algorithms involve efficient closed-form solutions. Furthermore, we consider the problem of dictionary-blind image reconstruction, and propose novel and efficient algorithms for adaptive image reconstruction using block coordinate descent and sum of outer products methodologies. We provide a convergence study of the algorithms for dictionary learning and dictionary-blind image reconstruction. Our numerical experiments show the promising performance and speed-ups provided by the proposed methods over previous schemes in sparse data representation and compressed sensing-based image reconstruction.},
  doi      = {10.1109/TCI.2017.2697206},
  keywords = {gradient methods;image reconstruction;image representation;iterative methods;minimisation;sparse matrices;NP-hard synthesis;aggregate sparsity penalized dictionary learning;alternating minimization approach;block coordinate descent approach;data-driven adaptation;dictionary-blind image reconstruction;inverse problems;outer products dictionary learning;signal sparsity;soup-dil;sparse data representation;sparse rank-one matrices;synthesis dictionaries;Algorithm design and analysis;Compressed sensing;Image reconstruction;Inverse problems;Sparse matrices;Compressed sensing;convergence analysis;dictionary learning;fast algorithms;inverse problems;sparsity},
}

@Article{Kazantsev2017p682-693,
  author   = {D. Kazantsev and F. Bleichrodt and T. van Leeuwen and A. Kaestner and P. J. Withers and K. J. Batenburg and P. D. Lee},
  title    = {A Novel Tomographic Reconstruction Method Based on the Robust Student's t Function For Suppressing Data Outliers},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {682-693},
  month    = {Dec},
  abstract = {Regularized iterative reconstruction methods in computed tomography can be effective when reconstructing from mildly inaccurate undersampled measurements. These approaches will fail, however, when more prominent data errors, or outliers, are present. These outliers are associated with various inaccuracies of the acquisition process: defective pixels or miscalibrated camera sensors, scattering, missing angles, etc. To account for such large outliers, robust data misfit functions, such as the generalized Huber function, have been applied successfully in the past. In conjunction with regularization techniques, these methods can overcome problems with both limited data and outliers. This paper proposes a novel reconstruction approach using a robust data fitting term which is based on the Student's t distribution. This misfit promises to be even more robust than the Huber misfit as it assigns a smaller penalty to large outliers. We include the total variation regularization term and automatic estimation of a scaling parameter that appears in the Student's t function. We demonstrate the effectiveness of the technique by using a realistic synthetic phantom and also apply it to a real neutron dataset.},
  doi      = {10.1109/TCI.2017.2694607},
  keywords = {computerised tomography;image reconstruction;iterative methods;statistical distributions;Huber misfit;computed tomography;data fitting;data misfit functions;data outliers;generalized Huber function;regularized iterative reconstruction;robust student t function;student t distribution;tomographic reconstruction;Attenuation;Image reconstruction;Neutrons;Robustness;X-ray tomography;Limited angle regularization;X-ray CT;neutron tomography;proximal point;ring artifacts;robust statistics;zingers},
}

@Article{Wang2017p355-368,
  author   = {P. Wang and L. Venkataramanan and V. Jain},
  title    = {Sparse Clustered Bayesian-Inspired $T_{1}-T_{2}$ Inversion From Borehole NMR Measurements},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {355-368},
  month    = {June},
  abstract = {This paper is interested in joint T1 - T2 inversion from borehole nuclear magnetic resonance (NMR) measurements when a limited number of wait times (WTs) are used. Unlike a straightforward representation of the multi-WT NMR measurements over an overcomplete kernel matrix and using a sparsity-aware inversion method, the paper proposes to exploit the two-dimensional sparsity in the T1 - T2 domain and the smoothness (i.e., the local cluster feature) simultaneously by using a sparse clustered signal representation. To enable a fully automated workflow for borehole NMR logging operations, a sparse clustered Bayesian-inspired algorithm is developed to exploit the sparsity in the solution space while learning the noise statistics. It in turn mitigates a cumbersome issue of selecting regularization parameters in deterministic sparsity-aware methods and reduces the human intervention. Several enhancements are discussed to reduce the computational complexity and improve the robustness at low signal-to-noise ratios. The proposed algorithm has been tested on synthetic datasets and lab samples and the results confirm its effectiveness.},
  doi      = {10.1109/TCI.2017.2693562},
  keywords = {geophysical techniques;nuclear magnetic resonance;Bayesian-inspired algorithm;NMR logging operations;T1 - T2 inversion;borehole NMR measurements;borehole nuclear magnetic resonance;cumbersome issue;human intervention;two-dimensional sparsity;Bayes methods;Clustering algorithms;Magnetization;Nuclear magnetic resonance;Sparse matrices;Time measurement; $T_1-T_2$ inversion;Borehole logging;nuclear magnetic resonance;sparse Bayesian learning;sparse signal recovery},
}

@Article{Ferraris2017p175-186,
  author   = {V. Ferraris and N. Dobigeon and Q. Wei and M. Chabert},
  title    = {Robust Fusion of Multiband Images With Different Spatial and Spectral Resolutions for Change Detection},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {175-186},
  month    = {June},
  issn     = {2333-9403},
  abstract = {Archetypal scenarios for change detection generally consider two images acquired through sensors of the same modality. However, in some specific cases such as emergency situations, the only images available may be those acquired through different kinds of sensors. More precisely, this paper addresses the problem of detecting changes between two multiband optical images characterized by different spatial and spectral resolutions. This sensor dissimilarity introduces additional issues in the context of operational change detection. To alleviate these issues, classical change detection methods are applied after independent preprocessing steps (e.g., resampling) used to get the same spatial and spectral resolutions for the pair of observed images. Nevertheless, these preprocessing steps tend to throw away relevant information. Conversely, in this paper, we propose a method that more effectively uses the available information by modeling the two observed images as spatial and spectral versions of two (unobserved) latent images characterized by the same high spatial and high spectral resolutions. As they cover the same scene, these latent images are expected to be globally similar except for possible changes in sparse spatial locations. Thus, the change detection task is envisioned through a robust multiband image fusion method, which enforces the differences between the estimated latent images to be spatially sparse. This robust fusion problem is formulated as an inverse problem, which is iteratively solved using an efficient block-coordinate descent algorithm. The proposed method is applied to real panchromatic, multispectral, and hyperspectral images with simulated realistic and real changes. A comparison with state-of-the-art change detection methods evidences the accuracy of the proposed strategy.},
  doi      = {10.1109/TCI.2017.2692645},
  keywords = {geophysical image processing;hyperspectral imaging;image fusion;image resolution;inverse problems;remote sensing;archetypal scenarios;block-coordinate descent algorithm;classical change detection methods;hyperspectral images;independent preprocessing steps;inverse problem;latent images;multiband optical images;multispectral images;operational change detection;panchromatic image;robust multiband image fusion method;sensor dissimilarity;sparse spatial locations;spatial resolutions;spectral resolutions;Degradation;Optical imaging;Optical sensors;Robustness;Spatial resolution;Change detection;different resolutions;hyperspectral imagery;image fusion;multispectral imagery},
}

@Article{Demanet2017p282-295,
  author   = {L. Demanet and V. Jugnon},
  title    = {Convex Recovery From Interferometric Measurements},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {282-295},
  month    = {June},
  abstract = {This paper discusses some questions that arise when a linear inverse problem involving Ax = b is reformulated in the interferometric framework, where quadratic combinations of b are considered as data in place of b. First, we show a deterministic recovery result for vectors x from measurements of the form (Ax)i (Ax)̅j for some left-invertible A. Recovery is exact, or stable in the noisy case, when the couples (i, j) are chosen as edges of a well-connected graph. One possible way of obtaining the solution is as a feasible point of a simple semidefinite program. Furthermore, we show how the proportionality constant in the error estimate depends on the spectral gap of a data-weighted graph Laplacian. Second, we present a new application of this formulation to interferometric waveform inversion, where products of the form (Ax)i (Ax)̅j in frequency encode generalized cross correlations in time. We present numerical evidence that interferometric inversion does not suffer from the loss of resolution generally associated with interferometric imaging, and can provide added robustness with respect to specific kinds of kinematic uncertainties in the forward model A.},
  doi      = {10.1109/TCI.2017.2688923},
  keywords = {geophysical techniques;graph theory;interferometry;inverse problems;convex recovery;data-weighted graph Laplacian spectral gap;error estimate;frequency encode generalized cross correlation;graph theory;interferometric inversion;interferometric measurement;kinematic uncertainty;linear inverse problem;numerical evidence;quadratic combination;simple semidefinite program;Geophysical measurements;Imaging;Laplace equations;Optical interferometry;Radar imaging;Geoscience;imaging;remote sensing, rank3},
}

@Article{Tsinos2017p160-174,
  author   = {C. G. Tsinos and A. A. Rontogiannis and K. Berberidis},
  title    = {Distributed Blind Hyperspectral Unmixing via Joint Sparsity and Low-Rank Constrained Non-Negative Matrix Factorization},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {160-174},
  month    = {June},
  abstract = {Hyperspectral unmixing is a crucial processing step in remote sensing image analysis. Its aim is the decomposition of each pixel in a hyperspectral image into a number of materials, the so-called endmembers, and their corresponding abundance fractions. Among the various unmixing approaches that have been suggested in the literature, we are interested here in unsupervised techniques that rely on some form of non-negative Matrix factorization (NMF). NMF-based techniques provide an easy way to simultaneously estimate the endmembers and their corresponding abundances, though they suffer from mediocre performance and high computational complexity due to the nonconvexity of the involved cost function. Improvements in performance have been recently achieved by imposing additional constraints to the NMF optimization problem related to the sparsity of the abundances. Another feature of hyperspectral images that can be exploited is their high spatial correlation, which is translated into the low rank of the involved abundance matrices. Motivated by this, in this paper we propose a novel unmixing method that is based on a simultaneously sparse and low-rank constrained NMF. In addition, prompted by the rapid evolution of multicore processors and graphics processing units, we devise a distributed unmixing scheme that processes in parallel different parts of the image. The proposed distributed unmixing algorithm achieves improved performance and faster convergence than existing state-of-the-art techniques as it is verified by extensive simulations on synthetic and real hyperspectral data.},
  doi      = {10.1109/TCI.2017.2693967},
  keywords = {computational complexity;geophysical image processing;hyperspectral imaging;matrix decomposition;multiprocessing systems;optimisation;parallel processing;remote sensing;NMF optimization problem;NMF-based techniques;abundance fractions;abundance matrices;computational complexity;cost function nonconvexity;distributed blind hyperspectral unmixing;endmembers;graphics processing units;hyperspectral image;joint sparsity;low-rank constrained NMF;low-rank constrained nonnegative matrix factorization;mediocre performance;multicore processors;parallel processing;pixel decomposition;real hyperspectral data;remote sensing image analysis;sparse constrained NMF;spatial correlation;synthetic hyperspectral data;unsupervised techniques;Cost function;Hyperspectral imaging;Matrix decomposition;Sparse matrices; $L_1$ -regularization;Hyperspectral unmixing;non-negative matrix mactorization (NMF);nuclear norm;sparse estimation},
}

@Article{Parada-Mayorga2017p202-216,
  author   = {A. Parada-Mayorga and G. R. Arce},
  title    = {Colored Coded Aperture Design in Compressive Spectral Imaging via Minimum Coherence},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {202-216},
  month    = {June},
  abstract = {Colored coded aperture optimization in compressive spectral imaging is discussed. Based on the analysis of the coherence of the underlying sensing matrix, a general family of codes is derived. These designs lead to reconstructions of multispectral scenes of better quality than the ones obtained using the traditional random black and white coded apertures. The approach used in this work exploits the structure of the sensing matrices and reduces the problem of the design of a large-scale matrix to a subset of substantially smaller problems for which it is possible to obtain a closed form solution, leading to fast design algorithms.},
  doi      = {10.1109/TCI.2017.2692649},
  keywords = {compressed sensing;image coding;image reconstruction;matrix algebra;optimisation;closed form solution;colored coded aperture design;colored coded aperture optimization;compressive spectral imaging;large-scale matrix design;minimum coherence;multispectral scene reconstruction;random black-white coded apertures;sensing matrix;Apertures;Image reconstruction;Optimization;Sensors;Transfer functions;CASSI system;coded aperture design;coherence of the sensing matrix;compressive spectral imaging;multispectral imaging},
}

@Article{Mihoubi2017p982-995,
  author   = {S. Mihoubi and O. Losson and B. Mathon and L. Macaire},
  title    = {Multispectral Demosaicing Using Pseudo-Panchromatic Image},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {982-995},
  month    = {Dec},
  abstract = {Single-sensor color cameras, which classically use a color filter array to sample RGB channels, have recently been extended to the multispectral domain. To sample more than three wavelength bands, such systems use a multispectral filter array that provides a raw image in which a single channel value is available at each pixel. A demosaicing procedure is then needed to estimate a fully defined multispectral image. In this paper, we review multispectral demosaicing methods and propose a new one based on the pseudo-panchromatic image (PPI). Pixel values in the PPI are computed as the average spectral values. Experimental results show that our method provides estimated images of better quality than classical ones.},
  doi      = {10.1109/TCI.2017.2691553},
  keywords = {cameras;image colour analysis;image filtering;image segmentation;image sensors;optical filters;color filter array;multispectral demosaicing methods;multispectral domain;multispectral filter array;multispectral image;pixel values;pseudopanchromatic image single-sensor color cameras;raw image;sample RGB channels;single channel value;Cameras;Channel estimation;Hyperspectral imaging;Image color analysis;Lighting;Illumination;multispectral filter array (MSFA);multispectral image demosaicing;pseudo-panchromatic image (PPI);spatial correlation;spectral correlation},
}

@Article{Dang2017p605-616,
  author   = {C. Dang and H. Radha},
  title    = {Fast Single-Image Super-Resolution Via Tangent Space Learning of High-Resolution-Patch Manifold},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {605-616},
  month    = {Dec},
  abstract = {Manifold assumption has been used in example-based super-resolution (SR) reconstruction from a single frame. Previous manifold-based SR approaches (more generally example-based SR) mainly focus on analyzing the co-occurrence properties of low-resolution and high-resolution patches. This paper develops a novel single-image SR approach based on linear approximation of the high-resolution-patch space using a sparse subspace clustering algorithm. The approach exploits the underlying high-resolution patches nonlinear space by considering it as a low-dimensional manifold in a high-dimensional Euclidean space, and by considering each training high-resolution-patch as a sample from the manifold. We utilize the sparse subspace clustering algorithm to create the set of low-dimensional linear spaces that are considered, approximately, as tangent spaces at the high-resolution samples. Furthermore, we consider and analyze each tangent space as one point in a Grassmann manifold, which helps to compute geodesic pairwise distances among these tangent spaces. An optimal subset of these tangent spaces is then selected using a min-max algorithm. The optimal subset reduces the computational cost in comparison with using the full set of tangent spaces while still preserving the quality of the high-resolution image reconstruction. In addition, we perform hierarchical clustering on the optimal subset based on the geodesic distance, which helps to further achieve much faster SR algorithm. We also analytically prove the validity of the geodesic distance based clustering under the proposed framework. A comparison of the obtained results with other related methods in both high-resolution image quality and computational complexity clearly indicates the viability of the proposed framework.},
  doi      = {10.1109/TCI.2017.2691554},
  keywords = {approximation theory;computational complexity;image reconstruction;image resolution;learning (artificial intelligence);minimax techniques;pattern clustering;Grassmann manifold;SR reconstruction;computational complexity;example-based SR;example-based super-resolution reconstruction;fast single-image super-resolution;geodesic pairwise distances;hierarchical clustering;high-dimensional Euclidean space;high-resolution image quality;high-resolution image reconstruction;high-resolution-patch manifold;high-resolution-patch space;high-resolution-patch training;linear approximation;low-dimensional linear spaces;low-dimensional manifold;low-resolution patches;manifold assumption;manifold-based SR approaches;min-max algorithm;single-image SR approach;sparse subspace clustering algorithm;tangent space learning;Clustering algorithms;Linear approximation;Sparse matrices;Spatial resolution;Training;Image super-resolution;manifold;sparse subspace clustering;tangent space},
}

@Article{Nose-Filho2017p275-281,
  author   = {K. Nose-Filho and J. M. T. Romano},
  title    = {Low-Rank Decomposition Based on Disjoint Component Analysis With Applications in Seismic Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {275-281},
  month    = {June},
  issn     = {2333-9403},
  abstract = {Low-rank decomposition plays a fundamental role in signal processing and computational imaging, due to the possibility of decomposing a signal into semantic components. The classical singular value decomposition (SVD) separates globally correlated components from uncorrelated ones. Modified versions of SVD that have been recently proposed allow the separation between horizontal and vertical components of the image. These versions explore blind source separation techniques, specially the well-known independent component analysis (ICA). However, these existing techniques fail in separating horizontal or vertical signals that are linearly independent to each other. In this paper, we propose a new low-rank decomposition method based on disjoint component analysis (DCA), namely, SVD-DCA. In contrast with the SVD and the SVD-ICA techniques, this new method is able to separate horizontal from vertical events, as well as to separate horizontal or vertical components that are linearly independent to each other. The proposed method is evaluated in two relevant applications in seismic imaging, the attenuation of multiple reflections and the attenuation of ground-roll noise. The results involving these applications are obtained with real marine and land seismic data, respectively.},
  doi      = {10.1109/TCI.2017.2691548},
  keywords = {blind source separation;geophysical image processing;independent component analysis;seismology;singular value decomposition;SVD-DCA technique;SVD-ICA technique;blind source separation techniques;disjoint component analysis;ground-roll noise attenuation;horizontal image components;horizontal signals;independent component analysis;land seismic data;low-rank decomposition method;marine data;seismic imaging;vertical image components;vertical signals;Attenuation;Computational modeling;Imaging;Linear matrix inequalities;Matrix decomposition;Signal processing;Singular value decomposition;Disjoint component analysis;ground-roll attenuation;image decomposition;low-rank modeling;multiples attenuation;seismic signal processing},
}

@Article{Nadir2017p876-890,
  author   = {Z. Nadir and M. S. Brown and M. L. Comer and C. A. Bouman},
  title    = {A Model-Based Iterative Reconstruction Approach to Tunable Diode Laser Absorption Tomography},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {876-890},
  month    = {Dec},
  abstract = {Tunable diode laser absorption tomography (TDLAT) has emerged as a popular nonintrusive technique for simultaneous sensing of gas concentration and temperature. However, TDLAT imaging of concentration and temperature is an ill-posed, nonlinear inverse problem. Major challenges of TDLAT imaging include a highly nonlinear forward model, few projection measurements, and limited training data. We propose a novel model-based iterative reconstruction (MBIR) framework for TDLAT imaging. To do this, we formulate a nonlinear forward model for TDLAT that incorporates the physics of light absorbance through gaseous media, and we couple it with a non-Gaussian prior model based on a Gaussian mixture distribution that can be trained using a sparse training set. We show that the resulting MAP estimation problem can be solved using majorization minimization together with a novel multigrid optimization algorithm that solves the resulting optimization problem using an orthogonal basis set. Reconstructions using simulated TDLAT datasets show that our TDLAT-MBIR method can reduce reconstruction error while also resulting in a very computationally efficient algorithm.},
  doi      = {10.1109/TCI.2017.2690143},
  keywords = {Gaussian processes;computerised tomography;expectation-maximisation algorithm;image reconstruction;inverse problems;iterative methods;measurement by laser beam;medical image processing;temperature measurement;MAP estimation problem;MBIR framework;TDLAT datasets;TDLAT imaging;TDLAT-MBIR method;gas concentration;limited training data;model-based iterative reconstruction framework;nonGaussian prior model;nonintrusive technique;nonlinear forward model;nonlinear inverse problem;optimization problem;sparse training set;temperature;tunable diode laser absorption tomography;Computational modeling;Frequency measurement;Image reconstruction;Measurement by laser beam;Temperature measurement;GMM;Gaussian mixture models;TDLAS;TDLAT;non-convex optimization;non-homogeneous image model;tomography;tunable diode laser absorption spectroscopy;tunable diode laser absorption tomography},
}

@Article{Takala2017p344-354,
  author   = {M. Takala and T. D. Hämäläinen and S. Pursiainen},
  title    = {The Effect of Hardware-Computed Travel Time on Localization Accuracy in the Inversion of Experimental (Acoustic) Waveform Data},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {344-354},
  month    = {June},
  issn     = {2333-9403},
  abstract = {This study aims to advance hardware-level computations for travel-time tomography applications in which the wavelength is close to the diameter of the information that has to be recovered. Such can be the case, for example, in the imaging applications of 1) biomedical physics; 2) astrogeophysics; and 3) civil engineering. Our aim is to shed light on the effect of that preprocessing the digital waveform signal has on the inversion results and to find computational solutions that guarantee robust inversion when there are incomplete and/or noisy measurements. We describe a hardware-level implementation for integrated and thresholded travel-time computation (ITT and TTT). We compare the ITT and TTT approaches in inversion analysis with experimental acoustic travel-time data recorded using a ring geometry for the transmission and measurement points. The results obtained suggest that ITT is essential for maintaining the robustness of the inversion with imperfect signal digitization and sparsity. In order to ensure the relevance of the results, the specifications of the test setup were related to those of applications 1-3.},
  doi      = {10.1109/TCI.2017.2686698},
  keywords = {computerised tomography;image processing;ITT;TTT;acoustic waveform data;astrogeophysics;biomedical physics;civil engineering;digital waveform signal;hardware-computed travel time;integrated travel-time computation;localization accuracy;signal digitization;thresholded travel-time computation;travel-time tomography applications;Acoustics;Biomedical measurement;Extraterrestrial measurements;Mathematical model;Robustness;Tomography;Fields-programmable gate array (FPGA);high-level synthesis;inverse imaging;travel-time measurements;waveform tomography},
}

@Article{Satat2017p398-407,
  author   = {G. Satat and M. Tancik and R. Raskar},
  title    = {Lensless Imaging With Compressive Ultrafast Sensing},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {398-407},
  month    = {Sept},
  abstract = {Lensless imaging is an important and challenging problem. One notable solution to lensless imaging is a single-pixel camera that benefits from ideas central to compressive sampling. However, traditional single-pixel cameras require many illumination patterns that result in a long acquisition process. Here, we present a method for lensless imaging based on compressive ultrafast sensing. Each sensor acquisition is encoded with a different illumination pattern and produces a time series where time is a function of the photon's origin in the scene. Currently available hardware with picosecond time resolution enables time tagging photons as they arrive to an omnidirectional sensor. This allows lensless imaging with significantly fewer patterns compared to regular single-pixel imaging. To that end, we develop a framework for designing lensless imaging systems that use ultrafast detectors. We provide an algorithm for ideal sensor placement and an algorithm for optimized active illumination patterns. We show that efficient lensless imaging is possible with ultrafast measurement and compressive sensing. This paves the way for novel imaging architectures and remote sensing in extreme situations where imaging with a lens is not possible.},
  doi      = {10.1109/TCI.2017.2684624},
  keywords = {cameras;compressed sensing;data acquisition;image sensors;optical sensors;sensor placement;time series;compressive sampling;compressive sensing;compressive ultrafast sensing;image acquisition process;imaging architecture;lensless imaging systems;omnidirectional sensor;optimized active illumination pattern;picosecond time resolution;remote sensing;sensor acquisition;sensor placement;single-pixel camera;single-pixel imaging;time series;ultrafast detector;ultrafast measurement;Cameras;Compressed sensing;Detectors;Image resolution;Lighting;Compressed sensing;digital cameras;lenses;optical imaging;optical sensors},
}

@Article{Mojabi2017p864-875,
  author   = {P. Mojabi and J. LoVetri},
  title    = {Evaluation of Balanced Ultrasound Breast Imaging Under Three Density Profile Assumptions},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {864-875},
  month    = {Dec},
  abstract = {A balanced inverse scattering algorithm for ultrasonic breast imaging is developed to simultaneously reconstruct quantitative images of the breast's ultrasonic properties. These properties are the inhomogeneous compressibility, attenuation, and density. Three scenarios are considered for this inversion algorithm. First, all the properties are assumed to be independent. The assumption of a linear relation between the contrast of compressibility and inverse density is then considered in the second scenario, whereas the density variation is neglected in the third scenario. The image corresponding to the attenuation is of particular importance because breast tumors can be better identified using this property in comparison with compressibility and density images. However, this contrast is often poorly reconstructed because the magnitude of this contrast in the mathematical formulation of the problem is generally smaller than the magnitude of the contrasts of the other two properties. To overcome this problem, a novel balancing method is applied to all these three inversion algorithms so as to enhance the reconstruction results. Using synthetic data from MRI-based breast models, it is demonstrated that the use of the proposed balancing scheme enhances the reconstruction results of all these algorithms and, in particular, enhances their reconstructed images corresponding to the attenuation profile.},
  doi      = {10.1109/TCI.2017.2678280},
  keywords = {biological organs;biomedical ultrasonics;cancer;image reconstruction;mammography;medical image processing;tumours;MRI-based breast models;balanced inverse scattering algorithm;balanced ultrasound breast imaging;balancing scheme;breast tumors;density variation;image reconstruction;inversion algorithm;Attenuation;Breast;Image coding;Image reconstruction;Inverse problems;Tomography;Balanced inversion;breast imaging;inverse scattering;ultrasound tomography},
}

@Article{Soncco2017p187-201,
  author   = {D. C. Soncco and C. Barbanson and M. Nikolova and A. Almansa and Y. Ferrec},
  title    = {Fast and Accurate Multiplicative Decomposition for Fringe Removal in Interferometric Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {187-201},
  month    = {June},
  abstract = {Airborne hyperspectral images can be efficiently obtained with imaging static Fourier transform spectrometers. However, to be effective on any location, this technology requires to know the relief of the scene. This is not a straightforward process, as the horizontal interference fringes on the images, which are necessary for spectrum construction, prevent efficient stereoscopic processing. We present a novel variational model for multiplicative image decomposition to separate the fringes from the panchromatic image of the scene. This multiplicative model is much more physically accurate than previous additive decomposition models inspired by cartoon-texture decomposition. It combines fully smoothed total variation operators and one-dimensional (1-D) Fourier transform. Smoothed total variation is adopted to avoid staircasing artifacts caused by traditional total variation regularization. The use of a 1-D Fourier transform is suggested by the geometry of the fringes, in order to circumvent the lack of horizontal periodicity in the interferometric pattern. We also present an optimization algorithm. Finally, a second algorithm is introduced, whose convergence is not mathematically guaranteed. However, it systematically approaches the solution of the first one in much less computation time. Our experimental evaluation on real and simulated images shows that the proposed model separates fringes from the panchromatic image very accurately and that this accuracy significantly improves subpixel stereo matching results.},
  doi      = {10.1109/TCI.2017.2678279},
  keywords = {Fourier transform spectrometers;Fourier transforms;concave programming;convex programming;geophysical image processing;hyperspectral imaging;image matching;interferometry;mathematical operators;spectral analysis;stereo image processing;1D Fourier transform;airborne hyperspectral images;computation time;convergence;fringe geometry;fringe removal;fully-smoothed total variation operators;horizontal periodicity;imaging static Fourier transform spectrometers;interferometric images;interferometric pattern;multiplicative image decomposition;one-dimensional Fourier transform;optimization algorithm;panchromatic image;real images;simulated images;subpixel stereo matching improvement;Fourier transforms;Hyperspectral imaging;Optical imaging;Optical interferometry;Optical sensors;Bi-convex optimisation;computational hyperspectral imaging;image restoration;interferometric imaging;inverse problems;multi-view stereo;multiplicative image decomposition;nonconvex variational models;proximal algorithms},
}

@Article{Bevacqua2017p296-304,
  author   = {M. T. Bevacqua and L. Crocco and L. D. Donato and T. Isernia},
  title    = {Non-Linear Inverse Scattering via Sparsity Regularized Contrast Source Inversion},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {296-304},
  month    = {June},
  issn     = {2333-9403},
  abstract = {Two compressive sensing inspired approaches for the solution of non-linear inverse scattering problems are introduced and discussed. Differently from the sparsity promoting approaches proposed in most of the papers published in the literature, the two methods here tackle the problem in its full non-linearity, by adopting a contrast source inversion scheme. In the first approach, the 11-norm of the unknown is added as a weighted penalty term to the contrast source cost functional. The second, and (to the best of our knowledge) completely original, approach enforces sparsity by constraining the solution of the non-linear problem into a convex set defined by the 11 -norm of the unknown. A numerical assessment against a widely used benchmark example (the “Austria” profile) is given to assess the capabilities of the proposed approaches. Notably, the two approaches can be applied to any kind of basis functions and they can successfully tackle both reduced number of data (with respect to Nyquist sampling) and/or overcomplete dictionaries.},
  doi      = {10.1109/TCI.2017.2675708},
  keywords = {compressed sensing;compressive sensing;contrast source cost functional;contrast source inversion scheme;nonlinear inverse scattering;sparsity promoting approaches;sparsity regularized contrast source inversion;weighted penalty term;Antenna measurements;Biomedical measurement;Imaging;Inverse problems;Microwave measurement;Minimization;Sensors;Compressive sensing;compressed measurements;contrast-source inversion method;microwave imaging;non linear inverse problem;stationary wavelet transform, rank3},
}

@Article{Liu2017p617-632,
  author   = {R. Liu and L. Fu and B. De Man and H. Yu},
  title    = {GPU-Based Branchless Distance-Driven Projection and Backprojection},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {617-632},
  month    = {Dec},
  abstract = {Projection and backprojection operations are essential in a variety of image reconstruction and physical correction algorithms in computed tomography (CT). The distance-driven (DD) projection and backprojection are widely used for their favorable image quality properties, highly sequential memory access pattern and low arithmetic cost. However, a typical DD implementation has an inner loop that adjusts the calculation depending on the relative position between voxel and detector cell boundaries. The irregularity of the branch behavior makes it inefficient to be implemented on massively parallel computing devices, such as graphics processing units (GPUs). Such irregular branch behaviors can be eliminated by factorizing the DD operation as three branchless steps: integration, linear interpolation, and differentiation, all of which are highly amenable to massive vectorization. In this paper, we implement and evaluate a highly parallel branchless DD algorithm for three-dimensional cone beam CT. The algorithm utilizes the texture memory and hardware interpolation on GPUs to achieve fast computational speed. The developed branchless DD algorithm achieved 137-fold speedup for forward projection and 188-fold speedup for backprojection relative to a single-thread CPU implementation. Compared with a state-of-the-art 32-thread CPU implementation, the proposed branchless DD achieved eight-fold acceleration for forward projection and ten-fold acceleration for backprojection. The GPU-based branchless DD method was evaluated by iterative reconstruction algorithms with both simulation and real datasets. It obtained visually identical images as the CPU reference algorithm.},
  doi      = {10.1109/TCI.2017.2675705},
  keywords = {computerised tomography;graphics processing units;image reconstruction;interpolation;iterative methods;medical image processing;3D cone beam CT;CPU reference algorithm;GPU;backprojection;branchless DD algorithm;branchless distance-driven projection;computed tomography;detector cell boundaries;graphics processing units;hardware interpolation;highly parallel branchless DD algorithm;image quality;image reconstruction;iterative reconstruction algorithms;linear interpolation;parallel computing devices;physical correction algorithms;single-thread CPU implementation;texture memory;Algorithm design and analysis;Computational modeling;Computed tomography;Detectors;Graphics processing units;Image reconstruction;Branchless distance-driven;GPU;backprojection;computed tomography;projection;reconstruction},
}

@Article{Zhu2017p966-981,
  author   = {C. Zhu and L. Yu and Z. Yan and S. Xiang},
  title    = {Frequency Estimation of the Plenoptic Function Using the Autocorrelation Theorem},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {966-981},
  month    = {Dec},
  abstract = {The frequency estimation of the plenoptic function (POF) is an important research topic in spectral analysis for determining the minimum sampling rate of image-based rendering. In this paper, we mathematically derive a frequency estimation function of the POF using the autocorrelation theory. The autocorrelation function (ACF) of the POF is studied along both the spatial and image plane frequency axes. The influence of the scene's complexity and depth on the ACF of the POF is analyzed. Furthermore, we study the frequency estimation error to analyze the performance of the method. Existing techniques typically use Fourier transformation to determine the frequency of the POF. The technique presented herein simply starts from measurements of the light field in a finite number of positions, and the information from the light field is analyzed in the spatial domain. Finally, experimental results are presented to demonstrate that the proposed method can effectively estimate the frequency of the POF. The results are shown to be in good agreement with traditional methods.},
  doi      = {10.1109/TCI.2017.2671450},
  keywords = {Fourier transforms;frequency estimation;image sampling;rendering (computer graphics);spectral analysis;Fourier transformation;POF;autocorrelation function;autocorrelation theory;frequency estimation error;frequency estimation function;image plane frequency axes;image-based rendering;minimum sampling rate;plenoptic function;scene complexity;spatial domain;spectral analysis;Cameras;Frequency estimation;Frequency-domain analysis;Optical fibers;Rendering (computer graphics);Spectral analysis;autocorrelation function (ACF);frequency estimation;image-based rendering;plenoptic function (POF);sampling},
}

@Article{Li2017p749-762,
  author   = {D. Li and Z. Wang},
  title    = {Video Superresolution via Motion Compensation and Deep Residual Learning},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {749-762},
  month    = {Dec},
  abstract = {Video superresolution (SR) techniques are of essential usages for high-resolution display devices due to the current lack of high-resolution videos. Although many algorithms have been proposed, video SR still remains a very challenging inverse problem under different conditions. In this paper, we propose a new method for video SR named motion compensation and residual net (MCResNet). We use optical flow algorithm for motion estimation and motion compensation as a preprocessing step. Then, we employ a novel deep residual convolutional neural network (CNN) to predict a high-resolution image using multiple motion compensated observations. The new residual CNN model preserves the low-frequency contents and facilitates the restoration of high-frequency details. Our method is able to handle large and complex motions adaptively. Extensive experimental results validate that our proposed method outperforms state-of-the-art single-image-based and multi-frame-based algorithms for video SR quantitatively and qualitatively.},
  doi      = {10.1109/TCI.2017.2671360},
  keywords = {image resolution;image restoration;image sequences;inverse problems;learning (artificial intelligence);motion compensation;motion estimation;neural nets;video signal processing;MCResNet;complex motions;deep residual convolutional neural network;deep residual learning;high-frequency details restoration;high-resolution display devices;high-resolution image;high-resolution videos;inverse problem;low-frequency contents;motion compensation;motion estimation;multiple motion compensated observations;optical flow algorithm;residual CNN model;residual net;video superresolution techniques;Image reconstruction;Image resolution;Motion compensation;Motion estimation;Neural networks;Optical imaging;Convolutional neural networks (CNNs);deep residual learning;multi-frame super-resolution;video super-resolution},
}

@Article{Obermeier2017p217-229,
  author   = {R. Obermeier and J. A. Martinez-Lorenzo},
  title    = {Sensing Matrix Design via Mutual Coherence Minimization for Electromagnetic Compressive Imaging Applications},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {217-229},
  month    = {June},
  abstract = {Compressive sensing (CS) theory states that sparse signals can be recovered from a small number of linear measurements y = Ax using l1norm minimization techniques, provided that the sensing matrix satisfies a restricted isometry property (RIP). Unfortunately, the RIP is difficult to verify in electromagnetic imaging applications, where the sensing matrix is computed deterministically. Although it provides weaker reconstruction guarantees than the RIP, the mutual coherence is a more practical metric for assessing the CS recovery properties of deterministic matrices. In this paper, we describe a method for minimizing the mutual coherence of sensing matrices in electromagnetic imaging applications. Numerical results for the design method are presented for a simple multiple monostatic imaging application, in which the sensor positions for each measurement serve as the design variables. These results demonstrate the algorithm's ability to both decrease the coherence and to generate sensing matrices with improved CS recovery capabilities.},
  doi      = {10.1109/TCI.2017.2671398},
  keywords = {compressed sensing;concave programming;matrix algebra;minimisation;CS recovery properties;RIP;compressive sensing;design variables;deterministic matrices;electromagnetic compressive imaging applications;l1-norm minimization techniques;linear measurement;monostatic imaging application;mutual coherence minimization;restricted isometry property;sensing matrix design;sensor positions;sparse signal recovery;Algorithm design and analysis;Compressed sensing;Electromagnetics;Minimization;Sensors;Sparse matrices;Compressive sensing (CS);nonconvex optimization;sensing matrix design},
}

@Article{Fan2017p330-343,
  author   = {B. Fan and S. Aeron and A. Pedrycz and H. P. Valero},
  title    = {On Acoustic Signal Compression for Ultrasonic Borehole Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {330-343},
  month    = {June},
  abstract = {This paper presents a novel approach for computationally efficient and robust compression for Ultrasonic Borehole Imaging. Although current methods achieve good compression versus accuracy tradeoffs, they inevitably employ iterative schemes, which for resource constrained downhole applications is computationally prohibitive. To alleviate this issue, we propose to model the waveforms as sum of exponentials (SOE) and use the matrix pencil (MP) algorithm for compression and recovery. This method is referred to as the SOE-MP method. We report that the SOE-MP method is able to compress the signal better than several existing methods in terms of accuracy, compression ratio, and speed. To achieve further gains in compression, we exploit the correlation across the waveforms and propose a novel method called angle-based adjacent basis grouping (ABBG). ABBG is an online method that exploits the correlation across successive acquisitions and avoids recomputing the MP solution for very similar waveforms. We report the tradeoffs among accuracy, compression, and running time for these methods on laboratory and field datasets, and show the nearly lossless imaging performance.},
  doi      = {10.1109/TCI.2017.2670366},
  keywords = {acoustic imaging;image processing;iterative methods;matrix algebra;production engineering computing;ultrasonic materials testing;ABBG;MP algorithm;SOE-MP method;acoustic signal compression;angle-based adjacent basis grouping;image compression;iterative schemes;lossless imaging performance;matrix pencil algorithm;sum of exponentials;ultrasonic borehole imaging;Acoustics;Computational modeling;Imaging;Mathematical model;Matrix decomposition;Signal resolution;Chirplet Signal Decomposition;High dimensional data compression;Matrix pencil;Ultrasonic Imaging;bandpass filter},
}

@Article{Thiel2017p369-378,
  author   = {M. Thiel and D. Omeragic},
  title    = {High-Fidelity Real-Time Imaging With Electromagnetic Logging-While-Drilling Measurements},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {369-378},
  month    = {June},
  issn     = {2333-9403},
  abstract = {A pixel-based inversion approach is introduced for interpretation of deep directional resistivity logging-while-drilling electromagnetic measurements. It can be used for real-time reservoir mapping while drilling to accurately place the well with respect to reservoir boundaries and fluid contacts as well as for reservoir characterization in high angle and horizontal wells. The methodology is based on the Gauss-Newton approach, using an adaptive l1-norm regularization and a robust error term to determine the 1-D formation anisotropic resistivity profile and local formation dip. The new inversion allows high-resolution imaging of the subsurface resistivity distributions and consistent integration of measurements of different depth of investigation. To further enhance the robustness and accuracy of the subsurface images, a fast approximate 2-D inversion is developed, which uses approximate modeling based on locally 1-D models, resulting in reservoir images of improved accuracy and consistency in mildly 2-D and 3-D scenarios. The inversion's ability to generate a stable robust but detailed resistivity image of the formation near the wellbore is proven on synthetic and field data.},
  doi      = {10.1109/TCI.2017.2670364},
  keywords = {drilling (geotechnical);hydrocarbon reservoirs;image processing;Gauss-Newton approach;adaptive L1-norm regularization;electromagnetic logging-while-drilling measurements;high-fidelity real-time imaging;pixel-based inversion approach;realtime reservoir mapping;reservoir boundaries;reservoir characterization;robust error term;subsurface resistivity distributions;Anisotropic magnetoresistance;Antenna measurements;Conductivity;Cost function;Geophysical measurements;Real-time systems;Reservoirs;Geophysics;inverse problems;logging-while-drilling (LWD);oilfield exploration;optimization;reservoir mapping;resistivity;well logging},
}

@Article{Marinoni2017p243-253,
  author   = {A. Marinoni and P. Gamba},
  title    = {Unsupervised Data Driven Feature Extraction by Means of Mutual Information Maximization},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {243-253},
  month    = {June},
  abstract = {In Earth observations technical literature, several methods have been proposed and implemented to efficiently extract a proper set of features for classification and segmentation purposes. However, these architectures show drawbacks when the considered datasets are characterized by complex interactions among the samples, especially when they rely on strong assumptions on noise and label domains. In this paper, a new unsupervised approach for feature extraction, based on data driven discovery, is introduced for accurate classification of remotely sensed data. Specifically, the proposed architecture exploits mutual information maximization in order to retrieve the most relevant features with respect to information measures. Experimental results on real datasets show that the proposed approach represents a valid framework for feature extraction from remote sensing images.},
  doi      = {10.1109/TCI.2017.2669731},
  keywords = {data mining;feature extraction;geophysical image processing;image classification;image retrieval;remote sensing;data driven discovery;information measures;label domains;most relevant feature retrieval;mutual information maximization;noise domains;remote sensing images;remotely sensed data classification;unsupervised data driven feature extraction;Bipartite graph;Computer architecture;Feature extraction;Mutual information;Principal component analysis;Remote sensing;Data driven discovery;feature extraction;information theory;mutual information maximization;remote sensing},
}

@Article{Haltmeier2017p853-863,
  author   = {M. Haltmeier and S. Moon and D. Schiefeneder},
  title    = {Inversion of the Attenuated V-Line Transform With Vertices on the Circle},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {853-863},
  month    = {Dec},
  abstract = {The Compton camera is a promising alternative to the Anger camera for imaging gamma radiation, with the potential to significantly increase the sensitivity of SPECT. Two-dimensional Compton camera image reconstruction can be implemented by inversion of the V-line transform, which integrates the emission distribution over V-lines (unions of two half-lines) that have vertices on a surrounding detector array. Inversion of the V-line transform without attenuation has recently been addressed by several authors. However, it is well known from standard SPECT that ignoring attenuation can significantly degrade the quality of the reconstructed image. In this paper, we address this issue and study the attenuated V-line transform accounting for attenuation of photons in SPECT with Compton cameras. Assuming vertices of V-lines on a circle, we derive an analytic inversion approach based on circular harmonics expansion, and show uniqueness of reconstruction for the attenuated V-line transform. We further develop a discrete image reconstruction algorithm based on our analytic studies, and present numerical results that demonstrate the effectiveness of our algorithm.},
  doi      = {10.1109/TCI.2017.2669868},
  keywords = {Compton effect;cameras;image reconstruction;medical image processing;single photon emission computed tomography;transforms;Anger camera;analytic inversion approach;attenuated V-line transform inversion;circular harmonics expansion;discrete image reconstruction algorithm;emission distribution;gamma radiation imaging;half-lines;photon attenuation;single photon emission computed tomography;standard SPECT;two-dimensional Compton camera image reconstruction;Attenuation;Cameras;Detectors;Image reconstruction;Photonics;Single photon emission computed tomography;Transforms;Abel integral equations;Compton cameras;Radon transform;SPECT;V-line transform;attenuation correction;image reconstruction;solution uniqueness},
}

@Article{Gennarelli2017p917-927,
  author   = {G. Gennarelli and I. Catapano and F. Soldovieri},
  title    = {Reconstruction Capabilities of Down-Looking Airborne GPRs: The Single Frequency Case},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {917-927},
  month    = {Dec},
  abstract = {This paper addresses the problem of imaging shallow buried targets via ground penetrating radar surveys carried out by an airborne platform. The radar system is monostatic and collects scattered field data at a single frequency in down-looking mode and along parallel lines. The data are processed by means of an image formation algorithm based on a microwave tomographic approach valid under Born and start-stop approximations. The goal of the present study is to derive analytical results for the spatial resolution depending on the measurement configuration parameters. The achieved results highlight the peculiar features of the imaging configuration providing useful indications for setting a proper acquisition strategy. Numerical results based on synthetic data are shown to support the analysis of resolution limits.},
  doi      = {10.1109/TCI.2017.2669865},
  keywords = {airborne radar;buried object detection;electromagnetic wave scattering;geophysical signal processing;geophysical techniques;ground penetrating radar;image reconstruction;microwave imaging;radar imaging;remote sensing by radar;synthetic aperture radar;tomography;airborne GPR;airborne platform;ground penetrating radar;image formation algorithm;imaging configuration;measurement configuration parameters;microwave tomographic approach;parallel lines;peculiar features;radar system;reconstruction capabilities;scattered field data;shallow buried targets;spatial resolution;start-stop approximations;synthetic data;Airborne radar;Eigenvalues and eigenfunctions;Ground penetrating radar;Image resolution;Radar imaging;Airborne radar;ground penetrating radar;microwave tomography;resolution limits},
}

@Article{Halimi2017p472-484,
  author   = {A. Halimi and A. Maccarone and A. McCarthy and S. McLaughlin and G. S. Buller},
  title    = {Object Depth Profile and Reflectivity Restoration From Sparse Single-Photon Data Acquired in Underwater Environments},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {472-484},
  month    = {Sept},
  abstract = {This paper presents two new algorithms for the joint restoration of depth and reflectivity (DR) images constructed from time-correlated single-photon counting measurements. Two extreme cases are considered: 1) a reduced acquisition time that leads to very low photon counts; and 2) imaging in a highly attenuating environment (such as a turbid medium), which makes the reflectivity estimation more difficult at increasing range. Adopting a Bayesian approach, the Poisson distributed observations are combined with prior distributions about the parameters of interest, to build the joint posterior distribution. More precisely, two Markov random field (MRF) priors enforcing spatial correlations are assigned to the DR images. Under some justified assumptions, the restoration problem (regularized likelihood) reduces to a convex formulation with respect to each of the parameters of interest. This problem is first solved using an adaptive Markov chain Monte Carlo (MCMC) algorithm that approximates the minimum mean square parameter estimators. This algorithm is fully automatic since it adjusts the parameters of the MRFs by maximum marginal likelihood estimation. However, the MCMC-based algorithm exhibits a relatively long computational time. The second algorithm deals with this issue and is based on a coordinate descent algorithm. Results on single-photon depth data from laboratory-based underwater measurements demonstrate the benefit of the proposed strategy that improves the quality of the estimated DR images.},
  doi      = {10.1109/TCI.2017.2669867},
  keywords = {Markov processes;Monte Carlo methods;image restoration;maximum likelihood estimation;Bayesian approach;DR images;MCMC algorithm;MRF priors;Markov random field;Poisson distributed observations;adaptive Markov chain Monte Carlo;convex formulation;coordinate descent algorithm;joint posterior distribution;joint restoration;laboratory-based underwater measurements;maximum marginal likelihood estimation;minimum mean square parameter estimators;object depth profile;photon counts;reflectivity estimation;reflectivity restoration;single-photon depth data;sparse single-photon data;spatial correlations;time-correlated single-photon counting measurements;underwater environments;Approximation algorithms;Bayes methods;Image restoration;Laser radar;Photonics;ADMM;MCMC;bayesian estimation;image restoration;lidar waveform;poisson statistics;underwater Lidar},
}

@Article{Lagrange2017p230-242,
  author   = {A. Lagrange and M. Fauvel and M. Grizonnet},
  title    = {Large-Scale Feature Selection With Gaussian Mixture Models for the Classification of High Dimensional Remote Sensing Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {230-242},
  month    = {June},
  abstract = {A large-scale feature selection wrapper is discussed for the classification of high dimensional remote sensing. An efficient implementation is proposed based on intrinsic properties of Gaussian mixtures models and block matrix. The criterion function is split into two parts:one that is updated to test each feature and one that needs to be updated only once per feature selection. This split saved a lot of computation for each test. The algorithm is implemented in C++ and integrated into the Orfeo Toolbox. It has been compared to other classification algorithms on two high dimension remote sensing images. Results show that the approach provides good classification accuracies with low computation time.},
  doi      = {10.1109/TCI.2017.2666551},
  keywords = {C++ language;Gaussian processes;feature selection;geophysical image processing;image classification;mixture models;remote sensing;C++ language;Gaussian mixture models;Orfeo Toolbox;block matrix;high dimensional remote sensing images;image classification;large-scale feature selection wrapper;Covariance matrices;Feature extraction;Gaussian mixture model;Hyperspectral imaging;Fast computing;feature selection;gaussian mixture model;hyperspectral imaging;remote sensing},
}

@Article{Pellizzari2017p901-916,
  author   = {C. J. Pellizzari and R. Trahan and H. Zhou and S. Williams and S. E. Williams and B. Nemati and M. Shao and C. A. Bouman},
  title    = {Synthetic Aperature LADAR: A Model-Based Approach},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {901-916},
  month    = {Dec},
  abstract = {Synthetic aperture LADAR (SAL) allows high resolution imaging of distant objects. Basic SAL image processing is based on fast Fourier transform (FFT) techniques originally developed for use in radar. These techniques can amplify noise and limit resolution. More advanced reconstruction techniques have been proposed for synthetic aperture radar (SAR), but have not been adapted for SAL. In addition, both conventional SAL and advanced SAR algorithms reconstruct the complex-valued reflection coefficient instead of the real-valued reflectance which leads to speckled images. In this paper, we present a model-based iterative reconstruction (MBIR) algorithm designed specifically for SAL. Rather than estimating the reflection coefficient, we propose estimating its variance which is equal to the reflectance, a function that more closely resembles conventional optical images. A Bayesian framework is used to find the maximum a posteriori (MAP) estimate for the reflectance using a Q-Generalized Gaussian Markov random field (QGGMRF) prior model. The QGGMRF is able to model complex correlations between neighboring pixels which promotes a smooth and more natural looking image. The expectation-maximization (EM) algorithm is used to derive a surrogate for the MAP cost function. Finally, the proposed MBIR algorithm is tested on both simulated and experimental data. Results show significant and consistent improvements over existing reconstruction techniques in terms of image contrast, speckle reduction, autofocus, and low signal-to-noise ratio performance.},
  doi      = {10.1109/TCI.2017.2663320},
  keywords = {Bayes methods;Gaussian processes;Markov processes;fast Fourier transforms;image reconstruction;image resolution;iterative methods;maximum likelihood estimation;object detection;optical radar;radar imaging;remote sensing by radar;synthetic aperture radar;Bayesian framework;EM algorithm;FFT techniques;Gaussian Markov random field;MAP cost function;MAP estimate;MBIR algorithm;QGGMRF;SAL image processing;SAR algorithms;complex correlations modelling;complex-valued reflection coefficient;distant objects;expectation-maximization algorithm;fast Fourier transform;high resolution imaging;maximum a posteriori estimate;model-based iterative reconstruction algorithm;reconstruction techniques;synthetic aperture LADAR;synthetic aperture radar;Algorithm design and analysis;Apertures;Bayes methods;Image reconstruction;Imaging;Laser radar;Synthetic aperture radar;Model-based iterative reconstruction;maximum a posteriori estimate;speckle reduction;synthetic aperture LADAR, rank3},
}

@Article{Chen2017p996-1007,
  author   = {H. Y. Chen and S. H. Hsu and W. J. Hwang and C. J. Cheng},
  title    = {An Efficient FPGA-Based Parallel Phase Unwrapping Hardware Architecture},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {996-1007},
  month    = {Dec},
  abstract = {This paper presents a novel phase unwrapping hardware architecture for imaging applications. The architecture is a hardware implementation of a path-independent noniterative discrete cosine transform (DCT) based minimum mean square algorithm for accurate and fast phase unwrapping. The implementation is based on field programmable gate array. The architecture is able to exploit the parallelism among different stages of the algorithm for maximizing the throughput of the computation. A network-on-chip platform is built for the computation time measurement. As compared with other implementations for fast phase unwrapping, the proposed architecture has the advantages of high throughput, high accuracy, and low power consumption.},
  doi      = {10.1109/TCI.2017.2663767},
  keywords = {discrete cosine transforms;field programmable gate arrays;image processing;least mean squares methods;network-on-chip;parallel processing;DCT;FPGA-based parallel phase unwrapping;computation time measurement;field programmable gate array;hardware architecture;imaging applications;minimum mean square algorithm;network-on-chip platform;parallelism;path-independent noniterative discrete cosine transform;Computer architecture;Discrete cosine transforms;Field programmable gate arrays;Imaging;Laplace equations;Shift registers;Digital holographic microscopy;FPGA;network on chip;phase unwrapping},
}

@Article{Aghagolzadeh2017p522-534,
  author   = {M. Aghagolzadeh and H. Radha},
  title    = {Joint Estimation of Dictionary and Image from Compressive Samples},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {4},
  pages    = {522-534},
  month    = {Dec},
  abstract = {Effective compressed sensing of images relies on the prior knowledge of a well-suited dictionary for sparse representation of the target image. In the absence of such knowledge, which is a typical scenario in real-world applications, the following question arises: Would it be advantageous to take an off-the-shelf overcomplete dictionary and fine-tune the dictionary with respect to (the observed part of) the image? A primary obstacle in this approach is overfitting, i.e., the loss in model generalization to the whole image. In this paper, we establish that local dictionary optimization using the compressive samples reduces the image recovery error-relative to the off-the-shelf recovery-with an overwhelming probability that depends on the sampling matrix. We present joint estimation of dictionary and image (JEDI), an iterative algorithm for dictionary fine-tuning from compressive samples and analyze its performance for image recovery. Our algorithmic analysis is supplemented with numerical simulations under different random sampling patterns and off-the-shelf dictionary initializations.},
  doi      = {10.1109/TCI.2017.2663321},
  keywords = {compressed sensing;data compression;image coding;image representation;iterative methods;matrix algebra;optimisation;probability;JEDI;compressive samples;dictionary fine-tuning;image recovery error;joint estimation of dictionary and image;local dictionary optimization;off-the-shelf dictionary initializations;off-the-shelf overcomplete dictionary;off-the-shelf recovery;random sampling patterns;sampling matrix;sparse representation;target image;Algorithm design and analysis;Atomic measurements;Compressed sensing;Image coding;Sparse matrices;Adaptive image recovery;blind compressed sensing;dictionary learning},
}

@Article{Huo2017p254-263,
  author   = {C. Huo and Z. Zhou and K. Ding and C. Pan},
  title    = {Online Target Recognition for Time-Sensitive Space Information Networks},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {254-263},
  month    = {June},
  abstract = {The key difficulties of online target recognition task for space information networks lie in the contradiction between time-sensitive response requirement and resource constraints(e.g., computation resource, communication resource, and training samples). To deal with the above problems, an effective online target recognizing approach is proposed, which seamlessly integrates fast online information processing task and efficient target-specific high-rate compression task. The proposed approach begins with enhancing the target-background separability by introducing intraclass and interclass couples, the new model adapted for the hospt spot image is then obtained by capturing the relation between the online target data and the massive historical data. The light-weight target-specific information is efficiently transmitted into the ground system, and the whole scene is capable of being recovered while the details of targets are being preserved. Compared with the traditional target recognition methods, the proposed approach is more promising for time-sensitive space information networks. The experiments demonstrate the effectiveness of the proposed approach.},
  doi      = {10.1109/TCI.2017.2655448},
  keywords = {aerospace computing;information networks;pattern recognition;fast online information processing task;online target recognition;online target recognizing approach;resource constraints;target-specific high-rate compression task;time-sensitive response requirement;time-sensitive space information networks;Feature extraction;Image coding;Pattern recognition;Target recognition;Training;Feature adaption;information compression;information processing;space information networks;target recognition},
}

@Article{Das2017p316-329,
  author   = {S. Das and X. Chen and M. P. Hobson},
  title    = {Fast GPU-Based Seismogram Simulation From Microseismic Events in Marine Environments Using Heterogeneous Velocity Models},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {316-329},
  month    = {June},
  issn     = {2333-9403},
  abstract = {A novel approach is presented for fast generation of synthetic seismograms due to microseismic events, using heterogeneous marine velocity models. The partial differential equations for the three-dimensional (3-D) elastic wave equation have been numerically solved using the Fourier domain pseudo-spectral method which is parallelizable on the graphics processing unit (GPU) cards, thus making it faster compared to traditional CPU based computing platforms. Due to computationally expensive forward simulation of large geological models, several combinations of individual synthetic seismic traces are used for specified microseismic event locations, in order to simulate the effect of realistic microseismic activity patterns in the subsurface. We here explore the patterns generated by few hundreds of microseismic events with different source mechanisms using various combinations, both in event amplitudes and origin times, using the simulated pressure and three component particle velocity fields via 1-D, 2-D and 3-D seismic visualizations.},
  doi      = {10.1109/TCI.2017.2654127},
  keywords = {earthquakes;geophysics computing;graphics processing units;partial differential equations;Fourier domain pseudospectral method;elastic wave equation;fast GPU-based seismogram simulation;graphics processing unit;heterogeneous velocity models;marine environment;microseismic event locations;microseismic events;partial differential equations;seismic traces;seismic visualizations;Computational modeling;Graphics processing units;Mathematical model;Numerical models;Propagation;Solid modeling;Three-dimensional displays;Elastic wave equation;GPU computing;marine velocity model;microseimic event simulation;seismogram},
}

@Article{Li2017p74-83,
  author   = {F. Li and H. Sekkati and J. Deglint and C. Scharfenberger and M. Lamm and D. Clausi and J. Zelek and A. Wong},
  title    = {Simultaneous Projector-Camera Self-Calibration for Three-Dimensional Reconstruction and Projection Mapping},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {74-83},
  month    = {March},
  issn     = {2333-9403},
  abstract = {Automatic calibration of structured-light systems, generally consisting of a projector and camera, is of great importance for a variety of practical applications. We propose a novel optimization approach for geometric calibration of a projector-camera system that estimates the intrinsic, extrinsic, and distortion parameters of both the camera and projector in an automatic fashion using structured light. Our approach benefits from a novel multifactor objective function that finds maximum-likelihood estimates from noisy point correspondences using constraints on focal lengths and resolves ambiguities estimating the fundamental matrix by enforcing epipolar geometry on the rectified noisy data. This new formulation allows estimation of all calibration parameters simultaneously and minimization is ensured by a greedy descent algorithm that decreases the cost function at each iteration. This provides more accurate parameter estimation, reconstruction accuracy, and robustness to noise and poor initialization compared to previous methods. Experimental results demonstrate the stability and robustness of our method, and show that the proposed solution outperforms a currently leading approach to an automatic geometric projector-camera calibration.},
  doi      = {10.1109/TCI.2017.2652844},
  keywords = {calibration;cameras;greedy algorithms;image denoising;image reconstruction;iterative methods;matrix algebra;maximum likelihood estimation;minimisation;optical projectors;stereo image processing;automatic calibration;calibration parameter estimation;cost function;distortion parameter;epipolar geometry;extrinsic parameter;focal lengths;geometric calibration;greedy descent algorithm;intrinsic parameter;maximum-likelihood estimation;minimization;multifactor objective function;noise robustness;noisy point correspondences;optimization approach;parameter estimation;projection mapping;rectified noisy data;simultaneous projector-camera self-calibration;structured-light systems;three-dimensional reconstruction;Calibration;Cameras;Distortion;Linear programming;Robustness;Three-dimensional displays;Auto-calibration;projection mapping;projector-camera;self-calibration},
}

@Article{Landau2017p58-73,
  author   = {M. J. Landau and P. A. Beling},
  title    = {Optimal Model-Based 6-D Object Pose Estimation With Structured-Light Depth Sensors},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {58-73},
  month    = {March},
  abstract = {Structured-light (SL) depth sensors are widely used because of their simplicity in design and ability to process depth data with minimal computational expense. Certain SL light coding methods can, however, lead to a loss of information, as well as inhomogeneous depth errors that depend on the composition and properties of the scene. This results in a reduction of potential accuracy for model-based pose estimation methods that operate on the depth images or subsequently transformed three-dimensional point clouds, such as the popular class of point set registration (PSR) methods. We therefore formulate an asymptotically optimal maximum likelihood estimation (MLE) method that operates directly on the raw SL infrared (IR) images. The proposed SLIR-MLE method maximizes the likelihood of the measured IR image over the pose region given the object model, sensor model, and calibrated speckle and thermal noise distributions. We also formulate a method to compute the Fisher information contained in the IR image and resulting Cramér-Rao bound (CRB) of any unbiased pose estimator for unique SL sensor measurement data. SLIR-MLE is shown to nearly achieve the calculated CRB for the Kinect sensor by operating on the more informative raw IR images. Furthermore, our method is shown to outperform two cutting edge PSR methods by an order of magnitude in the respective mean square errors.},
  doi      = {10.1109/TCI.2016.2646220},
  keywords = {CAD;image matching;infrared imaging;maximum likelihood estimation;pose estimation;shape recognition;solid modelling;thermal noise;6D object pose estimation;CAD models;Cramér-Rao bound;Fisher information;Kinect sensor;PSR methods;SL depth sensors;SL infrared images;SL light coding methods;SLIR-MLE method;depth data;model-based pose estimation methods;model-based shape matching;optimal MLE method;optimal maximum likelihood estimation method;optimal model;point set registration methods;structured-light depth sensors;thermal noise distributions;three-dimensional point clouds;Computational modeling;Image sensors;Pose estimation;Sensors;Solid modeling;Three-dimensional displays;Computer-aided design (CAD);Cramér–Rao bound (CRB);Fisher information matrix (FIM);Microsoft kinect;maximum likelihood estimation (MLE);minimum mean square error (MMSE)},
}

@Article{Zhao2017p47-57,
  author   = {H. Zhao and O. Gallo and I. Frosio and J. Kautz},
  title    = {Loss Functions for Image Restoration With Neural Networks},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {47-57},
  month    = {March},
  abstract = {Neural networks are becoming central in several areas of computer vision and image processing and different architectures have been proposed to solve specific problems. The impact of the loss layer of neural networks, however, has not received much attention in the context of image processing: the default and virtually only choice is ℓ2. In this paper, we bring attention to alternative choices for image restoration. In particular, we show the importance of perceptually-motivated losses when the resulting image is to be evaluated by a human observer. We compare the performance of several losses, and propose a novel, differentiable error function. We show that the quality of the results improves significantly with better loss functions, even when the network architecture is left unchanged.},
  doi      = {10.1109/TCI.2016.2644865},
  keywords = {computer vision;image restoration;neural nets;computer vision;image processing;image restoration;loss function;neural network;perceptually-motivated loss;Image quality;Image restoration;Measurement;Neural networks;Image processing;image restoration;loss functions;neural networks},
}

@Article{Kadu2017p305-315,
  author   = {A. Kadu and T. van Leeuwen and W. A. Mulder},
  title    = {Salt Reconstruction in Full-Waveform Inversion With a Parametric Level-Set Method},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {305-315},
  month    = {June},
  abstract = {Seismic full-waveform inversion tries to estimate subsurface medium parameters from seismic data. Areas with subsurface salt bodies are of particular interest because they often have hydrocarbon reservoirs on their sides or underneath. Accurate reconstruction of their geometry is a challenge for current techniques. This paper presents a parametric level-set method for the reconstruction of salt-bodies in seismic full-waveform inversion. We split the subsurface model in two parts: a background velocity model and a salt body with known velocity but undetermined shape. The salt geometry is represented by a level-set function that evolves during the inversion. We choose radial basis functions to represent the level-set function, leading to an optimization problem with a modest number of parameters. A common problem with level-set methods is to fine-tune the width of the level-set boundary for optimal sensitivity. We propose a robust algorithm that dynamically adapts the width of the level-set boundary to ensure faster convergence. Tests on a suite of idealized salt geometries show that the proposed method is stable against a modest amount of noise. We also extend the method to joint inversion of both the background velocity model and the salt geometry.},
  doi      = {10.1109/TCI.2016.2640761},
  keywords = {hydrocarbon reservoirs;optimisation;radial basis function networks;seismology;background velocity model;hydrocarbon reservoirs;level-set function;optimization problem;parametric level-set method;radial basis functions;salt geometry;salt-body reconstruction;seismic data;seismic full-waveform inversion;subsurface salt bodies;surface medium parameters;velocity model;Image reconstruction;Inverse problems;Mathematical model;Optimization;Sediments;Seismology;Level set;inverse problem;seismology},
}

@Article{Rousset2017p36-46,
  author   = {F. Rousset and N. Ducros and A. Farina and G. Valentini and C. D’Andrea and F. Peyrin},
  title    = {Adaptive Basis Scan by Wavelet Prediction for Single-Pixel Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {36-46},
  month    = {March},
  issn     = {2333-9403},
  abstract = {Single-pixel camera imaging is an emerging paradigm that allows high-quality images to be provided by a device only equipped with a single point detector. A single-pixel camera is an experimental setup able to measure the inner product of the scene under view-the image-with any user-defined pattern. Postprocessing a sequence of point measurements obtained with different patterns permits to recover spatial information, as it has been demonstrated by state-of-the-art approaches belonging to the compressed sensing framework. In this paper, a new framework for the choice of the patterns is proposed together with a simple and efficient image recovery scheme. Our goal is to overcome the computationally demanding ℓ1-minimization of the compressed sensing. We propose to choose patterns among a wavelet basis in an adaptive fashion, which essentially relies onto the prediction of the significant wavelet coefficients' location. More precisely, we adopt a multiresolution strategy that exploits the set of measurements acquired at coarse scales to predict the set of measurements to be performed at a finer scale. Prediction is based on a fast cubic interpolation in the image domain. A general formalism is given so that any kind of wavelets can be used, which enables one to adjust the wavelet to the type of images related to the desired application. Both simulated and experimental results demonstrate the ability of our technique to reconstruct biomedical images with improved quality compared with compressive-sensing-based recovery. Application to the real-time fluorescence imaging of biological tissues could benefit from the proposed method.},
  doi      = {10.1109/TCI.2016.2637079},
  keywords = {cameras;compressed sensing;fluorescence;image reconstruction;image resolution;interpolation;medical image processing;minimisation;pattern clustering;wavelet transforms;ℓ1-minimization;adaptive basis scan;biological tissues;biomedical image reconstruction;coarse scales;compressed sensing;compressive-sensing-based recovery;fast cubic interpolation prediction;image recovery;multiresolution strategy;point measurement sequence postprocessing;real-time fluorescence imaging;single point detector;single-pixel camera imaging;spatial information recovery;user-defined pattern;wavelet coefficient location;wavelet prediction;Cameras;Compressed sensing;Detectors;Image restoration;Optical imaging;Wavelet transforms;Compressive sensing;fluorescence imaging;optical imaging;single-pixel camera;wavelets},
}

@Article{Tan2017p126-140,
  author   = {K. Tan and W. Li},
  title    = {Imaging and Parameter Estimating for Fast Moving Targets in Airborne SAR},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {126-140},
  month    = {March},
  abstract = {A novel algorithm is presented to image fast moving targets and estimate moving parameters in single-antenna synthetic aperture radar, in which phase information is extracted by a proposed maximum amplitude extraction algorithm, and the Doppler parameters of moving targets are estimated by combining the fractional Fourier transform and an adaptive and iterative ambiguous number estimation algorithm. The range curve and walk can be corrected simultaneously with the estimated Doppler parameters. After azimuth compression, the shortest distance is estimated in a focused image to obtain the accurate moving parameters. Our simulations demonstrate that high-precision estimation and robust performance can be achieved when a large range curve and walk caused by fast moving targets exist, even in low-signal-to-noise-ratio cases. Comparisons with state-of-the-art algorithms also illustrate the advantages of the proposed algorithm.},
  doi      = {10.1109/TCI.2016.2634421},
  keywords = {Fourier transforms;adaptive estimation;airborne radar;data compression;image coding;image motion analysis;parameter estimation;synthetic aperture radar;adaptive ambiguous number estimation algorithm;airborne SAR;azimuth compression;fractional Fourier transform;iterative ambiguous number estimation algorithm;maximum amplitude extraction algorithm;moving target Doppler parameter estimation;phase information;single-antenna synthetic aperture radar;Algorithm design and analysis;Doppler effect;Estimation;Radar imaging;Synthetic aperture radar;Fast moving target;Synthetic Aperture Radar (SAR);imaging;maximum amplitude extraction;parameter estimation},
}

@Article{Halimi2017p146-159,
  author   = {A. Halimi and J. M. Bioucas-Dias and N. Dobigeon and G. S. Buller and S. McLaughlin},
  title    = {Fast Hyperspectral Unmixing in Presence of Nonlinearity or Mismodeling Effects},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {2},
  pages    = {146-159},
  month    = {June},
  issn     = {2333-9403},
  abstract = {This paper presents two novel hyperspectral mixture models and associated unmixing algorithms. The two models assume a linear mixing model corrupted by an additive term whose expression can be adapted to account for multiple scattering nonlinearities (NL), or mismodeling effects (ME). The NL model generalizes bilinear models by taking into account higher order interaction terms. The ME model accounts for different effects, such as endmember variability or the presence of outliers. The abundance and residual parameters of these models are estimated by considering a convex formulation suitable for fast estimation algorithms. This formulation accounts for constraints, such as the sum-to-one and nonnegativity of the abundances, the nonnegativity of the nonlinearity coefficients, the spectral smoothness of the ME terms and the spatial sparseness of the residuals. The resulting convex problem is solved using the alternating direction method of multipliers whose convergence is ensured theoretically. The proposed mixture models and their unmixing algorithms are validated on both synthetic and real images showing competitive results regarding the quality of the inference and the computational complexity when compared to the state-of-the-art algorithms.},
  doi      = {10.1109/TCI.2016.2631979},
  keywords = {convex programming;hyperspectral imaging;image processing;mixture models;alternating direction method of multipliers;associated unmixing algorithms;bilinear models;convex formulation;fast hyperspectral unmixing;higher order interaction terms;hyperspectral mixture models;mismodeling effect;nonlinearity coefficients;nonlinearity effect;Adaptation models;Computational modeling;Hyperspectral imaging;Mixture models;Scattering;Signal processing algorithms;ADMM;Hyperspectral imagery;collaborative sparse regression;convex optimization;nonlinear unmixing;robust unmixing},
}

@Article{Romano2017p110-125,
  author   = {Y. Romano and J. Isidoro and P. Milanfar},
  title    = {RAISR: Rapid and Accurate Image Super Resolution},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {110-125},
  month    = {March},
  abstract = {Given an image, we wish to produce an image of larger size with significantly more pixels and higher image quality. This is generally known as the single image super-resolution problem. The idea is that with sufficient training data (corresponding pairs of low and high resolution images) we can learn set of filters (i.e., a mapping) that when applied to given image that is not in the training set, will produce a higher resolution version of it, where the learning is preferably low complexity. In our proposed approach, the run-time is more than one to two orders of magnitude faster than the best competing methods currently available, while producing results comparable or better than state-of-the-art. A closely related topic is image sharpening and contrast enhancement, i.e., improving the visual quality of a blurry image by amplifying the underlying details (a wide range of frequencies). Our approach additionally includes an extremely efficient way to produce an image that is significantly sharper than the input blurry one, without introducing artifacts, such as halos and noise amplification. We illustrate how this effective sharpening algorithm, in addition to being of independent interest, can be used as a preprocessing step to induce the learning of more effective upscaling filters with built-in sharpening and contrast enhancement effect.},
  doi      = {10.1109/TCI.2016.2629284},
  keywords = {image enhancement;image resolution;RAISR;contrast enhancement;image quality;image sharpening;rapid and accurate image superresolution;Complexity theory;Image resolution;Image restoration;Interpolation;Memory management;Training;Filter Learning, image enhancement, image sharpening, super resolution},
}

@Article{Chan2017p84-98,
  author   = {S. H. Chan and X. Wang and O. A. Elgendy},
  title    = {Plug-and-Play ADMM for Image Restoration: Fixed-Point Convergence and Applications},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {84-98},
  month    = {March},
  abstract = {Alternating direction method of multiplier (ADMM) is a widely used algorithm for solving constrained optimization problems in image restoration. Among many useful features, one critical feature of the ADMM algorithm is its modular structure, which allows one to plug in any off-the-shelf image denoising algorithm for a subproblem in the ADMM algorithm. Because of the plug-in nature, this type of ADMM algorithms is coined the name “Plug-and-Play ADMM.” Plug-and-Play ADMM has demonstrated promising empirical results in a number of recent papers. However, it is unclear under what conditions and by using what denoising algorithms would it guarantee convergence. Also, since Plug-and-Play ADMM uses a specific way to split the variables, it is unclear if fast implementation can be made for common Gaussian and Poissonian image restoration problems. In this paper, we propose a Plug-and-Play ADMM algorithm with provable fixed-point convergence. We show that for any denoising algorithm satisfying an asymptotic criteria, called bounded denoisers, Plug-and-Play ADMM converges to a fixed point under a continuation scheme. We also present fast implementations for two image restoration problems on superresolution and single-photon imaging. We compare Plug-and-Play ADMM with state-of-the-art algorithms in each problem type and demonstrate promising experimental results of the algorithm.},
  doi      = {10.1109/TCI.2016.2629286},
  keywords = {Gaussian processes;convergence;image denoising;image resolution;image restoration;system buses;Gaussian image restoration problem;Poissonian image restoration problem;constrained optimization problems;denoising algorithms;fixed-point convergence;plug-and-play ADMM;plug-and-play alternating direction method of multiplier;single-photon imaging;superresolution imaging;Approximation algorithms;Convergence;Image resolution;Image restoration;Noise reduction;Optimization;ADMM;Plug-and-Play;Poisson noise;deblurring;denoising;image restoration;inpainting;single photon imaging;super-resolution},
}

@Article{Biswas2017p22-35,
  author   = {S. Biswas and S. Dasgupta and R. Mudumbai and M. Jacob},
  title    = {Subspace Aware Recovery of Low Rank and Jointly Sparse Signals},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {22-35},
  month    = {March},
  issn     = {2333-9403},
  abstract = {We consider the recovery of a matrix X, which is simultaneously low rank and joint sparse, from few measurements of its columns using a two-step algorithm. Each column of K is measured using a combination of two measurement matrices; one which is the same for every column, while the second measurement matrix varies from column to column. The recovery proceeds by first estimating the row subspace vectors from the measurements corresponding to the common matrix. The estimated row subspace vectors are then used to recover K from all the measurements using a convex program of joint sparsity minimization. Our main contribution is to provide sufficient conditions on the measurement matrices that guarantee the recovery of such a matrix using the above two-step algorithm. The results demonstrate quite significant savings in number of measurements when compared to the standard multiple measurement vector scheme, which assumes same time-invariant measurement pattern for all the time frames. We illustrate the impact of the sampling pattern on reconstruction quality using breath held cardiac cine MRI and cardiac perfusion MRI data, while the utility of the algorithm to accelerate the acquisition is demonstrated on MR parameter mapping.},
  doi      = {10.1109/TCI.2016.2628352},
  keywords = {biomedical MRI;cardiology;convex programming;image reconstruction;image sampling;medical image processing;minimisation;pneumodynamics;sparse matrices;MR parameter mapping;breath;cardiac cine MRI;cardiac perfusion MRI data;convex program;low rank sparse signal subspace aware recovery;matrix X recovery;minimization;multiple measurement vector scheme;sampling pattern;signal acquisition;signal reconstruction quality;subspace vector;time-invariant measurement pattern;two-step algorithm;Jacobian matrices;Magnetic resonance imaging;Navigation;Optimization;Sparse matrices;Time measurement;Joint sparsity;MR acquisition;low rank;subspace learning, rank3},
}

@Article{Wang2017p99-109,
  author   = {Z. Wang and G. AlRegib},
  title    = {Interactive Fault Extraction in 3-D Seismic Data Using the Hough Transform and Tracking Vectors},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {99-109},
  month    = {March},
  abstract = {The exploration of reservoir regions has a close relationship with the localization of faults. Although faults can be labeled in seismic volumes by experienced interpreters, such manual interpretation is inefficient when dealing with a dramatically growing amount of collected seismic data. To speed up the interpretation efficiency of faults, in this paper, we propose a method that semiautomatically detects fault surfaces by using the Hough transform as well as tracking vectors. In the proposed method, we classify seismic sections into reference and predicted ones by borrowing the concept of I- and B-frames in video-coding techniques. For these two types of seismic sections, we introduce different strategies to delineate faults. In reference sections, we first highlight likely fault regions from corresponding coherence maps and apply the Hough transform to extract the features of faults. After removing false features, we optimally connect remaining features under the constraints of coherence maps. Since the accuracy of fault detection in reference sections depends highly on several parameters, to avoid replicating the tweaking of parameters in all seismic sections, we propose tracking detected faults in reference sections through remaining predicted sections, in which faults are labeled based on estimated tracking vectors and geological constraints. To evaluate the performance of the proposed method, we introduce a fault similarity (FauSIM) index that describes the similarity between detected faults and manually picked faults. The FauSIM index based on the Fréchet distance focuses on both the local and global comparisons of faults. Experimental results show that the proposed method has the capability to accurately detect faults in seismic sections, and the tracking process improves interpretation efficiency by eliminating tweaked parameters. In addition, comparisons between faults delineated by various methods and faults manually picked show that- the FauSIM index is highly correlated with interpreters' subjective perception.},
  doi      = {10.1109/TCI.2016.2626998},
  keywords = {Hough transforms;faulting;feature extraction;geophysical image processing;seismology;vectors;video coding;3D seismic data;B-frames;FauSIM index;Fréchet distance;Hough transform;I-frames;coherence maps;estimated tracking vectors;fault feature extraction;fault interpretation efficiency;fault localization;fault similarity index;fault surface semiautomatic detection;geological constraints;interactive fault extraction;reservoir region exploration;video-coding;Fault detection;Feature extraction;Geology;Imaging;Surface treatment;Transforms;Hough transform;Seismic interpretation;fault detection and tracking;fault similarity index;tracking vectors},
}

@Article{Le2017p11-21,
  author   = {M. Le and J. A. Fessler},
  title    = {Efficient, Convergent SENSE MRI Reconstruction for Nonperiodic Boundary Conditions via Tridiagonal Solvers},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {11-21},
  month    = {March},
  issn     = {2333-9403},
  abstract = {Undersampling is an effective method for reducing scan acquisition time for MRI. Strategies for accelerated MRI, such as parallel MRI and compressed sensing MRI present challenging image reconstruction problems with nondifferentiable cost functions and computationally demanding operations. Variable splitting (VS) can simplify implementation of difficult image reconstruction problems, such as the combination of parallel MRI and compressed sensing, CS-SENSE-MRI. Combined with augmented Lagrangian (AL) and alternating minimization strategies, variable splitting can yield iterative minimization algorithms with simpler auxiliary variable updates. However, arbitrary variable splitting schemes are not guaranteed to converge. Many variable splitting strategies are combined with periodic boundary conditions. The resultant circulant Hessians enable O(n log n) computation but may compromise image accuracy at the spatial boundaries. We propose two methods for CS-SENSE-MRI that use regularization with nonperiodic boundary conditions to prevent wrap-around artifacts. Each algorithm computes one of the resulting variable updates efficiently in O(n) time using a parallelizable tridiagonal solver. AL-tridiag is a VS method designed to enable efficient computation for nonperiodic boundary conditions. Another proposed algorithm, ADMM-tridiag, uses a similar VS scheme but also ensures convergence to a minimizer of the proposed cost function using the alternating direction method of multipliers (ADMM). AL-tridiag and ADMM-tridiag show speeds competitive with previous VS CS-SENSE-MRI reconstruction algorithm AL-P2. We also apply the tridiagonal VS approach to a simple image inpainting problem.},
  doi      = {10.1109/TCI.2016.2626999},
  keywords = {biomedical MRI;image reconstruction;iterative methods;medical image processing;minimisation;ADMM-tridiag;AL-tridiag;VS CS-SENSE-MRI AL-P2 reconstruction algorithm;accelerated MRI;alternating direction method of multipliers;alternating minimization strategy;arbitrary variable splitting schemes;augmented Lagrangian strategy;circulant Hessians;compressed sensing MRI;convergent SENSE MRI reconstruction;image inpainting problem;image reconstruction problems;iterative minimization algorithms;nondifferentiable cost functions;nonperiodic boundary conditions;parallel MRI;parallelizable tridiagonal solver;periodic boundary conditions;scan acquisition time reduction;spatial boundary;tridiagonal solvers;wrap-around artifacts;Boundary conditions;Convergence;Cost function;Image reconstruction;Magnetic resonance imaging;Minimization;Alternating direction method of multipliers (ADMM);Image reconstruction;augmented Lagrangian (AL);denoising;inpainting;non-periodic boundaries;parallel magnetic resonance imaging (MRI);tridiagonal solvers;variable splitting},
}

@Article{Farouj2017p1-10,
  author   = {Y. Farouj and J. M. Freyermuth and L. Navarro and M. Clausel and P. Delachartre},
  title    = {Hyperbolic Wavelet-Fisz Denoising for a Model Arising in Ultrasound Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {1},
  pages    = {1-10},
  month    = {March},
  abstract = {We present an algorithm and its fully data-driven extension for noise reduction in ultrasound imaging. The proposed method computes the hyperbolic wavelet transform of the image, before applying a multiscale variance stabilization technique, via a Fisz transformation. This adapts the wavelet coefficients statistics to the wavelet thresholding paradigm. The use of hyperbolic wavelets makes it possible to recover the image while respecting the anisotropic nature of structural details. The data-driven extension obviates the need for any prior knowledge of the noise model parameters by estimating the noise variance using an isotonic Nadaraya-Watson estimator. Experiments on synthetic and real data demonstrate the potential of the proposed algorithm to recover ultrasound images while preserving tissue details. Furthermore, comparisons with other noise-reduction methods show that our technique is competitive with the state-of-the-art OBNLM filter. Finally, the variance estimation procedure is applied to real images emphasizing the noise model.},
  doi      = {10.1109/TCI.2016.2625740},
  keywords = {biomedical ultrasonics;estimation theory;hyperbolic equations;image denoising;image segmentation;medical image processing;wavelet transforms;Fisz transformation;Nadaraya-Watson estimator;data-driven extension;hyperbolic wavelet transform;image denoising;noise reduction;noise variance estimation;ultrasound imaging;variance stabilization technique;wavelet coefficient statistic;wavelet thresholding;Adaptation models;Imaging;Noise reduction;Ultrasonic imaging;Wavelet transforms;Data-driven denoising;Fisz transformation;Gaussianization;Hyperbolic wavelets;Ultrasound imaging;Variance stabilization},
}

@Article{Altmann2016p456-467,
  author   = {Y. Altmann and X. Ren and A. McCarthy and G. S. Buller and S. McLaughlin},
  title    = {Robust Bayesian Target Detection Algorithm for Depth Imaging From Sparse Single-Photon Data},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {456-467},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {This paper presents a new Bayesian model and associated algorithm for depth and intensity profiling using full waveforms from time-correlated single-photon counting measurements in the limit of very low photon counts (i.e., typically less than 20 photons per pixel). The model represents each Lidar waveform as an unknown constant background level, which is combined in the presence of a target, to a known impulse response weighted by the target intensity and finally corrupted by Poisson noise. The joint target detection and depth imaging problem is expressed as a pixelwise model selection and estimation problem, which is solved using Bayesian inference. Prior knowledge about the problem is embedded in a hierarchical model that describes the dependence structure between the model parameters while accounting for their constraints. In particular, Markov random fields (MRFs) are used to model the joint distribution of the background levels and of the target presence labels, which are both expected to exhibit significant spatial correlations. An adaptive Markov chain Monte Carlo algorithm including reversible-jump updates is then proposed to compute the Bayesian estimates of interest. This algorithm is equipped with a stochastic optimization adaptation mechanism that automatically adjusts the parameters of the MRFs by maximum marginal likelihood estimation. Finally, the benefits of the proposed methodology are demonstrated through a series of experiments using real data.},
  doi      = {10.1109/TCI.2016.2618323},
  keywords = {Markov processes;Monte Carlo methods;belief networks;object detection;optical radar;radar imaging;Bayesian estimates;Bayesian inference;Bayesian model;Lidar waveform;MRF;Markov random fields;Poisson noise;adaptive Markov chain Monte Carlo algorithm;background levels;constant background level;depth imaging problem;estimation problem;hierarchical model;impulse response;intensity profiling;marginal likelihood estimation;pixelwise model selection;reversible-jump updates;robust Bayesian target detection algorithm;sparse single-photon data;stochastic optimization adaptation mechanism;target presence labels;time-correlated single-photon counting measurements;waveforms;Adaptation models;Bayes methods;Estimation;Imaging;Markov processes;Object detection;Photonics;Bayesian estimation;full waveform Lidar;poisson statistics;remote sensing;reversible jump Markov chain monte carlo;target detection},
}

@Article{Fu2017p408-420,
  author   = {C. Fu and M. L. Don and G. R. Arce},
  title    = {Compressive Spectral Imaging via Polar Coded Aperture},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {408-420},
  month    = {Sept},
  abstract = {A compressive spectral imager based on a polar coded aperture and a continuous variable circular bandpass filter is proposed for spinning munitions. As the imager rotates with the munition, compressive projections are sequentially captured with embedded spatial and spectral modulation. The polar coded aperture design is introduced, aiming at optimizing the sensing process. Both discrete and continuous rotation models of the proposed imager are derived and used to characterize the compressive imager. Computer simulations validate the computational models and the reconstruction algorithm.},
  doi      = {10.1109/TCI.2016.2617740},
  keywords = {band-pass filters;compressed sensing;image coding;image filtering;image reconstruction;modulation;spectral analysis;compressive projections;compressive spectral imager;compressive spectral imaging;computer simulations;continuous rotation model;continuous variable circular bandpass filter;discrete rotation model;embedded spatial modulation;polar coded aperture design;reconstruction algorithm;sensing process;spectral modulation;spinning munitions;Apertures;Compressed sensing;Image coding;Modulation;Sensors;Spatial resolution;Compressed sensing;circular viable filter;continuous rotation model;image coding;polar coded aperture},
}

@Article{Syed2016p540-549,
  author   = {T. A. Syed and V. P. Krishnan and J. Sivaswamy},
  title    = {Numerical Inversion of Circular arc Radon Transform},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {540-549},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Circular arc Radon (CAR) transforms associate to a function, its integrals along arcs of circles. The inversion of such transforms is of natural interest in several imaging modalities such as thermoacoustic and photoacoustic tomography, ultrasound, and intravascular imaging. Unlike the full circle counterpart-the circular Radon transform-which has attracted significant attention in recent years, the CAR transforms are scarcely studied objects. In this paper, we present an efficient algorithm for the numerical inversion of the CAR transform with fixed angular span, for the cases in which the support of the function lies entirely inside or outside the acquisition circle. The numerical algorithm is noniterative and is very efficient as the entire scheme, once processed, can be stored and used repeatedly for reconstruction of images. A modified numerical inversion algorithm is also presented to reduce the artifacts in the reconstructed image which are induced due to the limited angular span.},
  doi      = {10.1109/TCI.2016.2615806},
  keywords = {Radon transforms;image reconstruction;inverse transforms;CAR transforms;acquisition circle;circular arc Radon transform;fixed angular span;image reconstruction;imaging modalities;integrals;intravascular imaging;noniterative numerical algorithm;numerical inversion algorithm;photoacoustic tomography;thermoacoustic tomography;ultrasound imaging;Automobiles;Detectors;Image reconstruction;Imaging;Integral equations;Radon;Transforms;Circular arc Radon transform;circular Radon transform;streak artifacts;trapezoidal product integration method;truncated singular value decomposition;volterra integral equations},
}

@Article{Mao2016p524-539,
  author   = {X. Mao and D. Zhu},
  title    = {Two-dimensional Autofocus for Spotlight SAR Polar Format Imagery},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {524-539},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Conventional two-dimensional (2-D) autofocus algorithms blindly estimate the phase error in the sense that they do not exploit any a priori information on the structure of the 2-D phase error. As such, they often suffer from the low computational efficiency and the lack of data redundancy to accurately estimate the 2-D phase error. In this paper, an efficient semi-blind 2-D autofocus algorithm which is based on exploiting the a priori knowledge about the 2-D phase error structure, is presented. First, as a prerequisite of the proposed method, the analytical structure of the residual 2-D phase error in SAR imagery is investigated in the polar format algorithm framework. Then, by incorporating this a priori information, a novel 2-D autofocus approach is proposed. The new method only requires an estimate of the azimuth phase error and/or residual range cell migration, while the 2-D phase error can then be computed directly from the estimated azimuth phase error or residual range cell migration. Experimental results clearly demonstrate the effectiveness and the robustness of the proposed method.},
  doi      = {10.1109/TCI.2016.2612945},
  keywords = {radar imaging;synthetic aperture radar;2D phase error structure;azimuth phase error;data redundancy;residual range cell migration;spotlight SAR polar format imagery;two-dimensional autofocus algorithm;Azimuth;Estimation;Frequency-domain analysis;Image resolution;Imaging;Radar imaging;Synthetic aperture radar;Phase gradient autofocus;polar format algorithm;synthetic aperture radar;two-dimensional autofocus},
}

@Article{Parada-Mayorga2016p440-455,
  author   = {A. Parada-Mayorga and G. R. Arce},
  title    = {Spectral Super-Resolution in Colored Coded Aperture Spectral Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {440-455},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Colored coded apertures have been recently introduced in compressive spectral imaging as a method to improve the quality of image reconstructions in terms of signal to noise ratio. This paper shows that colored coded apertures, in addition, can also provide a higher number of resolvable spectral bands. Colored coded apertures with real and ideal spectral responses are both considered. The maximum number of resolvable bands for the case of nonideal filters is estimated using the coherence of the sensing matrix which provides a condition that depends only on the characteristics of the optical filters involved in the colored coded aperture. Simulations and testbed experimental reconstructions with real data are presented.},
  doi      = {10.1109/TCI.2016.2612943},
  keywords = {geophysical image processing;hyperspectral imaging;image colour analysis;image reconstruction;image resolution;matrix algebra;optical filters;colored coded apertures;compressive spectral imaging;image reconstruction quality;nonideal filters;optical filters;sensing matrix;spectral super resolution;Apertures;Image reconstruction;Image resolution;Optical imaging;Optical sensors;CASSI;coherence;colored coded aperture;optical filter;sensing matrix;spectral imaging},
}

@Article{Gong2017p493-502,
  author   = {Q. Gong and E. Vera and D. R. Golish and S. D. Feller and D. J. Brady and M. E. Gehm},
  title    = {Model-Based Multiscale Gigapixel Image Formation Pipeline on GPU},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {493-502},
  month    = {Sept},
  abstract = {We present an efficient and flexible GPU implementation of a highly-parallelizable and scalable image formation pipeline for gigapixel images based on the MapReduce framework. The presented implementation was developed to operate with the AWARE multiscale gigapixel cameras, but it is also able to efficiently form gigapixel images from any source. The AWARE cameras are compact camera arrays that simultaneously collect images that span a wide field-of-view to generate high-resolution and high dynamic range panoramic images and video. The proposed GPU implementation exploits the mutiscale nature of the AWARE image acquisition, not only enabling the fast composition of gigapixel-scale panoramas, but also the rapid formation of images of arbitrary portions of the field-of-view at current display-scale resolutions at video rates.},
  doi      = {10.1109/TCI.2016.2612942},
  keywords = {cameras;computer vision;data handling;graphics processing units;pipeline processing;AWARE image acquisition;AWARE multiscale gigapixel cameras;MapReduce framework;display-scale resolutions;field-of-view arbitrary portions;gigapixel images;gigapixel-scale panoramas;high dynamic range video;high-resolution panoramic images;highly-parallelizable scalable image formation pipeline;model-based multiscale gigapixel image formation pipeline GPU;video rates;Cameras;Detectors;Graphics processing units;Image color analysis;Image resolution;GPU;Gigapixel imaging;MapReduce;image formation},
}

@Article{Chun2016p424-439,
  author   = {I. Y. Chun and S. Noh and D. J. Love and T. M. Talavage and S. Beckley and S. J. Kisner},
  title    = {Mean Squared Error Based Excitation Pattern Design for Parallel Transmit and Receive SENSE MRI Image Reconstruction},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {424-439},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Parallel coils at both the transmitter and receiver can be used to offer more control over the magnetic resonance imaging (MRI) system, and this implementation has potential to improve the performance in high-field MRI. A new MSE-based EXcitation Pattern (MSE-EXP) design for image reconstruction in parallel transmit and receive SENSitivity Encoding (pTxRx SENSE) MRI is presented in this paper to maximize the performance of an MRI using an array of transmit and receive coils. In the the small-tip-angle regime, we derive theoretically effective excitation patterns for fully-sampled k-space data (with no SNR assumption) and for under-sampled k-space data under both low and high SNR assumptions. The proposed MSE-EXP-encoded pTxRx SENSE MRI has two main advantages for high-field MRI, one is the specific absorption rate (SAR) management through prespecification of the global SAR regulatory limit in the excitation pattern design weight constraint and an another is the imaging acceleration by effective reduction of aliasing artifacts, particularly for advanced image reconstruction in highly under-sampled pTxRx SENSE MRI in the high-SNR regime. Numerical experiments demonstrate that reconstruction accuracy in pTxRx SENSE MRI is significantly improved by the proposed MSE-EXP design, but our study also identifies several practical challenges associated with generation of the proposed MSE-EXP.},
  doi      = {10.1109/TCI.2016.2610141},
  keywords = {antialiasing;biomedical MRI;encoding;image reconstruction;mean square error methods;parallel algorithms;sensitivity;MSE-EXP design;MSE-based excitation pattern;SAR management;SENSE MRI image reconstruction;aliasing artifact reduction;coil array;excitation pattern design weight constraint;image quality;imaging acceleration;k-space data;magnetic resonance imaging;mean squared error;medical imaging;multimodal neuroimaging;pTxRx SENSE MRI;parallel coils;parallel transmit and receive sensitivity encoding;specific absorption rate;Acceleration;Coils;Image reconstruction;Magnetic resonance imaging;Radio frequency;Signal to noise ratio;High-field MRI;MSE-based excitation pattern design;SENSitivity encoding;image reconstruction;pTxRx SENSE MRI;parallel MRI;parallel excitation},
}

@Article{Zhang2016p510-523,
  author   = {Y. Zhang and Y. Xi and Q. Yang and W. Cong and J. Zhou and G. Wang},
  title    = {Spectral CT Reconstruction With Image Sparsity and Spectral Mean},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {510-523},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Photon-counting detectors can acquire x-ray intensity data in different energy bins. The signal-to-noise ratio of resultant raw data in each energy bin is generally low due to the narrow bin width and quantum noise. To address this problem, here we propose an image reconstruction approach for spectral CT to simultaneously reconstruct x-ray attenuation coefficients in all the energy bins. Because the measured spectral data are highly correlated among the x-ray energy bins, the intraimage sparsity and interimage similarity are important prior knowledge for image reconstruction. Inspired by this observation, the total variation and spectral mean measures are combined to improve the quality of reconstructed images. For this purpose, a linear mapping function is used to minimalize image differences between energy bins. The split Bregman technique is applied to perform image reconstruction. Our numerical and experimental results show that the proposed algorithms outperform competing iterative algorithms in this context.},
  doi      = {10.1109/TCI.2016.2609414},
  keywords = {computerised tomography;image reconstruction;medical image processing;X-ray attenuation coefficients reconstruction;X-ray energy bins;energy bins;image reconstruction approach;interimage similarity;intraimage sparsity;linear mapping function;spectral CT reconstruction;spectral mean;split Bregman technique;Algorithm design and analysis;Computed tomography;Image reconstruction;Photonics;Spectral analysis;X-ray imaging;Computed tomography (CT);image reconstruction;spectral CT;spectral mean (SM);total variation (TV)},
}

@Article{Talebi2016p496-509,
  author   = {H. Talebi and P. Milanfar},
  title    = {Fast Multilayer Laplacian Enhancement},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {496-509},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {A novel, fast, and practical way of enhancing images is introduced in this paper. Our approach builds on Laplacian operators of well-known edge-aware kernels, such as bilateral and nonlocal means, and extends these filter's capabilities to perform more effective and fast image smoothing, sharpening, and tone manipulation. We propose an approximation of the Laplacian, which does not require normalization of the kernel weights. Multiple Laplacians of the affinity weights endow our method with progressive detail decomposition of the input image from fine to coarse scale. These image components are blended by a structure mask, which avoids noise/artifact magnification or detail loss in the output image. Contributions of the proposed method to existing image editing tools are: 1) low computational and memory requirements, making it appropriate for mobile device implementations (e.g., as a finish step in a camera pipeline); and 2) a range of filtering applications from detail enhancement to denoising with only a few control parameters, enabling the user to apply a combination of various (and even opposite) filtering effects.},
  doi      = {10.1109/TCI.2016.2607142},
  keywords = {Laplace transforms;cameras;image denoising;image enhancement;mobile computing;Laplacian operators;bilateral means;camera pipeline;computational requirements;control parameters;edge-aware kernels;fast image sharpening;fast image smoothing;fast multilayer Laplacian image enhancement;filter capabilities;image components;image denoising;image editing tools;kernel weight normalization;memory requirements;mobile device implementations;nonlocal means;tone manipulation;Image edge detection;Image enhancement;Imaging;Kernel;Laplace equations;Smoothing methods;Symmetric matrices;Image enhancement;image editing;image sharpening;image smoothing;local tone mapping},
}

@Article{Jin2016p480-495,
  author   = {K. H. Jin and D. Lee and J. C. Ye},
  title    = {A General Framework for Compressed Sensing and Parallel MRI Using Annihilating Filter Based Low-Rank Hankel Matrix},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {480-495},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Parallel MRI (pMRI) and compressed sensing MRI (CS-MRI) have been considered as two distinct reconstruction problems. Inspired by recent k-space interpolation methods, an annihilating filter-based low-rank Hankel matrix approach is proposed as a general framework for sparsity-driven k-space interpolation method which unifies pMRI and CS-MRI. Specifically, our framework is based on a novel observation that the transform domain sparsity in the primary space implies the low-rankness of weighted Hankel matrix in the reciprocal space. This converts pMRI and CS-MRI to a k-space interpolation problem using a structured matrix completion. Experimental results using in vivo data for single/multicoil imaging as well as dynamic imaging confirmed that the proposed method outperforms the state-of-the-art pMRI and CS-MRI.},
  doi      = {10.1109/TCI.2016.2601296},
  keywords = {biomedical MRI;compressed sensing;filtering theory;interpolation;matrix algebra;medical image processing;CS-MRI;annihilating filter;compressed sensing MRI;k-space interpolation method;low-rank Hankel matrix;magnetic resonance imaging;parallel MRI;sparsity-driven k-space interpolation method;structured matrix completion;transform domain sparsity;Compressed sensing;Image reconstruction;Magnetic resonance imaging;Sensitivity;Wavelet transforms;Annihilating filter;cardinal spline;compressed sensing;parallel MRI;pyramidal representation;structured low rank block Hankel matrix completion;wavelets},
}

@Article{Kaur2016p550-561,
  author   = {H. Kaur and J. S. Sahambi},
  title    = {Vehicle Tracking in Video Using Fractional Feedback Kalman Filter},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {550-561},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Object tracking is a challenging and important area of research. The object tracking system must be capable of tracking abrupt variations in object state. Kalman filter is fundamental and widely used as an optimal state estimator in object tracking. With known noise and system parameters, Kalman filter tends to stabilize the gain. However, during sudden transitions of the object tracked, constant gain Kalman filter may diverge. This paper proposes a modified steady-state gain of the Kalman filter, which is achieved by introducing a fractional feedback loop across the Kalman gain. The modified Kalman gain is estimated by minimizing the cost function of the proposed Kalman filter. Results show that the accuracy and robustness of the Kalman filter are significantly improved. The performance of the proposed method is compared with that of the standard Kalman filter, fractional-order Kalman filter, and unscented Kalman filter. In this work, the root mean square error is used as the performance metric. The proposed method has been tested for different datasets, including traffic videos. Experiments show that RMSE is improved upto $17%$ by using the proposed modified Kalman filter.},
  doi      = {10.1109/TCI.2016.2600480},
  keywords = {Kalman filters;estimation theory;feedback;minimisation;object tracking;road traffic;road vehicles;stability;video signal processing;Kalman filter;Kalman gain estimation;cost function minimization;fractional feedback loop;gain stabilization;object tracking system;traffic video;vehicle tracking;Feedback loop;Imaging;Kalman filters;Monitoring;Standards;Steady-state;Vehicles;Fractional derivative;Grünwald–Letnikov;Kalman filter;image processing;vehicle tracking},
}

@Article{Sreehari2016p408-423,
  author   = {S. Sreehari and S. V. Venkatakrishnan and B. Wohlberg and G. T. Buzzard and L. F. Drummy and J. P. Simmons and C. A. Bouman},
  title    = {Plug-and-Play Priors for Bright Field Electron Tomography and Sparse Interpolation},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {408-423},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Many material and biological samples in scientific imaging are characterized by nonlocal repeating structures. These are studied using scanning electron microscopy and electron tomography. Sparse sampling of individual pixels in a two-dimensional image acquisition geometry, or sparse sampling of projection images with large tilt increments in a tomography experiment, can enable high speed data acquisition and minimize sample damage caused by the electron beam. In this paper, we present an algorithm for electron tomographic reconstruction and sparse image interpolation that exploits the nonlocal redundancy in images. We adapt a framework, termed plug-and-play priors, to solve these imaging problems in a regularized inversion setting. The power of the plug-and-play approach is that it allows a wide array of modern denoising algorithms to be used as a “prior model” for tomography and image interpolation. We also present sufficient mathematical conditions that ensure convergence of the plug-and-play approach, and we use these insights to design a new nonlocal means denoising algorithm. Finally, we demonstrate that the algorithm produces higher quality reconstructions on both simulated and real electron microscope data, along with improved convergence properties compared to other methods.},
  doi      = {10.1109/TCI.2016.2599778},
  keywords = {compressed sensing;image denoising;image reconstruction;image sampling;interpolation;physics computing;scanning electron microscopy;tomography;2D image acquisition geometry;bright field electron tomography;electron tomographic reconstruction;high speed data acquisition;nonlocal means denoising algorithm;nonlocal redundancy;nonlocal repeating structures;pixels sparse sampling;plug-and-play priors;projection images sparse sampling;scanning electron microscopy;scientific imaging;sparse image interpolation;sparse interpolation;Image reconstruction;Interpolation;Microscopy;Noise reduction;Redundancy;Tomography;BM3D;Plug-and-play;bright field electron tomography;doubly stochastic gradient non-local means;non-local means;prior modeling;sparse interpolation},
}

@Article{Pustelnik2016p468-479,
  author   = {N. Pustelnik and H. Wendt and P. Abry and N. Dobigeon},
  title    = {Combining Local Regularity Estimation and Total Variation Optimization for Scale-Free Texture Segmentation},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {468-479},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Texture segmentation constitutes a standard image processing task, crucial for many applications. The present contribution focuses on the particular subset of scale-free textures and its originality resides in the combination of three key ingredients: First, texture characterization relies on the concept of local regularity; Second, estimation of local regularity is based on new multiscale quantities referred to as wavelet leaders; Third, segmentation from local regularity faces a fundamental bias variance tradeoff. In nature, local regularity estimation shows high variability that impairs the detection of changes, while a posteriori smoothing of regularity estimates precludes from locating correctly changes. Instead, the present contribution proposes several variational problem formulations based on total variation and proximal resolutions that effectively circumvent this tradeoff. Estimation and segmentation performance for the proposed procedures are quantified and compared on synthetic as well as on real-world textures.},
  doi      = {10.1109/TCI.2016.2594139},
  keywords = {face recognition;image resolution;image segmentation;image texture;object detection;smoothing methods;wavelet transforms;bias variance tradeoff;changes detection;local regularity estimation;local regularity faces segmentation;multiscale quantities;posteriori smoothing;proximal resolutions;scale-free texture segmentation;standard image processing;texture characterization;total variation optimization;wavelet leaders;Estimation;Fractals;Image resolution;Image segmentation;TV;Wavelet analysis;Wavelet transforms;Convex functions;image texture analysis;optimization methods;wavelet transforms},
}

@Article{Asif2017p384-397,
  author   = {M. S. Asif and A. Ayremlou and A. Sankaranarayanan and A. Veeraraghavan and R. G. Baraniuk},
  title    = {FlatCam: Thin, Lensless Cameras Using Coded Aperture and Computation},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {384-397},
  month    = {Sept},
  abstract = {FlatCam is a thin form-factor lensless camera that consists of a coded mask placed on top of a bare, conventional sensor array. Unlike a traditional, lens-based camera, where an image of the scene is directly recorded on the sensor pixels, each pixel in FlatCam records a linear combination of light from multiple scene elements. A computational algorithm is then used to demultiplex the recorded measurements and reconstruct an image of the scene. FlatCam is an instance of a coded aperture imaging system; however, unlike the vast majority of related work, we place the coded mask extremely close to the image sensor that enables thin and flat form-factor imaging devices. We employ a separable mask to ensure that both calibration and image reconstruction are scalable in terms of memory requirements and computational complexity. We demonstrate the potential of the FlatCam design using two prototypes: one at visible wavelengths and one at infrared wavelengths.},
  doi      = {10.1109/TCI.2016.2593662},
  keywords = {cameras;image coding;image reconstruction;image sensors;FlatCam;calibration;coded aperture imaging system;coded mask;computational algorithm;computational complexity;flat form-factor imaging devices;image reconstruction;image sensor;infrared wavelengths;lens-based camera;memory requirements;scene elements;sensor array;thin form-factor lensless camera;visible wavelengths;Apertures;Cameras;Image reconstruction;Lenses;Photography;Computational photography;binary mask;image reconstruction;infrared camera},
}

@Article{Alipoor2016p375-391,
  author   = {M. Alipoor and I. Y. H. Gu and S. E. Maier and G. Starck and A. Mehnert and F. Kahl},
  title    = {Optimal Gradient Encoding Schemes for Diffusion Tensor and Kurtosis Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {375-391},
  month    = {Sept},
  issn     = {2333-9403},
  abstract = {Diffusion-derived parameters find application in characterizing pathological and developmental changes in living tissues. Robust estimation of these parameters is important because they are used for medical diagnosis. An optimal gradient encoding scheme (GES) is one that minimizes the variance of the estimated diffusion parameters. This paper proposes a method for optimal GES design for two diffusion models: high-order diffusion tensor (HODT) imaging and diffusion kurtosis imaging (DKI). In both cases, the optimal GES design problem is formulated as a D-optimal (minimum determinant) experiment design problem. Then, using convex relaxation, it is reformulated as a semidefinite programming problem. Solving these problems we show that: 1) there exists a D-optimal solution for DKI that is simultaneously D-optimal for second- and fourth-order diffusion tensor imaging (DTI); 2) the traditionally used icosahedral scheme is approximately D-optimal for DTI and DKI; 3) the proposed D-optimal design is rotation invariant; 4) the proposed method can be used to compute the optimal design (b-values and directions) for an arbitrary number of measurements and shells; and 5) using the proposed method one can obtain uniform distribution of gradient encoding directions for a typical number of measurements. Importantly, these theoretical findings provide the first mathematical proof of the optimality of uniformly distributed GESs for DKI and HODT imaging. The utility of the proposed method is further supported by the evaluation results and comparisons with with existing methods.},
  doi      = {10.1109/TCI.2016.2590301},
  keywords = {biomedical MRI;gradient methods;mathematical programming;medical image processing;patient diagnosis;tensors;DKI;GES;HODT imaging;MRI;diffusion kurtosis imaging;diffusion tensor;high order diffusion tensor;icosahedral scheme;kurtosis imaging;living tissues;mathematical proof;medical diagnosis;optimal GES design problem;optimal gradient encoding scheme;optimal gradient encoding schemes;robust estimation;semidefinite programming problem;Covariance matrices;Diffusion tensor imaging;Encoding;Estimation;Tensile stress;Diffusion kurtosis imaging;high order diffusion tensor imaging;icosahedral scheme;optimal experiment design;optimal gradient encoding;semi-definite programming},
}

@Article{Zhang2016p359-374,
  author   = {R. Zhang and D. H. Ye and D. Pal and J. B. Thibault and K. D. Sauer and C. A. Bouman},
  title    = {A Gaussian Mixture MRF for Model-Based Iterative Reconstruction With Applications to Low-Dose X-Ray CT},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {359-374},
  month    = {Sept},
  issn     = {2333-9403},
  abstract = {Markov random fields (MRFs) have been widely used as prior models in various inverse problems such as tomographic reconstruction. While MRFs provide a simple and often effective way to model the spatial dependencies in images, they suffer from the fact that parameter estimation is difficult. In practice, this means that MRFs typically have very simple structure that cannot completely capture the subtle characteristics of complex images. In this paper, we present a novel Gaussian mixture Markov random field model (GM-MRF) that can be used as a very expressive prior model for inverse problems such as denoising and reconstruction. The GM-MRF forms a global image model by merging together individual Gaussian-mixture models (GMMs) for image patches. In addition, we present a novel analytical framework for computing MAP estimates using the GM-MRF prior model through the construction of surrogate functions that result in a sequence of quadratic optimizations. We also introduce a simple but effective method to adjust the GM-MRF so as to control the sharpness in low- and high-contrast regions of the reconstruction separately. We demonstrate the value of the model with experiments including image denoising and low-dose CT reconstruction.},
  doi      = {10.1109/TCI.2016.2582042},
  keywords = {Gaussian processes;Markov processes;computerised tomography;image denoising;image reconstruction;inverse problems;iterative methods;maximum likelihood estimation;medical image processing;mixture models;quadratic programming;GM-MRF;GMM;Gaussian mixture MRF;Gaussian mixture Markov random field model;Gaussian-mixture models;MAP estimate;complex image characteristics;high-contrast region;image denoising;image patch;image spatial dependency;inverse problems;low-contrast region;low-dose CT reconstruction;low-dose X-ray CT;model-based iterative reconstruction;parameter estimation;quadratic optimization;sharpness control;tomographic reconstruction;Adaptation models;Computational modeling;Computed tomography;Image reconstruction;Optimization;Gaussian mixture model (GMM);Markov random field (MRF);image model;model-based iterative reconstruction (MBIR);patch-based method;prior modeling},
}

@Article{Gueven2016p235-250,
  author   = {H. E. Güven and A. Güngör and M. Çetin},
  title    = {An Augmented Lagrangian Method for Complex-Valued Compressed SAR Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {235-250},
  month    = {Sept},
  issn     = {2333-9403},
  abstract = {In this paper, we present a solution to the complex synthetic aperture radar (SAR) imaging problem within a constrained optimization formulation where the objective function includes a combination of the $\ell _1$-norm and the total variation of the magnitude of the complex valued reflectivity field. The technique we present relies on recent advances in the solution of optimization problems, based on Augmented Lagrangian Methods, and in particular on the Alternating Direction Method of Multipliers (ADMM). We rigorously derive the proximal mapping operators, associated with a linear transform of the magnitude of the reflectivity vector and magnitude-total-variation cost functions, for complex-valued SAR images, and thus enable the use of ADMM techniques to obtain computationally efficient solutions for radar imaging. We study the proposed techniques with multiple features (sparse and piecewise-constant in magnitude) based on a weighted sum of the 1-norm and magnitude-total-variation. We derive a fast implementation of the algorithm using only two transforms per iteration for problems admitting unitary transforms as forward models. Experimental results on real data from TerraSAR-X and SARPER-airborne SAR system developed by ASELSAN-demonstrate the effectiveness of the proposed approach.},
  doi      = {10.1109/TCI.2016.2580498},
  keywords = {compressed sensing;data compression;image coding;iterative methods;optimisation;radar imaging;remote sensing by radar;synthetic aperture radar;transforms;ADMM;ASELSAN;SARPER;TerraSAR-X;admitting unitary transforms;airborne SAR system;alternating direction method-of-multipliers;augmented Lagrangian method;complex synthetic aperture radar imaging problem;complex valued reflectivity field;complex-valued compressed SAR imaging;constrained optimization formulation;l1-norm;linear transform;magnitude-total-variation;objective function;proximal mapping operators;Cost function;Image reconstruction;Imaging;Radar imaging;Radar polarimetry;Synthetic aperture radar},
}

@Article{Zhao2016p395-407,
  author   = {H. Zhao and M. Comer},
  title    = {A Hybrid Markov Random Field/Marked Point Process Model for Analysis of Materials Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {4},
  pages    = {395-407},
  month    = {Dec},
  issn     = {2333-9403},
  abstract = {Both Markov random field (MRF) and marked point process (MPP) models have some limitations for image analysis. While the MRF is useful for imposing local constraints, global constraints are not easily modeled. On the contrary, it is convenient to model global constraints, such as geometric shape and object interactions, within the MPP framework, but such an object-based MPP model has limited capability for imposing local constraints such as pixel-wise interactions. In this paper, we propose a combined model that incorporates both local and global constraints within a single energy function. Optimization using our model is performed using simulation schemes, including reversible jump Markov chain Monte Carlo and multiple birth and death algorithms. We also present results using iterated conditional modes for optimization. Although our model should be useful for any application that requires both global information and precise boundary localization, we consider the analysis of microscope images of materials in this paper. We present experimental results to compare our model to the MPP model for object detection and the MRF model for segmentation.},
  doi      = {10.1109/TCI.2016.2579601},
  keywords = {Markov processes;Monte Carlo methods;image segmentation;iterative methods;object detection;optimisation;MPP model;MRF model;Markov random field model;global information;image segmentation;iterated conditional modes;marked point process model;material image analysis;object detection;optimization;precise boundary localization;reversible jump Markov chain Monte Carlo;simulation schemes;single energy function;Computational modeling;Image segmentation;Imaging;Markov processes;Object detection;Optimization;Random variables;Image segmentation;Markov random field (MRF);Monte Carlo simulation;marked point process (MPP);object detection},
}

@Article{Chan2016p348-358,
  author   = {K. G. Chan and S. J. Streichan and L. A. Trinh and M. Liebling},
  title    = {Simultaneous Temporal Superresolution and Denoising for Cardiac Fluorescence Microscopy},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {348-358},
  month    = {Sept},
  issn     = {2333-9403},
  abstract = {Due to low-light emission of fluorescent samples, live fluorescence microscopy imposes a tradeoff between spatio-temporal resolution and signal-to-noise ratio. This can result in images and videos containing motion blur or Poisson-type shot noise, depending on the settings used during acquisition. Here, we propose an algorithm to simultaneously denoise and temporally superresolve movies of repeating microscopic processes that is compatible with any conventional microscopy setup that can achieve imaging at a rate of at least twice that of the fundamental frequency of the process (above 4 frames per second for a 2-Hz process). Our method combines low temporal resolution frames from multiple cycles of a repeating process to reconstruct a denoised, higher temporal resolution image sequence which is the solution to a linear program that maximizes the consistency of the reconstruction with the measurements, under a regularization constraint. This paper describes, in particular, a parallelizable superresolution reconstruction algorithm and demonstrates its application to live cardiac fluorescence microscopy. Using our method, we experimentally show temporal resolution improvement by a factor of 1.6, resulting in a visible reduction of motion blur in both on-sample and off-sample frames.},
  doi      = {10.1109/TCI.2016.2579606},
  keywords = {cardiology;fluorescence;image denoising;image resolution;image restoration;image sequences;medical image processing;video signal processing;Poisson-type shot noise;cardiac fluorescence microscopy;denoising;image sequence;linear program;microscopic processes;microscopy setup;motion blur;parallelizable superresolution reconstruction algorithm;regularization constraint;signal-to-noise ratio;simultaneous temporal superresolution;spatio-temporal resolution;videos;Cameras;Image reconstruction;Microscopy;Signal resolution;Spatial resolution;Fluorescence microscopy;image denoising;image reconstruction;motion blur;temporal superresolution},
}

@Article{Wang2016p218-234,
  author   = {X. Wang and J. Liang},
  title    = {Multi-Resolution Compressed Sensing Reconstruction Via Approximate Message Passing},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {218-234},
  month    = {Sept},
  issn     = {2333-9403},
  abstract = {In this paper, we consider the problem of multiresolution compressed sensing (MR-CS) reconstruction, which has received little attention in the literature. Instead of always reconstructing the signal at the original high resolution (HR), we enable the reconstruction of a low-resolution (LR) signal when there are insufficient CS samples to recover an HR signal. We propose an approximate message passing (AMP)-based framework dubbed MR-AMP and derive its state evolution, phase transition, and noise sensitivity, which show that, in addition to its reduced complexity, our method can recover an LR signal with bounded noise sensitivity even when the noise sensitivity of the conventional HR reconstruction is unbounded. We then apply the MR-AMP to image reconstruction using either soft-thresholding or a total variation denoiser and develop three pairs of up-/downsampling operators in the transform or spatial domain. The performance of the proposed scheme is demonstrated on both one-dimensional synthetic data and two-dimensional images.},
  doi      = {10.1109/TCI.2016.2575741},
  keywords = {approximation theory;data compression;image coding;image denoising;image reconstruction;image resolution;AMP-based framework;MR-CS reconstruction;approximate message passing;high resolution;image reconstruction;low-resolution signal;multiresolution compressed sensing reconstruction;noise sensitivity;one-dimensional synthetic data;phase transition;state evolution;total variation denoiser;two-dimensional images;Complexity theory;Image reconstruction;Image resolution;Imaging;Message passing;Sensitivity;Signal resolution;Approximate message passing;compressed sensing;multi-resolution;phase transition;state evolution},
}

@Article{Ono2016p204-217,
  author   = {S. Ono and I. Yamada},
  title    = {Color-Line Regularization for Color Artifact Removal},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {204-217},
  month    = {Sept},
  issn     = {2333-9403},
  abstract = {Existing regularization functions for color image restoration cannot remove color artifact, undesirable appearance of colors, sufficiently, which degrades the quality of color images. In this paper, we propose a new regularization function, named the local color nuclear norm (LCNN), for removing color artifact in color image restoration. LCNN is designed to promote the local color-line property: the color distribution of each local region of a color image exhibits strong linearity. The local color-line property is inherent in clean color images and is violated by color artifact, so that suppressing LCNN is expected to reduce color artifact effectively. In addition, the very nature of LCNN allows us to incorporate it into various color image restoration formulations, where the associated optimization problems can be efficiently solved by proximal splitting techniques. Several illustrative applications of LCNN are presented with comprehensive experimental results.},
  doi      = {10.1109/TCI.2016.2575740},
  keywords = {image colour analysis;image restoration;optimisation;LCNN;associated optimization problems;color artifact removal;color image restoration formulations;color line property;color line regularization;local color nuclear norm;proximal splitting techniques;regularization function;Color;Colored noise;Image color analysis;Image restoration;Imaging;Optimization;Smoothing methods;Color image restoration;proximal splitting;regularization},
}

@Article{Zhong2016p310-322,
  author   = {J. Zhong and L. Tian and P. Varma and L. Waller},
  title    = {Nonlinear Optimization Algorithm for Partially Coherent Phase Retrieval and Source Recovery},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {310-322},
  month    = {Sept},
  abstract = {We propose a new algorithm for recovering both complex field (phase and amplitude) and source distribution (illumination spatial coherence) from a stack of intensity images captured through focus. The joint recovery is formulated as a nonlinear least-square-error optimization problem, which is solved iteratively by a modified Gauss-Newton method. We derive the gradient and Hessian of the cost function and show that our second-order optimization approach outperforms previously proposed phase retrieval algorithms, for datasets taken with both coherent and partially coherent illumination. The method is validated experimentally in a commercial microscope with both Köhler illumination and a programmable light-emitting diode dome.},
  doi      = {10.1109/TCI.2016.2571669},
  keywords = {Newton method;image reconstruction;least squares approximations;light emitting diodes;lighting;nonlinear programming;Gauss-Newton method;Köhler illumination;amplitude field;complex field;illumination spatial coherence;image reconstruction;intensity images;joint recovery;nonlinear least-square-error optimization problem;partially coherent illumination;partially coherent phase retrieval;phase field;programmable light-emitting diode dome;second-order optimization approach;source distribution;source recovery;Computational modeling;Convolution;Lighting;Mathematical model;Microscopy;Optimization;Image reconstruction;phase retrieval},
}

@Article{Ravishankar2016p294-309,
  author   = {S. Ravishankar and Y. Bresler},
  title    = {Data-Driven Learning of a Union of Sparsifying Transforms Model for Blind Compressed Sensing},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {294-309},
  month    = {Sept},
  issn     = {2333-9403},
  abstract = {Compressed sensing is a powerful tool in applications such as magnetic resonance imaging (MRI). It enables accurate recovery of images from highly undersampled measurements by exploiting the sparsity of the images or image patches in a transform domain or dictionary. In this work, we focus on blind compressed sensing (BCS), where the underlying sparse signal model is a priori unknown, and propose a framework to simultaneously reconstruct the underlying image as well as the unknown model from highly undersampled measurements. Specifically, our model is that the patches of the underlying image(s) are approximately sparse in a transform domain. We also extend this model to a union of transforms model that better captures the diversity of features in natural images. The proposed block coordinate descent type algorithms for BCS are highly efficient, and are guaranteed to converge to at least the partial global and partial local minimizers of the highly nonconvex BCS problems. Our numerical experiments show that the proposed framework usually leads to better quality of image reconstructions in MRI compared to several recent image reconstruction methods. Importantly, the learning of a union of sparsifying transforms leads to better image reconstructions than a single adaptive transform.},
  doi      = {10.1109/TCI.2016.2567299},
  keywords = {compressed sensing;image coding;image reconstruction;learning (artificial intelligence);minimisation;transforms;MRI;blind compressed sensing;block coordinate descent type algorithms;data-driven learning;image patches;image reconstruction methods;image recovery;image sparsity;magnetic resonance imaging;nonconvex BCS problems;partial global minimizers;partial local minimizers;sparse signal model;sparsifying transform model;Compressed sensing;Convergence;Dictionaries;Image reconstruction;Magnetic resonance imaging;Transforms;Compressed sensing;dictionary learning;inverse problems;machine learning;magnetic resonance imaging;medical imaging;sparse representations;sparsifying transforms},
}

@Article{Zisler2016p335-347,
  author   = {M. Zisler and J. H. Kappes and C. Schnörr and S. Petra and C. Schnörr},
  title    = {Non-Binary Discrete Tomography by Continuous Non-Convex Optimization},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {335-347},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2563321},
  keywords = {computerised tomography;image reconstruction;optimisation;continuous nonconvex optimization;continuous reconstruction method;discrete constraints;energy formulation;generalized forward-backward splitting algorithm;nonbinary discrete tomography;nonconvex coupling term;nonconvex functions;numerical evaluation;projection angles;standard test-datasets;total variation regularization;Couplings;Image reconstruction;Optimization;Programming;TV;Tomography;Discrete tomography;limited-angle tomography;non-binary;non-convex optimization;reconstruction;relaxation;total variation regularization},
}

@Article{Zhang2016p281-293,
  author   = {Y. Zhang and K. Hirakawa},
  title    = {Combining Inertial Measurements With Blind Image Deblurring Using Distance Transform},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {281-293},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2561701},
  keywords = {cameras;concave programming;image restoration;image sensors;motion estimation;object tracking;transforms;IMU data;IMU fidelity cost;blind image deblurring techniques;blur kernel recovery;blur kernels;camera motion tracking;distance transform;image data-based fidelity;image sensor data;image sensor measurements;inertial measurement unit data;nonconvex energy function;nonconvex energy minimization problem;sharp image recovery;Cameras;Image restoration;Image sensors;Kernel;Minimization;Transforms;Blind image deblurring;IMU fidelity;blur kernel estimation;convex optimization;distance transform;homography;sensor fusion;spatially varying blur},
}

@Article{Guicquero2016p190-203,
  author   = {W. Guicquero and A. Dupret and P. Vandergheynst},
  title    = {An Algorithm Architecture Co-Design for CMOS Compressive High Dynamic Range Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {190-203},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2557073},
  keywords = {CMOS integrated circuits;image sensors;integrated circuit design;CMOS compressive high dynamic range imaging;HDR reconstruction;algorithm architecture codesign;classical pixel design;compressive sensing;high dynamic range;image sensor design;image sensors;linear measurements;multicapture acquisitions;Computer architecture;Dynamic range;Image coding;Image reconstruction;Image sensors;Sensors;Compressed sensing;high dynamic range;image sensor},
}

@Article{Holloway2016p251-265,
  author   = {J. Holloway and M. S. Asif and M. K. Sharma and N. Matsuda and R. Horstmeyer and O. Cossairt and A. Veeraraghavan},
  title    = {Toward Long-Distance Subdiffraction Imaging Using Coherent Camera Arrays},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {251-265},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2557067},
  keywords = {Fourier transform optics;cameras;image reconstruction;image resolution;light diffraction;sensor arrays;coherent camera array;coherent illumination;high resolution detail recovery;image overlap;imaging system;long distance image;long-distance subdiffraction imaging;macroscopic Fourier ptychography image;objective lens diffraction limit;phase retrieval based reconstruction algorithm;reconstructed image quality;spatial resolution;synthetic aperture size;Apertures;Cameras;Diffraction;Image resolution;Lenses;Lighting;Phase retrieval;high-resolution imaging;ptychography;synthetic aperture imaging},
}

@Article{Schuetze2016p177-189,
  author   = {H. Schütze and E. Barth and T. Martinetz},
  title    = {Learning Efficient Data Representations With Orthogonal Sparse Coding},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {177-189},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2557065},
  keywords = {approximation theory;data compression;feature extraction;image coding;image denoising;image representation;learning (artificial intelligence);sparse matrices;stochastic processes;CA;Gram-Schmidt orthogonalizations;Hebbian-like updates;JPEG standard;OSC dictionaries;canonical approach;data compression;data representation learning;feature extraction;handwritten digit images;image compression;image denoising;image denoising performance;natural image patches;orthogonal basis;orthogonal sparse coding;rate-distortion performance improvement;signal class;sparse approximation problem;sparse representations;stochastic descent;synthetic data;Dictionaries;Encoding;Image coding;Imaging;Sparse matrices;Training data;Transforms;Blind source separation;Sparse coding;dictionary learning;image compression;image denoising;orthogonal mixture;sparse component analysis;sparse representation;transform coding},
}

@Article{Cordero-Grande2016p266-280,
  author   = {L. Cordero-Grande and R. P. A. G. Teixeira and E. J. Hughes and J. Hutter and A. N. Price and J. V. Hajnal},
  title    = {Sensitivity Encoding for Aligned Multishot Magnetic Resonance Reconstruction},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {266-280},
  month    = {Sept},
  doi      = {10.1109/TCI.2016.2557069},
  keywords = {biomedical MRI;entropy;image reconstruction;image sampling;medical image processing;motion estimation;pose estimation;aligned multishot magnetic resonance reconstruction;gradient entropy based metrics;imaged object position estimation;motion estimation;motion-free image;motion-recovered reconstruction;multiple receiver coils;neonates;partial k-space information;prior information availability;resampling;sensitivity encoding;shot number;sparsity;trajectory encoding;volumetric brain imaging;Coils;Discrete Fourier transforms;Image reconstruction;Imaging;Motion estimation;Proposals;Trajectory;Image reconstruction;magnetic resonance;motion correction;multishot acquisition;parallel imaging},
}

@Article{Pragier2016p323-334,
  author   = {G. Pragier and I. Greenberg and X. Cheng and Y. Shkolnisky},
  title    = {A Graph Partitioning Approach to Simultaneous Angular Reconstitution},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {3},
  pages    = {323-334},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2557076},
  keywords = {graph theory;image reconstruction;common-lines-based method;cryo-electron microscopy;graph partitioning approach;handedness assignment problem;imaging orientation estimation;noisy two-dimensional projection-images;simultaneous angular reconstitution;single particle reconstruction;three-dimensional model;two-way handedness ambiguity;Casting;Eigenvalues and eigenfunctions;Image reconstruction;Microscopy;Noise measurement;Robustness;Angular reconstitution;cryo-electron microscopy;graph partitioning;line graph;synchronization;tomography},
}

@Article{Sun2016p101-108,
  author   = {H. Sun and S. Pistorius},
  title    = {A Geometric Model to Characterize Annihilation Positions Associated With Scattered Coincidences in PET: A Simulation-Based Study},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {2},
  pages    = {101-108},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2549742},
  keywords = {Monte Carlo methods;image reconstruction;medical image processing;positron emission tomography;scattering;statistical distributions;Monte-Carlo simulation;PET images;TCA;actual activity distribution;annihilation position;electron density;high energy resolution detectors;image reconstruction;nonideal detector energy resolution;normalized coordinate system;positron emission tomography;single scattered coincidences;two-circular arcs;Detectors;Energy resolution;Image reconstruction;Phantoms;Photonics;Positron emission tomography;Scattering;Geometric model;PET;Scattering reconstruction;scattering reconstruction},
}

@Article{Kappeler2016p109-122,
  author   = {A. Kappeler and S. Yoo and Q. Dai and A. K. Katsaggelos},
  title    = {Video Super-Resolution With Convolutional Neural Networks},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {2},
  pages    = {109-122},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2532323},
  keywords = {image resolution;image restoration;motion compensation;neural nets;video databases;video signal processing;CNN architecture;DNN;convolutional neural networks;deep neural networks;image SR;image databases;image restoration;image super-resolution;motion compensation;spatial video dimensions;super-resolved video frames;temporal video dimensions;video database;video restoration;video super-resolution;Computer architecture;Dictionaries;Image reconstruction;Neural networks;Spatial resolution;Training;Convolutional Neural Networks;Deep Learning;Deep Neural Networks;Video Super-Resolution},
}

@Article{Zhang2016p86-100,
  author   = {L. Zhang and W. Wei and Y. Zhang and H. Yan and F. Li and C. Tian},
  title    = {Locally Similar Sparsity-Based Hyperspectral Compressive Sensing Using Unmixing},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {2},
  pages    = {86-100},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2542002},
  keywords = {compressed sensing;geophysical image processing;hyperspectral imaging;inverse problems;matrix algebra;HSI compression;LSSHUCS method;abundance matrix;abundance vectors;augmented Lagrangian algorithm;gradient sparsity;hyperspectral image compression;inverse linear problem;linear unmixing-based compressive sensing;locally similar sparsity-based hyperspectral compressive sensing;redundant endmember library;sparse vectors;Compressed sensing;Hyperspectral imaging;Image coding;Image reconstruction;Imaging;Libraries;Locally similar sparsity;augmented Lagrangian algorithm;hyperspectral compressive sensing;linear unmixing},
}

@Article{Shao2016p123-135,
  author   = {F. Shao and W. Lin and G. Jiang and Q. Dai},
  title    = {Models of Monocular and Binocular Visual Perception in Quality Assessment of Stereoscopic Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {2},
  pages    = {123-135},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2538720},
  keywords = {image classification;quality of experience;stereo image processing;video signal processing;visual perception;3-D IQA databases;3-D image quality assessment databases;3-D video;QoE;binocular visual perception models;full-reference stereoscopic image quality metric;image classification;monocular energy responses;monocular visual perception models;quality-of-experience;stereoscopic image processing algorithms;three-dimensional video;Image quality;Measurement;Quality assessment;Stereo image processing;Three-dimensional displays;Visual perception;Visualization;Monocular visual perception;binocular visual perception;energy response;monocular visual perception;stereoscopic image quality assessment},
}

@Article{Ambartsoumian2016p166-173,
  author   = {G. Ambartsoumian and S. Roy},
  title    = {Numerical Inversion of a Broken Ray Transform Arising in Single Scattering Optical Tomography},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {2},
  pages    = {166-173},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2531581},
  keywords = {Fourier transforms;biomedical optical imaging;data acquisition;image reconstruction;medical image processing;optical tomography;piecewise linear techniques;singular value decomposition;BRT;Fourier coefficients;SSOT;V-line Radon;V-shaped piecewise linear trajectories;broken ray transform;circular geometry;data acquisition;half-rank truncated singular value decomposition method;ill-conditioned matrix problems;image function;image reconstruction algorithm;mathematical model;medical imaging;numerical algorithm;numerical inversion formula;photons;single scattering optical tomography;Biomedical optical imaging;Geometry;Optical imaging;Optical scattering;Transforms;Broken ray;V-line transform;optical imaging;optical imaging,;reconstruction algorithms;single scattering tomography;singular value decomposition},
}

@Article{Gu2016p150-165,
  author   = {R. Gu and A. Dogandžić},
  title    = {Blind X-Ray CT Image Reconstruction From Polychromatic Poisson Measurements},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {2},
  pages    = {150-165},
  month    = {June},
  doi      = {10.1109/TCI.2016.2523431},
  keywords = {Laplace equations;X-ray imaging;computerised tomography;convex programming;image reconstruction;integral equations;splines (mathematics);stochastic processes;B-splines;Kurdyka-Łojasiewicz property;L-BFGSB iteration;Laplace-integral equation;NPG step;Nesterovs proximal-gradient step;Poisson noise model;TV norm;basis functions;biconvex optimization problems;blind X-ray CT image reconstruction;block-coordinate descent algorithm;constrained minimization;convex total-variation norm;density-map image;gradient-map sparsity;limited-memory Broyden-Fletcher-Goldfarb-Shanno with box constraints;log-likelihood;mass-attenuation spectrum function;mass-attenuation spline coefficients;measurement-model parameterization;penalized NLL objective function;photon energy;polychromatic Poisson measurements;polychromatic computed tomography;signal-sparsity penalties;transform domain;Attenuation;Computed tomography;Energy measurement;Image reconstruction;Noise measurement;Photonics;X-ray imaging;X-ray CT;beam-hardening correction;statistical model-based iterative reconstruction (MBIR)},
}

@Article{Huang2016p136-149,
  author   = {C. Huang and K. Wang and R. W. Schoonover and L. V. Wang and M. A. Anastasio},
  title    = {Joint Reconstruction of Absorbed Optical Energy Density and Sound Speed Distributions in Photoacoustic Computed Tomography: A Numerical Investigation},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {2},
  pages    = {136-149},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2523427},
  keywords = {aberrations;acoustic tomography;image reconstruction;iterative methods;medical image processing;optical tomography;optimisation;photoacoustic effect;JR problem;PACT measurement data;SOS distribution induce aberrations;absorbed optical energy density;acoustic aberrations;bioimaging modality;conventional PACT image reconstruction method;image artifacts;image estimates;image quality;joint reconstruction problem;nonlinear iterative algorithm;optimization-based formulation;photoacoustic computed tomography;photoacoustic measurement data;photoacoustic wavefields;sound speed distributions;speed-of-sound;Biomedical measurement;Biomedical optical imaging;Image reconstruction;Nonlinear optics;Optical imaging;Optimization;Photoacoustic computed tomography;image reconstruction;optoacoustic tomography;ultrasound tomography},
}

@Article{Sanders2016p71-82,
  author   = {T. Sanders},
  title    = {Discrete Iterative Partial Segmentation Technique (DIPS) for Tomographic Reconstruction},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {1},
  pages    = {71-82},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2521340},
  keywords = {computerised tomography;image reconstruction;image segmentation;iterative methods;medical image processing;DIPS;discrete iterative partial segmentation technique;discrete tomography;sparsity model;tomographic images reconstruction;Data models;Image reconstruction;Image segmentation;Minimization;TV;Tomography;Image Reconstruction;Regularization;Tomography},
}

@Article{Zhao2016p1-12,
  author   = {Z. Zhao and Y. Shkolnisky and A. Singer},
  title    = {Fast Steerable Principal Component Analysis},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {1},
  pages    = {1-12},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2514700},
  keywords = {cryptography;electron microscopy;fast Fourier transforms;image denoising;principal component analysis;2D images;Fourier-Bessel basis;computational complexity;cryo-electron microscopy;nonuniform fast Fourier transform;steerable PCA;steerable principal component analysis;Algorithm design and analysis;Computational complexity;Fourier transforms;Microscopy;Noise reduction;Principal component analysis;Steerable PCA;denoising;group invariance;non-uniform FFT},
}

@Article{Kamilov2016p59-70,
  author   = {U. S. Kamilov and I. N. Papadopoulos and M. H. Shoreh and A. Goy and C. Vonesch and M. Unser and D. Psaltis},
  title    = {Optical Tomographic Image Reconstruction Based on Beam Propagation and Sparse Regularization},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {1},
  pages    = {59-70},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2519261},
  keywords = {computational complexity;gradient methods;image reconstruction;iterative methods;optical tomography;stochastic processes;beam propagation method;computationally prohibitive reconstruction algorithm;edge-preserving 3D TV regularizer;edge-preserving three-dimensional total variation regularizer;iterative imaging method;missing-data artifact mitigation;noise suppression;nonlinear forward model;optical tomographic image reconstruction;reconstructed image quality improvement;refractive index high-quality imaging;sparse regularization;sparsity-driven regularizer;stochastic proximal-gradient algorithm;time-reversal scheme;Image reconstruction;Optical imaging;Optical refraction;Optical variables control;Refractive index;Tomography;Optical phase tomography;beam propagation method;compressive sensing;optical phase tomography;sparse reconstruction;stochastic proximal-gradient;total variation regularization},
}

@Article{Koehler2016p42-58,
  author   = {T. Köhler and X. Huang and F. Schebesch and A. Aichert and A. Maier and J. Hornegger},
  title    = {Robust Multiframe Super-Resolution Employing Iteratively Re-Weighted Minimization},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {1},
  pages    = {42-58},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2016.2516909},
  keywords = {Bayes methods;Gaussian processes;image reconstruction;image resolution;iterative methods;minimisation;adaptive Bayesian modeling;edge preserving image reconstruction;high-resolution image reconstruction;image acquisition;iterative algorithm;iterative coarse-to-fine scheme;majorization-minimization algorithm;multiple low-resolution frame;reweighted minimization;robust multiframe superresolution;space variant noise;weighted Gaussian observation;weighted bilateral total variation;Image reconstruction;Imaging;Mathematical model;Optimization;Robustness;Spatial resolution;Super-resolution;automatic parameter selection;majorization–minimization;majorization-minimization;majorization¿¿¿minimization;sparse regularization},
}

@Article{Fuersattel2016p27-41,
  author   = {P. Fürsattel and S. Placht and M. Balda and C. Schaller and H. Hofmann and A. Maier and C. Riess},
  title    = {A Comparative Error Analysis of Current Time-of-Flight Sensors},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {1},
  pages    = {27-41},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2510506},
  keywords = {error analysis;image sensors;measurement errors;Microsoft Kinect V2;ToF cameras;characteristic measurement errors;comparative error analysis;correction methods;data processing algorithms;decision making;error characteristics;time-of-flight sensors;Cameras;Scattering;Sensor phenomena and characterization;Systematics;Time measurement;Computer Vision;Computer vision;Range Imaging;Time-of-Flight Cameras;range imaging;time-of-flight cameras},
}

@Article{Tian2016p13-26,
  author   = {J. Tian and W. Cui and X. G. Xia and S. L. Wu},
  title    = {Parameter Estimation of Ground Moving Targets Based on SKT-DLVT Processing},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2016},
  volume   = {2},
  number   = {1},
  pages    = {13-26},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2510499},
  keywords = {image motion analysis;object tracking;parameter estimation;transforms;Doppler Lv transform;SKT-DLVT processing;SNR;azimuth signal;ground moving target motion;image focusing;memory-limited processing system;parameter estimation algorithm;range cell migration;real-time processing system;segmented keystone transform;signal-to-noise ratio;smeared image;spectrum spread;velocity ambiguity;Azimuth;Doppler effect;Imaging;Parameter estimation;Radar imaging;Signal to noise ratio;Transforms;Doppler Lv’s transform (DLVT);Doppler Lv???s transform (DLVT);Ground moving target;ground moving target;parameter estimation;segmental keystone transform (SKT)},
}

@Article{Delbracio2015p270-283,
  author   = {M. Delbracio and G. Sapiro},
  title    = {Hand-Held Video Deblurring Via Efficient Fourier Aggregation},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {4},
  pages    = {270-283},
  month    = {Dec},
  doi      = {10.1109/TCI.2015.2501245},
  keywords = {Fourier transforms;video signal processing;Fourier aggregation;Fourier spectrum magnitude;camera shake removal;consistently registered video frames;handheld cameras;handheld video deblurring;multiple moving objects;temporally adjacent video frames;Cameras;Deconvolution;Handheld computers;Heuristic algorithms;Image restoration;Fourier accumulation;Video deblurring;camera shake},
}

@Article{Weller2015p247-258,
  author   = {D. S. Weller and A. Pnueli and G. Divon and O. Radzyner and Y. C. Eldar and J. A. Fessler},
  title    = {Undersampled Phase Retrieval With Outliers},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {4},
  pages    = {247-258},
  month    = {Dec},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2498402},
  keywords = {Monte Carlo methods;convex programming;image reconstruction;image retrieval;image sampling;iterative methods;minimisation;1D Monte Carlo tests;2D image reconstruction simulations;ADMM penalty parameter;adaptive heuristic;additive noise;alternating direction method of multipliers;convex majorizer;initial majorization vectors;iterative optimization;layered approach;nonconvex objective function;normalization scheme;outliers;reconstruction error;regularization parameter;repeated minimization;robust 1-norm data fit term;sparse image reconstruction;undersampled phase retrieval;Discrete Fourier transforms;Image reconstruction;Monte Carlo methods;Noise measurement;Robustness;Sparse matrices;Phase retrieval;alternating direction method of multipliers;majorize-minimize;phase retrieval;sparsity},
}

@Article{Matsunaga2015p259-269,
  author   = {S. Matsunaga and S. K. Nayar},
  title    = {Field Curvature Correction Using Focal Sweep},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {4},
  pages    = {259-269},
  month    = {Dec},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2491181},
  keywords = {cameras;image sensors;lenses;camera optics design;field curvature correction;focal stack;focal sweep;image sensor;imaging resolution;imaging system;lens;Adaptive optics;Image resolution;Image sensors;Lenses;Optical imaging;Optical sensors;Depth of field;Imaging optics;and computational imaging;computational imaging;depth of field;field curvature;focal sweep;imaging optics;programmable pixel exposure},
}

@Article{Bahmani2015p236-246,
  author   = {S. Bahmani and J. Romberg},
  title    = {Compressive Deconvolution in Random Mask Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {4},
  pages    = {236-246},
  month    = {Dec},
  doi      = {10.1109/TCI.2015.2485941},
  keywords = {convolution;deconvolution;image reconstruction;image sampling;matrix algebra;probability;random processes;blurring kernel;compressive deconvolution;measurement matrix;probability;random mask imaging;scene image reconstruction;scene image sparsity;signal reconstruction;sparse recovery algorithms;spatial phase modulation;spatial subsampling;subsampled convolution;Convolution;Deconvolution;Image reconstruction;Lenses;Modulation;Sparse matrices;Coded mask imaging;compressive sensing;deconvolution;property;restricted isometry;sparse recovery},
}

@Article{Ahmad2015p220-235,
  author   = {R. Ahmad and P. Schniter},
  title    = {Iteratively Reweighted $ell_1$ Approaches to Sparse Composite Regularization},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {4},
  pages    = {220-235},
  month    = {Dec},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2485078},
  keywords = {approximation theory;belief networks;concave programming;expectation-maximisation algorithm;image representation;inference mechanisms;Bayesian MAP inference;VEM;approximate Bo-type penalty;composite regularizers;iteratively reweighted ℓ1 approach;lasso algorithm;majorization-minimization;multiple dictionaries;nonconvex log-sum-type penalty;sparse composite regularization;sparse representations;variational expectation maximization;AWGN;Approximation algorithms;Bayes methods;Convergence;Image reconstruction;Inference algorithms;Optimization;Bayesian methods;composite regularization;iterative reweighting algorithms;majorization minimization;sparse optimization;variational inference},
}

@Article{Altmann2015p174-185,
  author   = {Y. Altmann and M. Pereyra and S. McLaughlin},
  title    = {Bayesian Nonlinear Hyperspectral Unmixing With Spatial Residual Component Analysis},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {3},
  pages    = {174-185},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2481603},
  keywords = {Bayes methods;Gaussian noise;Markov processes;Monte Carlo methods;hyperspectral imaging;image colour analysis;maximum likelihood estimation;optimisation;Bayesian inference;Bayesian nonlinear hyperspectral unmixing;adaptive Markov chain Monte Carlo algorithm;additive Gaussian noise;gamma Markov random field;hyperspectral image;maximum marginal likelihood estimation;spatial residual component analysis;stochastic optimisation adaptation mechanism;Bayes methods;Computational modeling;Estimation;Hyperspectral imaging;Joints;Licenses;Markov processes;Bayesian estimation;Gamma Markov random field;Hyperspectral imagery;nonlinear spectral unmixing;residual component analysis},
}

@Article{John2015p159-173,
  author   = {V. John and K. Yoneda and Z. Liu and S. Mita},
  title    = {Saliency Map Generation by the Convolutional Neural Network for Real-Time Traffic Light Detection Using Template Matching},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {3},
  pages    = {159-173},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2480006},
  keywords = {image colour analysis;image denoising;image matching;lighting;neural nets;object detection;road traffic;traffic engineering computing;ADAS;Global Positioning System;M-DBSCAN algorithm;advanced driver assistance systems;autonomous vehicle navigation;colour information;computer vision;convolutional neural network;illumination condition;image processing;learning algorithms;multidimensional density-based spatial clustering of applications with noise algorithm;realtime traffic light detection;region-of-interest identification;saliency map generation;template matching;vehicle GPS information;vision-based sensors;Accuracy;Clustering algorithms;Image color analysis;Imaging;Lighting;Real-time systems;Vehicles;Convolutional Neural Network;DBSCAN;Saliency Maps;Traffic Light Detection},
}

@Article{McGaffin2015p186-199,
  author   = {M. G. McGaffin and J. A. Fessler},
  title    = {Alternating Dual Updates Algorithm for X-ray CT Reconstruction on the GPU},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {3},
  pages    = {186-199},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2479555},
  keywords = {computerised tomography;graphics processing units;image reconstruction;medical image processing;optimisation;statistical analysis;GPU;MBIR;X-ray CT reconstruction;X-ray computed tomography;alternating dual updates algorithm;image quality;model-based image reconstruction;statistically motivated optimization problem;Approximation algorithms;Computed tomography;Cost function;Graphics processing units;Image reconstruction;X-ray imaging;Graphics processing units;X-ray CT image reconstruction;stochastic dual coordinate ascent},
}

@Article{Vila2015p143-158,
  author   = {J. Vila and P. Schniter and J. Meola},
  title    = {Hyperspectral Unmixing Via Turbo Bilinear Approximate Message Passing},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {3},
  pages    = {143-158},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2465161},
  keywords = {approximation theory;belief networks;expectation-maximisation algorithm;graph theory;hyperspectral imaging;image processing;message passing;BP;BiG-AMP;EM strategy;belief-propagation-based approach;bilinear generalized approximate message passing algorithm;bilinear subgraphs;electromagnetic spectral dataset;endmembers;expectation-maximization strategy;factor graph;hyperspectral unmixing;image pixels;loopy belief propagation;material spectra;matrix factorization;model-order selection strategy;real-world data;spatial abundances;spatial coherence;spectral bands;spectral coherence;synthetic data;turbo approach;turbo bilinear approximate message passing;Approximation methods;Coherence;Computational modeling;Hyperspectral imaging;Manganese;Message passing;Spatial coherence;Approximate message passing;approximate message passing;belief propagation;expectation-maximization algorithms;hyperspectral imaging},
}

@Article{Achim2015p86-95,
  author   = {A. Achim and A. Basarab and G. Tzagkarakis and P. Tsakalides and D. Kouamé},
  title    = {Reconstruction of Ultrasound RF Echoes Modeled as Stable Random Variables},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {2},
  pages    = {86-95},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2463257},
  keywords = {Monte Carlo methods;biomedical ultrasonics;image reconstruction;medical image processing;minimisation;ℓp minimization approach;Fourier domain;IRLS algorithm;Monte Carlo simulations;alpha-stable distributions;biomedical ultrasound images;iteratively reweighted least squares algorithm;simulated compressive measurements;stable random variables;ultrasound RF echoes;Frequency-domain analysis;Image coding;Image reconstruction;Imaging;Minimization;Radio frequency;Ultrasonic imaging;$ell_p$ minimization;ℓp minimization;Medical ultrasound;alpha-stable distributions;compressive sampling;image reconstruction},
}

@Article{Jin2015p200-216,
  author   = {P. Jin and C. A. Bouman and K. D. Sauer},
  title    = {A Model-Based Image Reconstruction Algorithm With Simultaneous Beam Hardening Correction for X-Ray CT},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {3},
  pages    = {200-216},
  month    = {Sept},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2461492},
  keywords = {computerised tomography;image reconstruction;image segmentation;iterative methods;medical image processing;minimisation;MBIR-BHC algorithm;X-ray CT scanning;alternating minimization algorithm;beam hardening correction;component polynomial;cupping;energy-dependent material attenuation;iterative algorithm;low-density material;mass attenuation functions;material projections:;material segmentation;model-based image reconstruction algorithm;poly-energetic forward model;polynomial function;sinogram precorrection techniques;spectrum functions;streaking;Attenuation;Computed tomography;Image reconstruction;Image segmentation;Polynomials;X-ray imaging;X-ray CT;beam hardening correction;model-based iterative reconstruction (MBIR);poly-energetic},
}

@Article{Altmann2015p74-85,
  author   = {Y. Altmann and S. McLaughlin and A. Hero},
  title    = {Robust Linear Spectral Unmixing Using Anomaly Detection},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {2},
  pages    = {74-85},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2455411},
  keywords = {Markov processes;hyperspectral imaging;image classification;white noise;Bayesian algorithm;Markov random field;additive Gaussian noise;anomaly detection algorithm;hyperspectral images;linear spectral unmixing;nonlinear term modeling anomalies;outlier detection;Bayes methods;Computational modeling;Estimation;Joints;Licenses;Noise;Robustness;Bayesian estimation;Hyperspectral imagery;MCMC;anomaly detection;unsupervised spectral unmixing},
}

@Article{Nava2015p126-139,
  author   = {G. Pablo Nava and H. Duy Nguyen and Y. Kamamoto and T. G. Sato and Y. Shiraki and N. Harada and T. Moriya},
  title    = {A High-Speed Camera-Based Approach to Massive Sound Sensing With Optical Wireless Acoustic Sensors},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {2},
  pages    = {126-139},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2454995},
  keywords = {audio systems;graphics processing units;light emitting diodes;light transmission;microphone arrays;numerical analysis;optical sensors;video cameras;wireless sensor networks;LED;RF wireless microphone array;acoustic imaging;audio channel;audio signal processing;beamforming;camera interface hardware;high-speed video camera-based approach;image processing;numerical analysis;optical signal decoding;optical wireless acoustic sensor;optical wireless audio system;parallel transmission;single GPU card;sound sensor;wired microphone array;High-speed optical techniques;Light emitting diodes;Optical imaging;Optical sensors;Sensor arrays;Wireless sensor networks;High speed camera;acoustic imaging;beamforming;free space optical communication;high speed camera;microphone arrays;parallel processing;wireless sensor networks},
}

@Article{Shin2015p112-125,
  author   = {D. Shin and A. Kirmani and V. K. Goyal and J. H. Shapiro},
  title    = {Photon-Efficient Computational 3-D and Reflectivity Imaging With Single-Photon Detectors},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {2},
  pages    = {112-125},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2453093},
  keywords = {avalanche photodiodes;image filtering;image processing;low-power electronics;photodetectors;reflectivity;stochastic processes;3D filtering;Poisson noise;block-matching;low-power active optical imaging;median filtering;noise-tolerant active optical imaging;photon-efficient computational 3D imaging;reflectivity imaging;signal-independent noise removal algorithms;single-photon detectors;Detectors;Lighting;Noise;Optical imaging;Photonics;Three-dimensional displays;3-D imaging;3D imaging;LIDAR;Poisson noise;computational imaging;convex optimization;first-photon imaging;low-light imaging;single-photon detection;time-of-flight imaging},
}

@Article{Gregor2015p44-55,
  author   = {J. Gregor and J. A. Fessler},
  title    = {Comparison of SIRT and SQS for Regularized Weighted Least Squares Image Reconstruction},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {1},
  pages    = {44-55},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2442511},
  keywords = {computerised tomography;gradient methods;image reconstruction;iterative methods;least squares approximations;medical image processing;RWLS problem;SIRT;SQS;aviation security;conjugate gradient;eigenvalue bounds;gradient descent;iterative algorithms;near optimal relaxation;regularized weighted least squares image reconstruction;separable quadratic surrogates;simultaneous iterative reconstruction technique;statistical point;tomographic image reconstruction;Computed tomography;Convergence;Eigenvalues and eigenfunctions;Image reconstruction;Three-dimensional displays;Upper bound;Algebraic reconstruction;X-ray CT;preconditioned gradient descent;regularization;relaxation;weighted least squares},
}

@Article{Duman2015p30-43,
  author   = {K. Duman and B. Yazıcı},
  title    = {Moving Target Artifacts in Bistatic Synthetic Aperture Radar Images},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {1},
  pages    = {30-43},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2440995},
  keywords = {computational geometry;motion estimation;parameter estimation;radar imaging;synthetic aperture radar;SAR image reconstruction;arbitrary antenna trajectories;arbitrary imaging geometries;bistatic SAR imagery;bistatic configurations;bistatic synthetic aperture radar imaging methods;form focused bistatic SAR images;moving target artifacts;moving target signature extraction;nonflat topography;parametric equations;positioning error prediction;predictive equations;target motion parameter estimation;target velocities;Apertures;Geometry;Image reconstruction;Imaging;Receivers;Synthetic aperture radar;Transmitters;Bistatic synthetic aperture radar (SAR);moving target imaging;moving target morphology;positioning errors due to moving targets},
}

@Article{Lefkimmiatis2015p16-29,
  author   = {S. Lefkimmiatis and S. Osher},
  title    = {Nonlocal Structure Tensor Functionals for Image Regularization},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {1},
  pages    = {16-29},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2434616},
  keywords = {convex programming;gradient methods;image processing;minimisation;tensors;alternating-direction methods;augmented Lagrangian formulation;convex optimization;graph gradient;image location;inverse imaging problems;local structural image regularity;minimization algorithm;natural images;nonlocal energy functionals;nonlocal image self-similarity;nonlocal regularization methods;nonlocal structure tensor functionals;splitting variable strategy;standard image gradient;Eigenvalues and eigenfunctions;Image edge detection;Image reconstruction;Imaging;Standards;TV;Tensile stress;Image reconstruction;convex optimization;non-local regularization;nonlocal regularization;structure tensor;total variation},
}

@Article{Mohan2015p96-111,
  author   = {K. Aditya Mohan and S. V. Venkatakrishnan and J. W. Gibbs and E. B. Gulsoy and X. Xiao and M. De Graef and P. W. Voorhees and C. A. Bouman},
  title    = {TIMBIR: A Method for Time-Space Reconstruction From Interlaced Views},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {2},
  pages    = {96-111},
  month    = {June},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2431913},
  keywords = {computerised tomography;data acquisition;image reconstruction;image resolution;image sampling;iterative methods;statistical analysis;synchrotrons;3D volume image reconstruction;4D image reconstruction method;SXCT;TIMBIR method;data acquisition;ring artifact;sensor noise statistics;streak artifact;synchrotron X-ray computed tomography;temporal image resolution;time-interlaced model-based iterative reconstruction method;time-resolved volumetric reconstruction;Cost function;Data acquisition;Image reconstruction;Photonics;Reconstruction algorithms;Three-dimensional displays;4D reconstruction;Compressed sensing;MBIR;X-ray computed tomography;interlaced views;optimization;ring artifacts;streak artifacts;synchrotron;time-space imaging;zingers},
}

@Article{Qasaimeh2015p56-70,
  author   = {M. Qasaimeh and A. Sagahyroon and T. Shanableh},
  title    = {FPGA-Based Parallel Hardware Architecture for Real-Time Image Classification},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {1},
  pages    = {56-70},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2015.2424077},
  keywords = {feature extraction;field programmable gate arrays;image classification;parallel architectures;support vector machines;transforms;Belgium traffic sign datasets;BoF algorithm;Caltech-256 datasets;FPGA-based parallel hardware architecture;SIFT algorithm;SVM algorithms;bag of features algorithm;feature extraction algorithm;hardware resource utilization;real-time image classification;scale-invariant feature transform;support vector machine algorithms;Acceleration;Accuracy;Classification algorithms;Computer architecture;Feature extraction;Hardware;Support vector machines;Field-programmable gate array (FPGA);Image classification;Scale Invariant Feature Transform;field-programmable gate array;hardware implementation;image classification;scale-invariant feature transform (SIFT)},
}

@Article{Venkatakrishnan2015p1-15,
  author   = {S. V. Venkatakrishnan and L. F. Drummy and M. Jackson and M. De Graef and J. Simmons and C. A. Bouman},
  title    = {Model-Based Iterative Reconstruction for Bright-Field Electron Tomography},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2015},
  volume   = {1},
  number   = {1},
  pages    = {1-15},
  month    = {March},
  issn     = {2333-9403},
  doi      = {10.1109/TCI.2014.2371751},
  keywords = {data acquisition;electron microscopy;image reconstruction;iterative methods;minimisation;tomography;3D BF-ET imaging;Bragg scatter;acquisition system;biological specimens;bright-field electron tomography;crystalline materials;dynamical diffraction;filtered back-projection;majorization-minimization;model-based iterative reconstruction;single cost function;Attenuation;Cost function;Image reconstruction;Materials;Three-dimensional displays;Tomography;Vectors;Model-based reconstruction;bright-field;electron microscopy;tomography},
}

@Article{Freeman2017p382-383,
  author   = {W. T. Freeman and A. Savakis and Y. Schechner and N. Snavely and W. Heidrich},
  title    = {Guest Editorial Special Issue on Extreme Imaging},
  journal  = {IEEE Transactions on Computational Imaging},
  year     = {2017},
  volume   = {3},
  number   = {3},
  pages    = {382-383},
  month    = {Sept},
  doi      = {10.1109/TCI.2017.2726838},
  keywords = {Image processing;Image resolution;Meetings;Photonics;Signal resolution;Special issues and sections;Visualization},
}

@Article{Chen2018p33399-33409,
  author   = {S. Chen and T. Xu and J. Zhang and X. Wang and Y. Zhang},
  title    = {Random Positional Deviations Correction for Each LED via ePIE in Fourier Ptychographic Microscopy},
  journal  = {IEEE Access},
  year     = {2018},
  volume   = {6},
  pages    = {33399-33409},
  doi      = {10.1109/ACCESS.2018.2849010},
  keywords = {Convergence;Image reconstruction;Lenses;Light emitting diodes;Lighting;Microscopy;Computational imaging;imaging system;microscopy;phase retrieval},
}

@Article{Zhao2018p1-16,
  author   = {S. B. Zhao and M. Y. Ma and C. Guo},
  title    = {Accurate Pixel-to-Pixel Alignment Method With Six-Axis Adjustment for Computational Photography},
  journal  = {IEEE Photonics Journal},
  year     = {2018},
  volume   = {10},
  number   = {3},
  pages    = {1-16},
  month    = {June},
  doi      = {10.1109/JPHOT.2018.2839093},
  keywords = {computer vision;diffraction gratings;digital photography;image resolution;image sensors;moire fringes;spatial light modulators;accuracy pixel-to-pixel alignment method;accurate pixel-to-pixel alignment method;alignment accuracy;computational imaging applications;computational photography;five-grating pattern;four-step alignment procedure;freedom displacements;moiré fringe distribution;pixel-to-pixel correspondence adjustment;six degree-of-freedom displacements;six-axis adjustment;spatial light modulator;Computer architecture;Gratings;Optical imaging;Optical sensors;Photography;Alignment;Fourier optics and signal processing.;computational imaging;moiré techniques},
}

@Article{Yurduseven2018p14884-14894,
  author   = {O. Yurduseven and T. Fromenteze and D. R. Smith},
  title    = {Relaxation of Alignment Errors and Phase Calibration in Computational Frequency-Diverse Imaging using Phase Retrieval},
  journal  = {IEEE Access},
  year     = {2018},
  volume   = {6},
  pages    = {14884-14894},
  doi      = {10.1109/ACCESS.2018.2816341},
  keywords = {calibration;image reconstruction;image retrieval;light polarisation;microwave imaging;alignment errors;complex metal structures;complex-based images;complex-based reconstructions;composite imaging system;computational frequency;distinguishable images;frequency 17.5 GHz to 26.5 GHz;frequency-diverse computational imaging systems;frequency-diverse imaging system;heavily corrupted images;image reconstruction;microwave frequencies;phase calibration error;phase retrieval techniques;phaseless imaging technique;significant phase errors;system calibration;unwanted phase shifts;Antenna measurements;Antennas;Calibration;Frequency measurement;Image reconstruction;Imaging;Phase measurement;Microwaves;calibration;coherent imaging;computational imaging;frequency-diversity;imaging;phase coherence;phase retrieval;phaseless imaging},
}

@Article{Tang2018p1-9,
  author   = {J. Tang and Y. Tang and K. He and L. Lu and D. Zhang and M. Cheng and L. Deng and D. Liu and M. Zhang},
  title    = {Computational Temporal Ghost Imaging Using Intensity-Only Detection Over a Single Optical Fiber},
  journal  = {IEEE Photonics Journal},
  year     = {2018},
  volume   = {10},
  number   = {2},
  pages    = {1-9},
  month    = {April},
  doi      = {10.1109/JPHOT.2018.2815713},
  keywords = {Fourier transform optics;image resolution;light coherence;light sources;optical correlation;optical fibre dispersion;transfer functions;coherent detection;computational temporal ghost imaging;distorted ghost image;distorted image;fiber dispersion;high-quality image;image quality;light source bandwidth;optical fiber;optical intensity detection;optical spectrum;power density spectrum;temporal ghost imaging system;Correlation;Light sources;Optical fiber dispersion;Optical fibers;Optical imaging;Ghost imaging;computational imaging;fiber optics imaging},
}
{He2017p1-10,
  author        = {R. He and W. Zhang and B. Sun and M. A. Olvera and Z. Lin and Q. Chen},
  title         = {Analysis of the } # 8216;Anti-scattering #{8217; Capacity of Computational Ghost Imaging System in Solid Scattering Material},
  journal       = {IEEE Photonics Journal},
  year          = {2017},
  volume        = {9},
  number        = {6},
  pages         = {1-10},
  month         = {Dec},
  __markedentry = {[junhu:]},
  doi           = {10.1109/JPHOT.2017.2773470},
  keywords      = {image reconstruction;image resolution;light scattering;quantum optics;DPSF;Huygens-Fresnel theory;TGI;antiscattering capacity;blurry effect;computational ghost imaging system;computer-generated patterns;d-based pixel-grids;discrete point-scattering-function;image reconstruction;light source;point scattering function;pseudothermal light;scattered light distribution;solid scattering material;spatial resolution power;traditional ghost imaging;Detectors;Image reconstruction;Imaging;Media;Scattering;Solids;Ultraviolet sources;Computational imaging;Imaging systems;Multiple scattering.},
}

@Article{Martinez-Corral2017p825-836,
  author   = {M. Martínez-Corral and A. Dorado and J. C. Barreiro and G. Saavedra and B. Javidi},
  title    = {Recent Advances in the Capture and Display of Macroscopic and Microscopic 3-D Scenes by Integral Imaging},
  journal  = {Proceedings of the IEEE},
  year     = {2017},
  volume   = {105},
  number   = {5},
  pages    = {825-836},
  month    = {May},
  issn     = {0018-9219},
  doi      = {10.1109/JPROC.2017.2655260},
  keywords = {image capture;image resolution;stereo image processing;three-dimensional displays;3D display;InI technique;bioimaging;depth of field;entertainment industry;image resolution;industrial procedure;integral imaging;light ray spatial-angular information;macroscopic 3D scene capture;macroscopic 3D scene display;microscopic 3D scene capture;microscopic 3D scene display;military and surveillance;polychromatic illumination;scattering medium;Cameras;Computational imaging;IP networks;Image processing;Lenses;Microoptics;Microscopy;Three-dimensional displays;Computational imaging;image processing;three-dimensional imaging;three-dimensional microscopy},
}

@Article{Wu2016p1-9,
  author   = {H. Wu and X. Zhang and J. Gan and C. Luo},
  title    = {High-Quality Computational Ghost Imaging Using an Optimum Distance Search Method},
  journal  = {IEEE Photonics Journal},
  year     = {2016},
  volume   = {8},
  number   = {6},
  pages    = {1-9},
  month    = {Dec},
  issn     = {1943-0655},
  doi      = {10.1109/JPHOT.2016.2633867},
  keywords = {compressed sensing;image enhancement;image reconstruction;mean square error methods;CGI;RMSE;SNR;compressive sensing;computational ghost imaging;optimum distance search;relative mean square error;signal-to-noise ratio;Charge coupled devices;Detectors;Image reconstruction;Imaging;Laser beams;Measurement by laser beam;Signal to noise ratio;Ghost imaging;compressive sensing;computational imaging;image reconstruction techniques},
}

@Article{Wang2017p2357-2364,
  author   = {Y. Wang and Y. Liu and W. Heidrich and Q. Dai},
  title    = {The Light Field Attachment: Turning a DSLR into a Light Field Camera Using a Low Budget Camera Ring},
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  year     = {2017},
  volume   = {23},
  number   = {10},
  pages    = {2357-2364},
  month    = {Oct},
  issn     = {1077-2626},
  doi      = {10.1109/TVCG.2016.2628743},
  keywords = {image capture;image resolution;iterative methods;photographic lenses;rendering (computer graphics);algorithmic point of view;central high-quality SLR lens;high-quality 2D image mode;high-quality rendering;high-resolution light fields;iPADS;image quality;iterative patch-and depth-based synthesis;light field attachment;light field camera;light field super-resolution method;low budget camera ring;low-quality side cameras;low-resolution cameras;real captured data;side-view images;spatial resolution;standard DSLR camera;synthetic data;view-coherent rendering;Cameras;Lenses;Prototypes;Spatial resolution;Tablet computers;Light field;computational imaging;super-resolution},
}

@Article{Davis*2017p732-745,
  author   = {A. Davis* and K. L. Bouman* and J. G. Chen and M. Rubinstein and O. Büyüköztürk and F. Durand and W. T. Freeman},
  title    = {Visual Vibrometry: Estimating Material Properties from Small Motions in Video},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2017},
  volume   = {39},
  number   = {4},
  pages    = {732-745},
  month    = {April},
  issn     = {0162-8828},
  doi      = {10.1109/TPAMI.2016.2622271},
  keywords = {computer vision;image motion analysis;materials science computing;video signal processing;computer vision;object material property estimation;regular frame rate video;structural engineering;structure properties;vibrating object video;vibration mechanics;visual vibrometry;Damping;Estimation;Fabrics;Geometry;Material properties;Measurement by laser beam;Vibrations;Material properties;computational imaging;computational photography;small motion;vibration},
}

@Article{Yurduseven2016p5436-5451,
  author   = {O. Yurduseven and J. N. Gollub and A. Rose and D. L. Marks and D. R. Smith},
  title    = {Design and Simulation of a Frequency-Diverse Aperture for Imaging of Human-Scale Targets},
  journal  = {IEEE Access},
  year     = {2016},
  volume   = {4},
  pages    = {5436-5451},
  doi      = {10.1109/ACCESS.2016.2604823},
  keywords = {image coding;image reconstruction;image sampling;image sensors;microwave imaging;stereolithography;all-electronic operation;computational imaging scheme;frequency-diverse aperture design;frequency-diverse imager;human-scale target imaging;mechanical scanning;optimization;radiation pattern;security-screening application;stereolithography format;synthetic aperture radar approach;Adaptation modeling;Apertures;Computational modeling;Frequency Diversity;Imaging;Synthetic aperture radar;Frequency-diversity;aperture;computational imaging;microwave imaging;microwaves;simulation},
}

@Article{Jain2016p649-657,
  author   = {R. Jain and J. Grzyb and U. R. Pfeiffer},
  title    = {Terahertz Light-Field Imaging},
  journal  = {IEEE Transactions on Terahertz Science and Technology},
  year     = {2016},
  volume   = {6},
  number   = {5},
  pages    = {649-657},
  month    = {Sept},
  issn     = {2156-342X},
  doi      = {10.1109/TTHZ.2016.2584861},
  keywords = {terahertz wave imaging;CMOS camera;radiation pattern;silicon hyper-hemispherical lens;terahertz light-field imaging;Apertures;Cameras;Detectors;Interpolation;Lenses;Optical imaging;Computational imaging;light-field;plenoptics;radiation pattern;silicon lens;terahertz (THz);transmission-mode imaging, rank3},
}

@Article{Yurduseven2016p367-369,
  author   = {O. Yurduseven and V. R. Gowda and J. N. Gollub and D. R. Smith},
  title    = {Printed Aperiodic Cavity for Computational and Microwave Imaging},
  journal  = {IEEE Microwave and Wireless Components Letters},
  year     = {2016},
  volume   = {26},
  number   = {5},
  pages    = {367-369},
  month    = {May},
  issn     = {1531-1309},
  doi      = {10.1109/LMWC.2016.2548443},
  keywords = {image coding;image reconstruction;microwave imaging;microwave metamaterials;printed circuits;Fibonacci pattern;K-band frequency;computational imaging;double-sided printed circuit board;frequency 18 GHz to 26.5 GHz;frequency-diverse aperture;image reconstruction;imaged scene information encoding;metamaterial apertures;microwave imaging;phase-diverse system;printed aperiodic cavity;printed cavity imager;quality factor;radiating circular irises array;spatial diversity;Apertures;Cavity resonators;Frequency measurement;Microwave imaging;Q-factor;Radar imaging;Computational imaging;Fibonacci;microwave cavity;microwave imaging;printed cavity},
}

@Article{Chen2016p1-9,
  author   = {W. Chen},
  title    = {Single-Shot Imaging Without Reference Wave Using Binary Intensity Pattern for Optically-Secured-Based Correlation},
  journal  = {IEEE Photonics Journal},
  year     = {2016},
  volume   = {8},
  number   = {1},
  pages    = {1-9},
  month    = {Feb},
  issn     = {1943-0655},
  doi      = {10.1109/JPHOT.2016.2523245},
  keywords = {decoding;image coding;iterative methods;optical correlation;optical images;1-bit intensity pattern;DRPE;binary intensity pattern;double random phase encoding;image decoding;iterative phase retrieval algorithm;optical correlation;optical imaging;optical verification;optically-secured-based correlation;recorded intensity pattern;single-shot imaging;Correlation;Encoding;Iterative decoding;Nonlinear optics;Optical diffraction;Optical imaging;Optical receivers;Single-pixel imaging;binary intensity pattern;computational imaging;optical correlation},
}

@Article{Liu2016p1715-1718,
  author   = {X. Liu and Z. Li and P. Miraldo and K. Zhong and Y. Shi},
  title    = {A Framework to Calibrate the Scanning Electron Microscope Under Variational Magnifications},
  journal  = {IEEE Photonics Technology Letters},
  year     = {2016},
  volume   = {28},
  number   = {16},
  pages    = {1715-1718},
  month    = {Aug},
  issn     = {1041-1135},
  doi      = {10.1109/LPT.2016.2522758},
  keywords = {calibration;scanning electron microscopy;black box;linear well point-based calibration method;scanning electron microscope calibration procedures;scanning electron microscope imaging model;scanning electron microscope system;variational magnifications;Calibration;Computational modeling;Numerical analysis;Scanning electron microscopy;Solid modeling;Three-dimensional displays;Calibration;Computational imaging;General imaging model;Scanning electron microscope;calibration;computational imaging;general imaging model},
}

@Article{Wang2016p288-291,
  author   = {Y. Wang and J. Suo and J. Fan and Q. Dai},
  title    = {Hyperspectral Computational Ghost Imaging via Temporal Multiplexing},
  journal  = {IEEE Photonics Technology Letters},
  year     = {2016},
  volume   = {28},
  number   = {3},
  pages    = {288-291},
  month    = {Feb},
  issn     = {1041-1135},
  doi      = {10.1109/LPT.2015.2494878},
  keywords = {hyperspectral imaging;image coding;image reconstruction;lighting;optical images;optical modulation;optical projectors;principal component analysis;2D illumination pattern;bucket detector;hyperspectral computational ghost imaging;hyperspectral image projections;image reconstruction quality;principal component analysis;spatial illumination modulation;spectral reflectance well;spectrum encoded acquisition scheme;temporal multiplexing;Detectors;Hyperspectral imaging;Image color analysis;Image reconstruction;Imaging;Lighting;Wheels;Computational imaging;Ghost imaging;Hyperspectal imaging;Single-pixel imaging;ghost imaging;hyperspectal imaging;single-pixel imaging},
}

@Article{Shin2015p2254-2258,
  author   = {D. Shin and J. H. Shapiro and V. K. Goyal},
  title    = {Single-Photon Depth Imaging Using a Union-of-Subspaces Model},
  journal  = {IEEE Signal Processing Letters},
  year     = {2015},
  volume   = {22},
  number   = {12},
  pages    = {2254-2258},
  month    = {Dec},
  issn     = {1070-9908},
  doi      = {10.1109/LSP.2015.2475274},
  keywords = {Poisson equation;optical filters;optical radar;photon counting;Poisson observation model;background light;discrete-time flux;greedy signal-pursuit algorithm;light detection and ranging systems;maximum-likelihood solution;photon detections;pixelwise log-matched filtering;single-photon depth imaging;union-of-subspaces model;Calibration;Correlation;Detectors;Imaging;Lighting;Noise;Photonics;Computational imaging;LIDAR;greedy algorithms;single-photon imaging;union-of-subspaces},
}

@Article{Feigin2016p3419-3427,
  author   = {M. Feigin and A. Bhandari and S. Izadi and C. Rhemann and M. Schmidt and R. Raskar},
  title    = {Resolving Multipath Interference in Kinect: An Inverse Problem Approach},
  journal  = {IEEE Sensors Journal},
  year     = {2016},
  volume   = {16},
  number   = {10},
  pages    = {3419-3427},
  month    = {May},
  issn     = {1530-437X},
  doi      = {10.1109/JSEN.2015.2421360},
  keywords = {frequency measurement;image sensors;inverse problems;Kinect;XBox One camera;closed-form noniterative technique;inverse problems;multipath interference;multiple frequency measurements;spectral estimation problem;Cameras;Eigenvalues and eigenfunctions;Frequency measurement;Frequency modulation;Interference;Sensors;Computational imaging;Depth imaging;Inverse Problems;Multi-path interference;Time-of-Flight imaging;Time-of-flight imaging;computational imaging;depth imaging;inverse problems;multipath interference},
}

@Article{Barry2015p56-66,
  author   = {B. Barry and C. Brick and F. Connor and D. Donohoe and D. Moloney and R. Richmond and M. O'Riordan and V. Toma},
  title    = {Always-on Vision Processing Unit for Mobile Applications},
  journal  = {IEEE Micro},
  year     = {2015},
  volume   = {35},
  number   = {2},
  pages    = {56-66},
  month    = {Mar},
  issn     = {0272-1732},
  doi      = {10.1109/MM.2015.10},
  keywords = {computer vision;instruction sets;mobile computing;multiprocessing systems;system-on-chip;Myriad 2;always-on system-on-chip;always-on vision processing unit;computational imaging;computer vision applications;embedded applications;instruction set architecture;low latency requirements;microarchitectural features;mobile applications;sustainable performance efficiency;visual awareness;wearable applications;Computational efficiency;Computer architecture;Computer vision;Embedded system;Graphics processing units;Instruction sets;Memory management;Multicore processing;ISA;SIMD;VLIW;VLLIW;VPU;computational imaging;computer vision;corner detection;embedded systems;hardware accelerator;instruction set architecture;mobile;multicore;multicore multiported memory subsystem;variable-length long instruction word;vector processor;very long instruction word;vision processing unit},
}

@Article{Liu2014p258-266,
  author   = {C. Liu and L. A. Christopher},
  title    = {Three dimensional moving pictures with a single imager and microfluidic lens},
  journal  = {IEEE Transactions on Consumer Electronics},
  year     = {2014},
  volume   = {60},
  number   = {2},
  pages    = {258-266},
  month    = {May},
  issn     = {0098-3063},
  doi      = {10.1109/TCE.2014.6852002},
  keywords = {Markov processes;expectation-maximisation algorithm;high definition television;humanities;image colour analysis;image sensors;lenses;microfluidics;solid modelling;three-dimensional displays;3D movie acquisition;3D moving pictures;3D object modeling;EDfD;Markov random field;RMSE;average root mean squared error;cell phone movie cameras;consumer products;depth data;depth map;expectation maximization;extended depth-from-defocus;fasy-focus microfluidic lens;high frequency image data;image color data;movie speeds;multiple cameras;multiple views;real-time HDTV 3D movie frame rates;single imager;small camcorders;Cameras;Estimation;Lenses;Mathematical model;Microfluidics;Three-dimensional displays;Computational Imaging;Depth from Defocus;Expectation Maximization;Markov Random Field},
}

@Article{Langfelder2013p1695-1700,
  author   = {G. Langfelder},
  title    = {CMOS Pixels Directly Sensitive to Both Visible and Near-Infrared Radiation},
  journal  = {IEEE Transactions on Electron Devices},
  year     = {2013},
  volume   = {60},
  number   = {5},
  pages    = {1695-1700},
  month    = {May},
  issn     = {0018-9383},
  doi      = {10.1109/TED.2013.2255056},
  keywords = {CMOS image sensors;finite element analysis;CMOS pixels;NIR channels;NIR signals;VIS channels;VIS signals;device principle;finite element simulation;four-band passive pixel;monolithic CMOS sensor;near-infrared radiation;pixel topology;radiation absorption depth dependence;sensor resolution;size 6.4 mum;transverse field detector principle;visible radiation;working principle;CMOS sensors;Color imaging;Computational imaging;Infrared imaging;CMOS sensors;color imaging;computational imaging;infrared imaging},
}

@Article{Javidi2010p256-259,
  author   = {B. Javidi and M. Daneshpanah and I. Moon},
  title    = {Three-Dimensional Holographic Imaging for Identification of Biological Micro/Nanoorganisms},
  journal  = {IEEE Photonics Journal},
  year     = {2010},
  volume   = {2},
  number   = {2},
  pages    = {256-259},
  month    = {April},
  doi      = {10.1109/JPHOT.2010.2044876},
  keywords = {Biomedical imaging;Holography;Microscopy;Three dimensional displays;3-D microscopy;Digital holography;cell analysis;computational imaging;medical and biological imaging},
}

@Article{Wang2012p257-271,
  author   = {A. Wang and A. Molnar},
  title    = {A Light-Field Image Sensor in 180 nm CMOS},
  journal  = {IEEE Journal of Solid-State Circuits},
  year     = {2012},
  volume   = {47},
  number   = {1},
  pages    = {257-271},
  month    = {Jan},
  issn     = {0018-9200},
  doi      = {10.1109/JSSC.2011.2164669},
  keywords = {CMOS image sensors;light diffraction;mixed analogue-digital integrated circuits;natural scenes;photodiodes;CMOS image sensor;CMOS manufacturing technology;complex visual scenes;incident angle detection;light field image sensor;local diffraction gratings;metal interconnect layers;mixed-mode CMOS process;photodiode;size 180 nm;Arrays;CMOS integrated circuits;Cameras;Diffraction;Diffraction gratings;Gratings;Image sensors;3D imaging;Angle-sensitive pixel;CMOS image sensor;Talbot effect;computational imaging;light field;rangefinding;synthetic refocus},
}

@Article{Peng2012p897-910,
  author   = {M. Peng and Y. Xiao},
  title    = {Notice of Retraction A survey of reference structure for sensor systems},
  journal  = {IEEE Communications Surveys Tutorials},
  year     = {2012},
  volume   = {14},
  number   = {3},
  pages    = {897-910},
  month    = {Third},
  issn     = {1553-877X},
  doi      = {10.1109/SURV.2011.081511.00070},
  keywords = {absorption;image processing;mathematical analysis;permittivity;sensors;absorption;computational imaging systems;mathematical framework;modulation role;object space segmentation;permittivity;radiation properties;reference structure;sensor systems;Reference structure;computational imaging system;sensor system},
}

@Article{Bagheri2010p412-421,
  author   = {S. Bagheri and Z. Kavehvash and K. Mehrany and B. Javidi},
  title    = {A Fast Optimization Method for Extension of Depth-of-Field in Three-Dimensional Task-Specific Imaging Systems},
  journal  = {Journal of Display Technology},
  year     = {2010},
  volume   = {6},
  number   = {10},
  pages    = {412-421},
  month    = {Oct},
  issn     = {1551-319X},
  doi      = {10.1109/JDT.2010.2049335},
  keywords = {image processing;optical transfer function;optimisation;principal component analysis;depth-of-field extension;high energy spatial frequency;modulation transfer function;optimization method;principal component analysis;pupil plane;spatial frequency spectrum;three dimensional imaging systems;three dimensional task specific imaging systems;Design engineering;Filters;Frequency;Image generation;Image quality;Lenses;Optimization methods;Power engineering and energy;Principal component analysis;Transfer functions;Bio imaging;computational imaging;depth of field (DOF);pupil function engineering},
}

@Article{Veeraraghavan2011p671-686,
  author   = {A. Veeraraghavan and D. Reddy and R. Raskar},
  title    = {Coded Strobing Photography: Compressive Sensing of High Speed Periodic Videos},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2011},
  volume   = {33},
  number   = {4},
  pages    = {671-686},
  month    = {April},
  issn     = {0162-8828},
  doi      = {10.1109/TPAMI.2010.87},
  keywords = {Fourier transforms;image reconstruction;image sampling;image sequences;video signal processing;Fourier domain;Nyquist rate constraint;coded strobing photography;compressive sensing;dynamic event projection;high speed periodic videos;low-frame-rate camera;sub-Nyquist signal sampling;temporal modulation;video reconstruction;Biomedical imaging;Cameras;Frequency;Image reconstruction;Inspection;Layout;Photography;Reconstruction algorithms;Signal design;Signal sampling;Computational imaging;compressive sensing;compressive video sensing;high-speed imaging;stroboscopy.;Algorithms;Image Processing, Computer-Assisted;Photography;Signal Processing, Computer-Assisted;Video Recording},
}

@Article{Horn2010p193-205,
  author   = {B. K. P. Horn and R. C. Lanza and J. T. Bell and G. E. Kohse},
  title    = {Dynamic Reconstruction},
  journal  = {IEEE Transactions on Nuclear Science},
  year     = {2010},
  volume   = {57},
  number   = {1},
  pages    = {193-205},
  month    = {Feb},
  issn     = {0018-9499},
  doi      = {10.1109/TNS.2009.2032544},
  keywords = {computerised tomography;image reconstruction;image sequences;medical image processing;backscattered X-rays;coded apertures;dynamic reconstruction;image sequences;information collection modality;isotopic area sources;radiation detection systems;Apertures;Autocorrelation;Fourier transforms;Frequency;Image reconstruction;Optical imaging;Radiation detectors;Tomography;X-ray detection;X-ray detectors;Back projection;X-ray backscatter;coded apertures;computational imaging;dynamic reconstruction;moving detector systems;tomographic reconstruction, rank3},
}

@Article{Mait2009p1713-1719,
  author   = {J. N. Mait and D. A. Wikner and M. S. Mirotznik and J. van der Gracht and G. P. Behrmann and B. L. Good and S. A. Mathews},
  title    = {94-GHz Imager With Extended Depth of Field},
  journal  = {IEEE Transactions on Antennas and Propagation},
  year     = {2009},
  volume   = {57},
  number   = {6},
  pages    = {1713-1719},
  month    = {June},
  issn     = {0018-926X},
  doi      = {10.1109/TAP.2009.2019882},
  keywords = {millimetre wave imaging;signal processing;computational imaging;cubic phase element;depth-of-field;frequency 90 GHz;millimeter wave imaging;post-detection signal processing;render system operation;Clothing;Frequency;Helium;Millimeter wave technology;Optical imaging;Optical signal processing;Signal design;Signal processing;System performance;Weapons;Computational imaging;extended depth of field;millimeter wave imaging},
}

@Article{Wu2018p17768-17775,
  author   = {S. Wu and T. Zhang and B. Wu and C. Liu and J. Xiao},
  title    = {Single-Pixel Camera in the Visible Band With Fiber Signal Collection},
  journal  = {IEEE Access},
  year     = {2018},
  volume   = {6},
  pages    = {17768-17775},
  doi      = {10.1109/ACCESS.2018.2819358},
  keywords = {cameras;compressed sensing;image reconstruction;image resolution;coded measurements;computational imaging;computational reconstruction algorithm;conventional SPC;conventional imaging;fiber collection;fiber signal collection;fiber-based prototype system;high-quality images;high-signal-to-noise visible light imaging;image quality;lens collection scheme;linear measurements;multispectral imaging;projected patterns;single-pixel camera;single-pixel sensor;visible band;Cameras;Detectors;Image coding;Image reconstruction;Lenses;Optical fiber sensors;Single-pixel camera;correlation coefficient;fiber collection;noise suppression},
}

@Article{Yurduseven2017p1962-1969,
  author   = {O. Yurduseven and P. Flowers and S. Ye and D. L. Marks and J. N. Gollub and T. Fromenteze and B. J. Wiley and D. R. Smith},
  title    = {Computational microwave imaging using 3D printed conductive polymer frequency-diverse metasurface antennas},
  journal  = {IET Microwaves, Antennas Propagation},
  year     = {2017},
  volume   = {11},
  number   = {14},
  pages    = {1962-1969},
  issn     = {1751-8725},
  doi      = {10.1049/iet-map.2017.0104},
  keywords = {image reconstruction;metamaterial antennas;microwave antennas;microwave imaging;polymers;3D printed conductive polymer frequency-diverse metasurface antennas;Electrifi conductivity;K-band frequency regime;active circuit component;composite aperture design;computational microwave imaging;conductive polymer material;diffraction limit;frequency 17.5 GHz to 26.5 GHz;frequency-diverse computational imaging system;image reconstruction;laser-etching;machine milling;mechanical scanning;photolithography;polylactic acid polymer material;three-dimensional fabrication},
}

@Article{Sleasman2017p6864-6877,
  author   = {T. Sleasman and M. Boyarsky and L. Pulido-Mancera and T. Fromenteze and M. F. Imani and M. S. Reynolds and D. R. Smith},
  title    = {Experimental Synthetic Aperture Radar With Dynamic Metasurfaces},
  journal  = {IEEE Transactions on Antennas and Propagation},
  year     = {2017},
  volume   = {65},
  number   = {12},
  pages    = {6864-6877},
  month    = {Dec},
  issn     = {0018-926X},
  doi      = {10.1109/TAP.2017.2758797},
  keywords = {aperture antennas;metamaterial antennas;microwave antennas;microwave resonators;radar antennas;radar imaging;synthetic aperture radar;transmitting antennas;1D microstrip waveguide;K-band frequencies;SAR modalities;cELC resonance;complementary electric resonator elements;computational imaging strategies;dynamic metasurface antenna;frequency 17.5 GHz to 20.3 GHz;image quality;metasurface aperture;synthetic aperture radar imaging system;transmitting antenna;Antenna radiation patterns;Apertures;Imaging;Radar imaging;Resonant frequency;Synthetic aperture radar;Beam steering;microwave imaging;radar imaging;reconfigurable antennas;synthetic aperture radar (SAR);waveguide antennas},
}

@Article{Yurduseven2017p2808-2811,
  author   = {O. Yurduseven and T. Fromenteze and D. L. Marks and J. N. Gollub and D. R. Smith},
  title    = {Frequency-Diverse Computational Microwave Phaseless Imaging},
  journal  = {IEEE Antennas and Wireless Propagation Letters},
  year     = {2017},
  volume   = {16},
  pages    = {2808-2811},
  issn     = {1536-1225},
  doi      = {10.1109/LAWP.2017.2748139},
  keywords = {antenna radiation patterns;image reconstruction;image retrieval;microwave antennas;microwave circuits;microwave imaging;microwave phase shifters;K-band frequencies;Wirtinger Flow algorithm;cavity-backed metasurface antenna;computational imaging system;frequency 17.5 GHz to 26.5 GHz;frequency-diverse computational microwave phaseless imaging;frequency-diverse metasurface antenna;image sampling;mechanically moving parts;phase retrieval techniques;phase-shifting circuits;phaseless frequency-diverse computational imaging system;spatially diverse radiation patterns;Antenna measurements;Antenna radiation patterns;Apertures;Frequency measurement;Image reconstruction;Imaging;Phase measurement;Computational;imaging;metasurface;microwaves;phase retrieval, rank3},
}

@Article{Sleasman2017p3257-3262,
  author   = {T. Sleasman and M. F. Imani and O. Yurduseven and K. P. Trofatter and V. R. Gowda and D. L. Marks and J. N. Gollub and D. R. Smith},
  title    = {Near Field Scan Alignment Procedure for Electrically Large Apertures},
  journal  = {IEEE Transactions on Antennas and Propagation},
  year     = {2017},
  volume   = {65},
  number   = {6},
  pages    = {3257-3262},
  month    = {June},
  issn     = {0018-926X},
  doi      = {10.1109/TAP.2017.2691465},
  keywords = {antenna radiation patterns;microwave antenna arrays;photogrammetry;RF markers;antenna structures;characterization process;computational imaging;electrically large apertures;metamaterial apertures;multistatic imaging systems;near field scan alignment procedure;near field scanning;optical photogrammetry;radiation patterns;security screening;threat detection;Adaptive optics;Antennas;Noise measurement;Optical imaging;Optical variables measurement;Radio frequency;Antenna radiation patterns;microwave antenna arrays;microwave imaging;multi-in multi-out systems;near fields;nonuniformly spaced arrays;optical position measurement;radar position measurement;sparse array antennas},
}

@Article{Patel2016p109-118,
  author   = {V. M. Patel and J. N. Mait and D. W. Prather and A. S. Hedden},
  title    = {Computational Millimeter Wave Imaging: Problems, progress, and prospects},
  journal  = {IEEE Signal Processing Magazine},
  year     = {2016},
  volume   = {33},
  number   = {5},
  pages    = {109-118},
  month    = {Sept},
  issn     = {1053-5888},
  doi      = {10.1109/MSP.2016.2581206},
  keywords = {image processing;millimetre wave imaging;computational imaging;computational millimeter wave imaging;imaging obstacles;terrestrial bodies;Apertures;Digital imaging;Millimeter wave imaging;Optical filters;Optical imaging;Optical signal processing;Optical variables measurement;Phase measurement, rank3},
}

@Article{Dana2016p70-80,
  author   = {K. J. Dana},
  title    = {Capturing Computational Appearance: More than meets the eye},
  journal  = {IEEE Signal Processing Magazine},
  year     = {2016},
  volume   = {33},
  number   = {5},
  pages    = {70-80},
  month    = {Sept},
  issn     = {1053-5888},
  doi      = {10.1109/MSP.2016.2580179},
  keywords = {cameras;goniometers;image recognition;reflectometers;surface texture;camera;computational imaging;digital architecture;e-commerce;gonioreflectometer;human-computer interaction;image recognition;image rendering;inspection;intelligent vehicle;lighting;robotics;surface geometry;surface reflectance;surface texture;Cameras;Computational complexity;Digital imaging;Lighting;Reflection;Reflectivity;Surface treatment},
}

@Article{Ho2016p52-56,
  author   = {R. Ho},
  title    = {Enabling the Hardware for Computational Photography: Mark Horowitz Turned Ideas into Working Hardware Systems},
  journal  = {IEEE Solid-State Circuits Magazine},
  year     = {2016},
  volume   = {8},
  number   = {3},
  pages    = {52-56},
  month    = {Summer},
  issn     = {1943-0582},
  doi      = {10.1109/MSSC.2016.2580282},
  keywords = {cameras;photography;computational imaging;computational photography;hardware systems;light fields;Apertures;Cameras;Digital imaging;Lenses;Photography},
}

@Article{Yurduseven2016p1174-1181,
  author   = {O. Yurduseven and V. R. Gowda and J. N. Gollub and D. R. Smith},
  title    = {Multistatic microwave imaging with arrays of planar cavities},
  journal  = {IET Microwaves, Antennas Propagation},
  year     = {2016},
  volume   = {10},
  number   = {11},
  pages    = {1174-1181},
  issn     = {1751-8725},
  doi      = {10.1049/iet-map.2015.0836},
  keywords = {calibration;image reconstruction;microwave imaging;microwave metamaterials;radar imaging;synthetic aperture radar;air-filled cavity systems;aperiodic pattern;cavity imager;cavity-based imager;computational imaging systems;frequency-diverse aperture;frequency-diverse panels;image reconstructions;microwave frequencies;mode diversity;multistatic imaging system;multistatic microwave imaging;planar cavity subapertures;radiation patterns;receive panels;transmit panels},
}

@Article{Shkvarko2016p152-156,
  author   = {Y. V. Shkvarko and J. I. Yañez and J. A. Amao and G. D. Martín del Campo},
  title    = {Radar/SAR Image Resolution Enhancement via Unifying Descriptive Experiment Design Regularization and Wavelet-Domain Processing},
  journal  = {IEEE Geoscience and Remote Sensing Letters},
  year     = {2016},
  volume   = {13},
  number   = {2},
  pages    = {152-156},
  month    = {Feb},
  issn     = {1545-598X},
  doi      = {10.1109/LGRS.2015.2502539},
  keywords = {computational complexity;discrete wavelet transforms;geophysical image processing;image denoising;image enhancement;image reconstruction;image resolution;iterative methods;remote sensing by radar;synthetic aperture radar;coherent remote sensing;descriptive experiment design regularization;despeckled high-resolution image;discrete-wavelet-transform-based sparsity-promoting denoising;feature-enhanced radar-fractional synthetic aperture radar computational imaging;iterative reconstruction;multistage iterative superresolution technique;radar-SAR image resolution enhancement;wavelet-domain processing;Convergence;Discrete wavelet transforms;Image reconstruction;Image resolution;Imaging;Radar imaging;Experiment design;radar image enhancement;sparse representation;superresolution (SR);wavelets},
}

@Article{Stern2014p1571-1587,
  author   = {A. Stern and Y. Yitzhaky and B. Javidi},
  title    = {Perceivable Light Fields: Matching the Requirements Between the Human Visual System and Autostereoscopic 3-D Displays},
  journal  = {Proceedings of the IEEE},
  year     = {2014},
  volume   = {102},
  number   = {10},
  pages    = {1571-1587},
  month    = {Oct},
  issn     = {0018-9219},
  doi      = {10.1109/JPROC.2014.2348938},
  keywords = {display devices;stereo image processing;three-dimensional displays;visual perception;3D visualization technology;Asia;Europe;North America;autostereoscopic 3D display;comfort-based requirement;computational imaging;computer graphics;depth perception;human visual system;nonlinear effect;perceivable light field;physiological 3D information sensing capability;reality communication;signal processing;spatial resolution;spectral content;temporal resolution;vergence accommodation effect;Human factors;Optical imaging;Stereo image processing;Three-dimensional displays;Visual systems;Visualization;3-D displays;Autostersoecopic displays;human visual perception;light fields;visual fatigue},
}

@Article{Faramarzi2013p2101-2114,
  author   = {E. Faramarzi and D. Rajan and M. P. Christensen},
  title    = {Unified Blind Method for Multi-Image Super-Resolution and Single/Multi-Image Blur Deconvolution},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2013},
  volume   = {22},
  number   = {6},
  pages    = {2101-2114},
  month    = {June},
  issn     = {1057-7149},
  doi      = {10.1109/TIP.2013.2237915},
  keywords = {AWGN;Markov processes;deconvolution;estimation theory;frequency-domain analysis;image registration;image resolution;image restoration;image sampling;iterative methods;minimisation;random processes;AM;AWGN;HMRF;HR;Huber-Markov random field model;LR;LSI;MIBD;MISR;SIBD;additive white Gaussian noise;alternating minimization;blur estimation process;computational imaging;edge-emphasizing smoothing operation;filtering domain;frequency domain analysis;high-resolution imaging;image reconstruction;image registration;image sampling;image separation;linear space-invariant blur;low-resolution imaging;multiimage superresolution;noniterative optimization;regularization term;single-multiimage blur deconvolution;unified blind method;Estimation;Image edge detection;Image reconstruction;Image resolution;Noise;Optimization;Smoothing methods;Blind estimation;Huber-Markov Random Field (HMRF) prior;blur deconvolution;image restoration;super-resolution;Algorithms;Animals;Computer Simulation;Diagnostic Imaging;Humans;Image Processing, Computer-Assisted;Markov Chains;Phantoms, Imaging;Photography},
}

@Article{Zhou2011p3322-3340,
  author   = {C. Zhou and S. K. Nayar},
  title    = {Computational Cameras: Convergence of Optics and Processing},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2011},
  volume   = {20},
  number   = {12},
  pages    = {3322-3340},
  month    = {Dec},
  issn     = {1057-7149},
  doi      = {10.1109/TIP.2011.2171700},
  keywords = {cameras;image coding;image sensors;2D image sensor;camera arrays;clusters;computational camera;computational imaging;illumination coding;light field representation;object side coding;pupil plane coding;sensor side coding;unconventional imaging systems;Cameras;Detectors;Image coding;Lenses;Optical devices;Computer vision;image processing;imaging;optics},
}

@Article{Javidi2005p341-346,
  author   = {B. Javidi and Seung-Hyun Hong},
  title    = {Three-dimensional holographic image sensing and Integral imaging display},
  journal  = {Journal of Display Technology},
  year     = {2005},
  volume   = {1},
  number   = {2},
  pages    = {341-346},
  month    = {Dec},
  issn     = {1551-319X},
  doi      = {10.1109/JDT.2005.858871},
  keywords = {holography;image reconstruction;integral equations;microlenses;optical computing;three-dimensional displays;2D display;3D color objects;3D holographic image sensing;3D scene reconstruction;computational imaging reconstruction;digital holograms;incoherent light;integral imaging display;integral imaging reconstruction;microlens array;optical data processing;Holographic optical components;Holography;Image reconstruction;Layout;Optical arrays;Optical computing;Optical imaging;Optical sensors;Three dimensional displays;Two dimensional displays;Digital holography;integral imaging;optical data processing},
}

@Article{Zhu2017p2265-2269,
  author   = {S. Zhu and X. Dong and M. Zhang and R. Lu and J. Li and X. Chen and A. Zhang},
  title    = {A Super-Resolution Computational Coincidence Imaging Method Based on SIMO Radar System},
  journal  = {IEEE Geoscience and Remote Sensing Letters},
  year     = {2017},
  volume   = {14},
  number   = {12},
  pages    = {2265-2269},
  month    = {Dec},
  issn     = {1545-598X},
  doi      = {10.1109/LGRS.2017.2761552},
  keywords = {MIMO radar;frequency modulation;image resolution;optimisation;radar antennas;radar detection;radar imaging;radar resolution;SIMO radar system;directional pattern factor;incoherent imaging method;multilinear frequency modulation signal;multiple-output radar detection system;nonlinear post random modulation process;post random modulation radar imaging;radar elements;receiving radar array;single-output structure;super-resolution computational coincidence imaging method;super-resolution radar imaging;Frequency modulation;Image resolution;Imaging;Radar imaging;Signal resolution;Coincidence imaging;incoherent imaging;multilinear frequency modulation (MLFM) signal;random modulation, rank3},
}

@Article{Jeon2017p2311-2326,
  author   = {H. G. Jeon and J. Y. Lee and Y. Han and S. J. Kim and I. S. Kweon},
  title    = {Multi-Image Deblurring Using Complementary Sets of Fluttering Patterns},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2017},
  volume   = {26},
  number   = {5},
  pages    = {2311-2326},
  month    = {May},
  issn     = {1057-7149},
  doi      = {10.1109/TIP.2017.2675202},
  keywords = {cameras;computer vision;image capture;image restoration;image sequences;video signal processing;coded exposure video technique;complementary binary sequence set;complementary fluttering pattern sets;latent image all spectrum band preservation;multiimage motion deblurring;off-the-shelf machine vision camera;sharp latent image recovery;video frame capture;Cameras;Correlation;Gain;Image restoration;Lighting;Signal to noise ratio;Image deblurring;coded exposure;computational photography;video privacy protection},
}

@Article{Dong2014p1379-1393,
  author   = {C. Dong and Y. Jin and E. Lu},
  title    = {Accelerated Nonlinear Multichannel Ultrasonic Tomographic Imaging Using Target Sparseness},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2014},
  volume   = {23},
  number   = {3},
  pages    = {1379-1393},
  month    = {March},
  issn     = {1057-7149},
  doi      = {10.1109/TIP.2014.2302679},
  keywords = {gradient methods;image reconstruction;inverse problems;iterative methods;ultrasonic imaging;MIMO signal processing techniques;accelerated iterative Landweber method;accelerated nonlinear multichannel ultrasonic tomographic imaging;image reconstruction;iterative imaging method;multiple-input multiple-output configuration;real-time tomographic imaging;sparsity constraint;target sparseness constraints;Acoustics;Convergence;Image reconstruction;Inverse problems;MIMO;Tomography;Ultrasonic tomography;accelerated projected steepest descent method;inverse problems;multiple-input multiple-output;sparsity constraints;Algorithms;Image Enhancement;Image Interpretation, Computer-Assisted;Nonlinear Dynamics;Reproducibility of Results;Sensitivity and Specificity;Ultrasonography},
}

@Article{Chen2006p762-766,
  author   = {Xiaowei Chen and Xiaobo Zhou and S. T. C. Wong},
  title    = {Automated segmentation, classification, and tracking of cancer cell nuclei in time-lapse microscopy},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2006},
  volume   = {53},
  number   = {4},
  pages    = {762-766},
  month    = {April},
  issn     = {0018-9294},
  doi      = {10.1109/TBME.2006.870201},
  keywords = {biomedical optical imaging;cancer;cellular biophysics;fluorescence;image classification;image segmentation;medical image processing;optical microscopy;automated image segmentation;cancer cell nuclei tracking;cell cycle progression;cellular image analysis;drug treatment effects;image classification;perturbation;phase identification;time-lapse fluorescence microscopy imaging;Analysis of variance;Bioinformatics;Cancer;Data analysis;Drugs;Fluorescence;Image analysis;Image segmentation;Microscopy;Nuclear measurements;Image analysis;phase identification;time-lapse fluorescence microscopy;tracking;Artificial Intelligence;Cell Cycle;Cell Movement;Cell Nucleus;Humans;Image Interpretation, Computer-Assisted;Microscopy, Fluorescence;Microscopy, Video;Neoplasms;Pattern Recognition, Automated;Tumor Cells, Cultured},
}

@Article{Kamilov2017p1872-1876,
  author   = {U. S. Kamilov and H. Mansour and B. Wohlberg},
  title    = {A Plug-and-Play Priors Approach for Solving Nonlinear Imaging Inverse Problems},
  journal  = {IEEE Signal Processing Letters},
  year     = {2017},
  volume   = {24},
  number   = {12},
  pages    = {1872-1876},
  month    = {Dec},
  issn     = {1070-9908},
  doi      = {10.1109/LSP.2017.2763583},
  keywords = {image denoising;image reconstruction;image segmentation;iterative methods;optimisation;PPP framework;data consistency;fast iterative shrinkage algorithm variant;fast iterative thresholding algorithm variant;imaging systems;linear inverse problems;model-based nonlinear inverse scattering;nonlinear image reconstruction methods;nonlinear imaging inverse problems;optimization problems;plug-and-play priors approach;prior models;Computational modeling;Imaging;Inverse problems;Iterative methods;Mathematical model;Noise measurement;Optimization;Scattering;Fast iterative shrinkage/thresholding algorithm (FISTA);image reconstruction;inverse scattering;nonlinear inverse problems;plug-and-play priors (PPP)},
}

@Article{Lassila2018p1654-1661,
  author   = {T. Lassila and L. Y. D. Marco and M. Mitolo and V. Iaia and G. Levedianos and A. Venneri and A. F. Frangi},
  title    = {Screening for Cognitive Impairment by Model-Assisted Cerebral Blood Flow Estimation},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2018},
  volume   = {65},
  number   = {7},
  pages    = {1654-1661},
  month    = {July},
  issn     = {0018-9294},
  doi      = {10.1109/TBME.2017.2759511},
  keywords = {biomedical ultrasonics;blood;blood pressure measurement;blood vessels;brain;cognition;diseases;medical disorders;medical image processing;neurophysiology;patient monitoring;regression analysis;Alzheimer's disease;CBF-enhanced classifier;Holter blood pressure monitoring;MCI diagnosis accuracy;ambulatory blood pressure measurements;arterial spin-labeling magnetic resonance imaging;blood-brain barrier dysfunction;carotid ultrasound imaging;cerebral blood flow estimation;chronic cerebral hypoperfusion;dementia;early diagnosis;lasso regression models;mild cognitive impairment;neurodegenerative disease;physiological modeling;Biological system modeling;Biomedical monitoring;Blood flow;Predictive models;Ultrasonic imaging;Ultrasonic variables measurement;Alzheimer's disease;biomedical monitoring;cerebral blood flow;physiological modelling},
}

@Article{Kar2017p16495-16519,
  author   = {A. Kar and P. Corcoran},
  title    = {A Review and Analysis of Eye-Gaze Estimation Systems, Algorithms and Performance Evaluation Methods in Consumer Platforms},
  journal  = {IEEE Access},
  year     = {2017},
  volume   = {5},
  pages    = {16495-16519},
  doi      = {10.1109/ACCESS.2017.2735633},
  keywords = {gaze tracking;performance evaluation;consumer platforms;eye-gaze estimation;gaze tracking systems;performance evaluation;review;standardized methodologies;Calibration;Computers;Estimation;Gaze tracking;Imaging;Performance evaluation;Visualization;Eye gaze;accuracy;error sources;gaze estimation;performance evaluation;user platforms},
}

@Article{Bieth2017p2276-2286,
  author   = {M. Bieth and L. Peter and S. G. Nekolla and M. Eiber and G. Langs and M. Schwaiger and B. Menze},
  title    = {Segmentation of Skeleton and Organs in Whole-Body CT Images via Iterative Trilateration},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2017},
  volume   = {36},
  number   = {11},
  pages    = {2276-2286},
  month    = {Nov},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2017.2720261},
  keywords = {biological organs;bone;computerised tomography;image segmentation;iterative methods;medical image processing;anatomical localisation;high-level long-range context information;iterative scale-adaptive random forests;iterative trilateration;multi-organ localisation;organs segmentation;skeleton segmentation;spine imaging;whole body oncological screening;whole-bBody CT images;Biomedical imaging;Bones;Computed tomography;Context;Image segmentation;Radio frequency;Medical Imaging;Segmentation},
}

@Article{AliAkbarpour2017p4618-4637,
  author   = {H. AliAkbarpour and K. Palaniappan and G. Seetharaman},
  title    = {Parallax-Tolerant Aerial Image Georegistration and Efficient Camera Pose Refinement #x2014;Without Piecewise Homographies},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  year     = {2017},
  volume   = {55},
  number   = {8},
  pages    = {4618-4637},
  month    = {Aug},
  issn     = {0196-2892},
  doi      = {10.1109/TGRS.2017.2695172},
  keywords = {cameras;geophysical image processing;image registration;remote sensing;3D reconstruction;MavMap;Parallax-tolerant aerial image georegistration;Pix4D;SfM method;Structure from Motion;VisualSfM;camera metadata measurement;camera pose refinement;camera-induced motion;global positioning system;ground-plane georegistration method;ground-plane motion;image-plane-to-ground-plane homography transformation;image-to-image registration;inertial measurement unit;iterative consensus combinatorial method;object motion;on-board sensors;random sample consensus;sequential aerial imagery;sequential imagery;vehicle tracking;Cameras;Global Positioning System;Metadata;Noise measurement;Pipelines;Robustness;Three-dimensional displays;Aerial image stabilization;Structure from Motion (SfM);georegistration;homography and bundle adjustment (BA);multiview stereo (MVS);parallax tolerant;wide area motion imagery (WAMI)},
}

@Article{Fu2017p1930-1938,
  author   = {H. Fu and Y. Xu and S. Lin and X. Zhang and D. W. K. Wong and J. Liu and A. F. Frangi and M. Baskaran and T. Aung},
  title    = {Segmentation and Quantification for Angle-Closure Glaucoma Assessment in Anterior Segment OCT},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2017},
  volume   = {36},
  number   = {9},
  pages    = {1930-1938},
  month    = {Sept},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2017.2703147},
  keywords = {biomedical optical imaging;diseases;eye;image segmentation;medical image processing;optical tomography;Cirrus high-definition-OCT data set;Visante AS-OCT data set;angle-closure glaucoma;anterior chamber angle;anterior segment OCT;automatic AS-OCT structure measurement;automatic AS-OCT structure screening;automatic AS-OCT structure segmentation;automatic glaucoma screening algorithm;eye;graph-based smoothing method;hand-labeled exemplar data set;image analysis;imaging characteristics;ocular structure;optical coherence tomography;visual impairment;Cornea;Electronic mail;Feature extraction;Image segmentation;Imaging;Iris;Shape;AS-OCT;Data-driven;angle-closure glaucoma;anterior chamber angle;segmentation;Anterior Chamber;Anterior Eye Segment;Glaucoma, Angle-Closure;Gonioscopy;Humans;Tomography, Optical Coherence},
}

@Article{Gooya2018p891-904,
  author   = {A. Gooya and K. Lekadir and I. Castro-Mateos and J. M. Pozo and A. F. Frangi},
  title    = {Mixture of Probabilistic Principal Component Analyzers for Shapes from Point Sets},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2018},
  volume   = {40},
  number   = {4},
  pages    = {891-904},
  month    = {April},
  issn     = {0162-8828},
  doi      = {10.1109/TPAMI.2017.2700276},
  keywords = {Gaussian processes;principal component analysis;probability;unsupervised learning;Probabilistic Principal Component Analyzers;Variational Bayesian approach;distinctive shape classes;linear models;local variation modes;manifolds model;mean models;piece-wise linear form;point set labels;point sets;point-to-point correspondences;probability density function;shape spaces;shape variations;Data models;Manifolds;Principal component analysis;Probability density function;Shape;Sociology;Generative modeling;graphical models;model selection;statistical shape models;variational Bayes},
}

@Article{Vogl2017p1773-1783,
  author   = {W. D. Vogl and S. M. Waldstein and B. S. Gerendas and U. Schmidt-Erfurth and G. Langs},
  title    = {Predicting Macular Edema Recurrence from Spatio-Temporal Signatures in Optical Coherence Tomography Images},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2017},
  volume   = {36},
  number   = {9},
  pages    = {1773-1783},
  month    = {Sept},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2017.2700213},
  keywords = {biomedical optical imaging;data mining;diseases;eye;feature extraction;learning (artificial intelligence);medical image processing;optical tomography;random processes;regression analysis;sensitivity analysis;spatiotemporal phenomena;SD-OCT scans;area under the receiver operating characteristic curve;branch retinal vein occlusion;central retinal vein occlusion;data-driven machine learning approaches;fivefold cross-validation;high-dimensional feature space;longitudinal data mining;longitudinal spectral-domain optical coherence tomography imaging data;macular edema recurrence prediction;optical coherence tomography images;random forest-based extra trees;retinal diseases;retinal thickness features;sparse logistic regression;spatiotemporal features;Diseases;Feature extraction;Image segmentation;Imaging;Predictive models;Retina;Veins;Predictive models;biomarkers;optical coherence tomography;Humans;Macular Edema;Retina;Retinal Vein Occlusion;Tomography, Optical Coherence;Visual Acuity},
}

@Article{Aliakbarpour2017p2640-2641,
  author   = {H. Aliakbarpour and J. F. Ferreira and V. B. S. Prasath and K. Palaniappan and G. Seetharaman and J. Dias},
  title    = {A Probabilistic Fusion Framework for 3-D Reconstruction Using Heterogeneous Sensors},
  journal  = {IEEE Sensors Journal},
  year     = {2017},
  volume   = {17},
  number   = {9},
  pages    = {2640-2641},
  month    = {May},
  issn     = {1530-437X},
  doi      = {10.1109/JSEN.2017.2679187},
  keywords = {cameras;probability;sensor fusion;spatial variables measurement;time measurement;3D reconstruction;augmented reality;camera;heterogeneous sensor network;human behavior understanding;inertial sensor;multimodal data fusion;probabilistic fusion framework;robotics;smart-room implementation;time of flight sensor;Cameras;Fuses;Probabilistic logic;Robots;Sensor fusion;Three-dimensional displays;3D reconstruction;Multi-modal fusion;heterogeneous sensor network;probabilistic},
}

@Article{Suinesiaputra2018p503-515,
  author   = {A. Suinesiaputra and P. Ablin and X. Albà and M. Alessandrini and J. Allen and W. Bai and S. Çimen and P. Claes and B. R. Cowan and J. D’hooge and N. Duchateau and J. Ehrhardt and A. F. Frangi and A. Gooya and V. Grau and K. Lekadir and A. Lu and A. Mukhopadhyay and I. Oksuz and N. Parajuli and X. Pennec and M. Pereañez and C. Pinto and P. Piras and M. M. Rohé and D. Rueckert and D. Säring and M. Sermesant and K. Siddiqi and M. Tabassian and L. Teresi and S. A. Tsaftaris and M. Wilms and A. A. Young and X. Zhang and P. Medrano-Gracia},
  title    = {Statistical Shape Modeling of the Left Ventricle: Myocardial Infarct Classification Challenge},
  journal  = {IEEE Journal of Biomedical and Health Informatics},
  year     = {2018},
  volume   = {22},
  number   = {2},
  pages    = {503-515},
  month    = {March},
  issn     = {2168-2194},
  doi      = {10.1109/JBHI.2017.2652449},
  keywords = {cardiovascular system;computational geometry;data visualisation;diseases;feature extraction;image classification;medical image processing;shape recognition;statistical analysis;Cardiac Atlas Project website;feature extraction;functional patterns;left ventricular remodeling;myocardial infarct classification;quantifying geometric patterns;shape characterization;statistical shape modeling;three-dimensional left ventricular surface points;visualizing patterns;Biomedical imaging;Biomedical measurement;Diseases;Heart;Informatics;Shape;Training;Cardiac modeling;classification;myocardial infarct;statistical shape analysis},
}

@Article{Tsai2017p912-919,
  author   = {D. Tsai and D. G. Dansereau and T. Peynot and P. Corke},
  title    = {Image-Based Visual Servoing With Light Field Cameras},
  journal  = {IEEE Robotics and Automation Letters},
  year     = {2017},
  volume   = {2},
  number   = {2},
  pages    = {912-919},
  month    = {April},
  doi      = {10.1109/LRA.2017.2654544},
  keywords = {feature extraction;manipulators;robot vision;stereo image processing;visual servoing;compact light field feature representation;custom-mirror-based light field camera;feature detection enhancement;field-of-view constraints;field-of-view occlusions;light field cameras;light field image Jacobians;monocular image;robotic arm;standard visual servoing control loop;stereo image;Cameras;Feature extraction;Geometry;Jacobian matrices;Visual servoing;Computer vision for automation;visual servoing},
}

@Article{Aliakbarpour2016p8264-8285,
  author   = {H. Aliakbarpour and V. B. S. Prasath and K. Palaniappan and G. Seetharaman and J. Dias},
  title    = {Heterogeneous Multi-View Information Fusion: Review of 3-D Reconstruction Methods and a New Registration with Uncertainty Modeling},
  journal  = {IEEE Access},
  year     = {2016},
  volume   = {4},
  pages    = {8264-8285},
  doi      = {10.1109/ACCESS.2016.2629987},
  keywords = {cameras;computational geometry;image fusion;image reconstruction;image registration;inertial systems;measurement uncertainty;natural scenes;statistical analysis;3D data registration;3D orientation data;3D reconstruction methods;3D scene information;camera-IS node;coupled camera;fusion-based virtual camera;geometric relations;heterogeneous multiview information fusion;homography;hybrid sensor;image registration;inertial measurement unit;inertial planes;inertial sensor unit;measurement uncertainties;multisensor network fusion framework;multiview images;scene reconstruction;statistical geometry methods;structure-from-motion algorithms;transformation model uncertainties;uncertainty modeling;virtual registrations;Calibration;Cameras;Image reconstruction;Information fusion;Motion control;Solid modeling;Three-dimensional displays;Uncertainty;Wireless sensor networks;3D reconstruction;Structure-from-motion;coupled sensors;geometric uncertainty;heterogeneous information fusion;homography;image registration;inertial measurement unit (IMU);sensor network;virtual reality},
}

@Article{Alba2016p845-859,
  author   = {X. Albà and M. Pereañez and C. Hoogendoorn and A. J. Swift and J. M. Wild and A. F. Frangi and K. Lekadir},
  title    = {An Algorithm for the Segmentation of Highly Abnormal Hearts Using a Generic Statistical Shape Model},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2016},
  volume   = {35},
  number   = {3},
  pages    = {845-859},
  month    = {March},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2015.2497906},
  keywords = {biomedical MRI;cardiovascular system;diseases;feature extraction;image segmentation;medical image processing;physiological models;statistical analysis;boundary point search;cardiac image segmentation;feature point extraction;generic statistical shape model;highly abnormal heart segmentation;hypertrophic cardiomyopathy;magnetic resonance imaging;patient-specific geometry;pulmonary hypertension;Biomedical imaging;Deformable models;Heart;Image segmentation;Pathology;Reliability;Shape;Abnormal hearts;cardiac segmentation;hypertrophic cardiomyopathy;magnetic resonance imaging;pulmonary hypertension;statistical shape models;Algorithms;Cardiac Imaging Techniques;Cardiomyopathy, Hypertrophic;Heart;Humans;Hypertension, Pulmonary;Models, Cardiovascular;Models, Statistical;Myocardium;Reproducibility of Results},
}

@Article{Bazrafkan2015p65-71,
  author   = {S. Bazrafkan and A. Kar and C. Costache},
  title    = {Eye Gaze for Consumer Electronics: Controlling and commanding intelligent systems.},
  journal  = {IEEE Consumer Electronics Magazine},
  year     = {2015},
  volume   = {4},
  number   = {4},
  pages    = {65-71},
  month    = {Oct},
  issn     = {2162-2248},
  doi      = {10.1109/MCE.2015.2464852},
  keywords = {consumer electronics;feature extraction;gaze tracking;human computer interaction;intelligent control;HCI;consumer electronics;driver consciousness detection;gaze tracking;gaze-based interactions;human eye gaze;human-computer interaction;intelligent systems;multimedia entertainment;smart systems;smartphone;virtual gaming;Cameras;Consumer electronics;Cornea;Gaze tracking;Intelligent vehicles;Light sources;Lighting},
}

@Article{Cao2015p4381-4393,
  author   = {X. Cao and C. Zhang and C. Zhou and H. Fu and H. Foroosh},
  title    = {Constrained Multi-View Video Face Clustering},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2015},
  volume   = {24},
  number   = {11},
  pages    = {4381-4393},
  month    = {Nov},
  issn     = {1057-7149},
  doi      = {10.1109/TIP.2015.2463223},
  keywords = {face recognition;image representation;constrained multi-view video face clustering;graph regularization;pairwise constraints;sparse subspace representation;spectral clustering;unified graph-based model;Clustering methods;Electronic mail;Face;Face recognition;Feature extraction;Measurement;Sparse matrices;Video face clustering;multi-view clustering;pairwise constraints;sparse subspace representation},
}

@Article{Porras2016p89-97,
  author   = {A. R. Porras and M. Alessandrini and O. Mirea and J. D'hooge and A. F. Frangi and G. Piella},
  title    = {Integration of Multi-Plane Tissue Doppler and B-Mode Echocardiographic Images for Left Ventricular Motion Estimation},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2016},
  volume   = {35},
  number   = {1},
  pages    = {89-97},
  month    = {Jan},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2015.2456631},
  keywords = {echocardiography;image registration;interpolation;medical image processing;3D echocardiographic images;B-mode echocardiographic images;cardiac cycle;diffeomorphic continuous spatio-temporal transformation model;heart rhythms;interpolation;left ventricular motion estimation;multiplane tissue Doppler image integration;spherical data representation;ultrasound acquisition system;Image segmentation;Imaging;Spatial resolution;Splines (mathematics);Strain;Three-dimensional displays;Echocardiography;image integration;image registration;multi-plane;tissue Doppler;tracking;ultrasound;Adult;Echocardiography, Doppler;Female;Heart Ventricles;Humans;Image Processing, Computer-Assisted;Male;Middle Aged},
}

@Article{Castro-Mateos2015p1663-1675,
  author   = {I. Castro-Mateos and J. M. Pozo and M. Pereañez and K. Lekadir and A. Lazary and A. F. Frangi},
  title    = {Statistical Interspace Models (SIMs): Application to Robust 3D Spine Segmentation},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2015},
  volume   = {34},
  number   = {8},
  pages    = {1663-1675},
  month    = {Aug},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2015.2443912},
  keywords = {bone;computerised tomography;image segmentation;medical image processing;statistical analysis;CT image datasets;individual shape variations;medical image segmentation;multiobject structures;relative position vectors;robust 3D spine segmentation;statistical interspace models;Computational modeling;Geometry;Image segmentation;Manifolds;Shape;Splines (mathematics);Training;Inter-process overlap;multi-object;statistical shape models;vertebral segmentation;Adult;Algorithms;Databases, Factual;Female;Humans;Imaging, Three-Dimensional;Male;Middle Aged;Models, Statistical;Spine;Tomography, X-Ray Computed},
}

@Article{Cao2015p1302-1314,
  author   = {X. Cao and W. Ren and W. Zuo and X. Guo and H. Foroosh},
  title    = {Scene Text Deblurring Using Text-Specific Multiscale Dictionaries},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2015},
  volume   = {24},
  number   = {4},
  pages    = {1302-1314},
  month    = {April},
  issn     = {1057-7149},
  doi      = {10.1109/TIP.2015.2400217},
  keywords = {cameras;character recognition;image capture;image reconstruction;image restoration;natural scenes;text detection;TMD-based text field reconstruction;character recognition;handheld camera;image deblurring technique;image understanding;image visual quality improve;natural scene dictionary;natural scene image capture;nonuniform deblurring method adaptive version;scene text deblurring;spatially varying problem;text-specific multiscale dictionary learning;Cameras;Dictionaries;Image restoration;Kernel;Robustness;Training;Visualization;Scene text;multi-scale dictionaries;non-unifrom deblurring;text localization},
}

@Article{Pereanez2015p1627-1639,
  author   = {M. Pereañez and K. Lekadir and I. Castro-Mateos and J. M. Pozo and Á. Lazáry and A. F. Frangi},
  title    = {Accurate Segmentation of Vertebral Bodies and Processes Using Statistical Shape Decomposition and Conditional Models},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2015},
  volume   = {34},
  number   = {8},
  pages    = {1627-1639},
  month    = {Aug},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2015.2396774},
  keywords = {biomechanics;bone;computerised tomography;image reconstruction;image segmentation;medical image processing;muscle;statistical analysis;surgery;accurate segmentation;anatomic coherence;biomechanical modeling;conditional models;healthy CT scans;image-based spine assessment;image-guided interventions;ligaments;musculoskeletal models;optimal bone grafts placement;part-based statistical decomposition;pathological scans;point-to-surface error improvement;robust model fitting procedure;shape reconstruction;statistical interrelationships;statistical shape decomposition;surgery;vertebrae;vertebral bodies;Computational modeling;Computed tomography;Image segmentation;Pathology;Shape;Sociology;Training;Conditional models;part-based shape decomposition;point distribution models;vertebral segmentation;0},
}

@Article{Lekadir2015p1747-1759,
  author   = {K. Lekadir and C. Hoogendoorn and J. Hazrati-Marangalou and Z. Taylor and C. Noble and B. van Rietbergen and A. F. Frangi},
  title    = {A Predictive Model of Vertebral Trabecular Anisotropy From Ex Vivo Micro-CT},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2015},
  volume   = {34},
  number   = {8},
  pages    = {1747-1759},
  month    = {Aug},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2014.2387114},
  keywords = {biomechanics;bone;computerised tomography;feature extraction;feature selection;least squares approximations;medical disorders;medical image processing;regression analysis;statistical analysis;clinical medicine;comprehensive computational models;density information;ex vivo T12 vertebrae;ex vivo microCT;extracted shape;features selection;image-based biomechanical modeling;optimal latent variables;partial least squares regression;spinal interventions;spine-related disorders;statistical approach;subject-specific computational models;trabecular anisotropy;vertebral anisotropic microarchitecture;vertebral datasets;vertebral fabric tensors;vertebral trabecular anisotropy;Biomechanics;Bones;Fabrics;Predictive models;Shape;Tensile stress;Training;Bone shape and density;computational spine modeling;fabric tensors;micro-CT;optimal feature predictors;partial least squares regression;vertebral trabecular anisotropy;Aged;Aged, 80 and over;Algorithms;Anisotropy;Female;Humans;Image Processing, Computer-Assisted;Least-Squares Analysis;Male;Middle Aged;Models, Biological;Models, Statistical;Spine;X-Ray Microtomography},
}

@Article{Porras2014p1-11,
  author   = {A. R. Porras and G. Piella and A. Berruezo and J. Fernández-Armenta and A. F. Frangi},
  title    = {Pre to Intraoperative Data Fusion Framework for Multimodal Characterization of Myocardial Scar Tissue},
  journal  = {IEEE Journal of Translational Engineering in Health and Medicine},
  year     = {2014},
  volume   = {2},
  pages    = {1-11},
  doi      = {10.1109/JTEHM.2014.2354332},
  keywords = {bioelectric phenomena;biological tissues;biomechanics;biomedical MRI;cardiology;catheters;deformation;image fusion;image segmentation;medical image processing;motion estimation;patient treatment;DE-MRI;cardiac mechanics;catheter ablation;deformation;delayed enhancement magnetic resonance imaging;electrical-based characterization;electro-anatomical mapping data;endocardial motion;image segmentation;image-based characterization;intraoperative data fusion framework;ischemic cardiomyopathy;mechanical-based characterization;multimodal information;myocardial scar tissue;radiofrequency ablation;ventricular arrhythmias;ventricular tachycardia;Biomedical imaging;Catheters;Heart;Image segmentation;Magnetic resonance imaging;Myocardium;Three-dimensional displays;Arrhythmia;DE-MRI;catheter ablation;electro-anatomical mapping system;ventricular tachycardia},
}

@Article{Porras2014p2098-2106,
  author   = {A. R. Porras and M. Alessandrini and M. De Craene and N. Duchateau and M. Sitges and B. H. Bijnens and H. Delingette and M. Sermesant and J. D'hooge and A. F. Frangi and G. Piella},
  title    = {Improved Myocardial Motion Estimation Combining Tissue Doppler and B-Mode Echocardiographic Images},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2014},
  volume   = {33},
  number   = {11},
  pages    = {2098-2106},
  month    = {Nov},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2014.2331392},
  keywords = {Doppler measurement;echocardiography;image registration;image sequences;medical image processing;motion estimation;muscle;speckle;splines (mathematics);B-mode echocardiographic images;B-splines;diffeomorphic free form deformation;estimated velocity field;estimation accuracy;exercise;heart rates;image quality;image registration;mean displacement errors;myocardial motion estimation;realistic synthetic dataset;registration accuracy;rest;scan conversion;similarity measure;spatiotemporal transform;speckle pattern distribution;tissue Doppler sequences;tissue Doppler velocities;Doppler effect;Imaging;Myocardium;Splines (mathematics);Transducers;Transforms;Velocity measurement;Echocardiography;free form deformation (FFD);image registration;motion estimation;multi-modal integration;temporal diffeomorphic free form deformation (TDFFD);tissue Doppler;ultrasound (US);0},
}

@Article{Lekadir2014p2740-2748,
  author   = {K. Lekadir and A. Pashaei and C. Hoogendoorn and M. Pereanez and X. Albà and A. F. Frangi},
  title    = {Effect of Statistically Derived Fiber Models on the Estimation of Cardiac Electrical Activation},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2014},
  volume   = {61},
  number   = {11},
  pages    = {2740-2748},
  month    = {Nov},
  issn     = {0018-9294},
  doi      = {10.1109/TBME.2014.2327025},
  keywords = {biodiffusion;bioelectric phenomena;biomedical MRI;cardiology;medical image processing;statistical analysis;DTI datasets;biventricular pacing simulation;cardiac electrical activation estimation;cardiac electrical activation patterns;cardiac electrical activation times;cardiac simulation;diffusion tensor imaging;local activation times;rule-based fiber model;sinus rhythm;statistical predictive model;statistically derived fiber models;subject-specific fiber orientation;Biological system modeling;Computational modeling;Diffusion tensor imaging;Estimation;Heart;Predictive models;Rhythm;Cardiac fibers;diffusion tensor imaging (DTI);rule-based models;simulation of electrophysiology;statistical predictive models;Animals;Cardiac Electrophysiology;Computer Simulation;Diffusion Tensor Imaging;Dogs;Heart;Heart Conduction System;Image Processing, Computer-Assisted;Models, Cardiovascular;Models, Statistical;Myofibrils},
}

@Article{Lekadir2014p882-890,
  author   = {K. Lekadir and C. Hoogendoorn and M. Pereanez and X. Albà and A. Pashaei and A. F. Frangi},
  title    = {Statistical Personalization of Ventricular Fiber Orientation Using Shape Predictors},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2014},
  volume   = {33},
  number   = {4},
  pages    = {882-890},
  month    = {April},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2013.2297333},
  keywords = {biomedical MRI;cardiology;muscle;physiological models;statistical analysis;canine subjects;ex vivo diffusion tensor imaging datasets;intersubject variability;latent shape predictors;left ventricles;myocardial fiber orientations;myocardial location;predictive framework;predictive model;right ventricles;statistical personalization;subject-specific geometry;ventricular fiber orientation;Diffusion tensor imaging;Myocardium;Predictive models;Shape;Tensile stress;Training;Vectors;Cardiac fiber structure;cardiac simulation;diffusion tensor imaging;partial least squares regression;predictive modeling;Algorithms;Animals;Dogs;Heart Ventricles;Imaging, Three-Dimensional;Least-Squares Analysis;Models, Cardiovascular},
}

@Article{Bogunovic2013p1587-1599,
  author   = {H. Bogunović and J. M. Pozo and R. Cárdenes and L. S. Román and A. F. Frangi},
  title    = {Anatomical Labeling of the Circle of Willis Using Maximum A Posteriori Probability Estimation},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2013},
  volume   = {32},
  number   = {9},
  pages    = {1587-1599},
  month    = {Sept},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2013.2259595},
  keywords = {bifurcation;biomedical MRI;blood vessels;brain;image segmentation;maximum likelihood estimation;medical image processing;probability;Circle-of-Willis;Riemannian manifold;anatomical structural variability;arterial segments;automated anatomical labeling;cerebral arteries;cerebrovascular pathologies;geometric characterization;graph they span;intersubject comparison;local bifurcation features;magnetic resonance angiography;maximum a posteriori probability estimation;mean detection accuracy;prior structural knowledge;rooted attributed relational graph;target vasculature;topology variability;vertices;Arteries;Bifurcation;Biomedical imaging;Labeling;Skeleton;Topology;Vectors;Anatomical labeling;attributed relational graph;classification;maximum a posteriori;vascular analysis;Adult;Aged;Algorithms;Circle of Willis;Female;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Angiography;Male;Middle Aged;Models, Statistical;Reproducibility of Results},
}

@Article{Wang2013p943-956,
  author   = {L. Wang and K. Lekadir and S. L. Lee and R. Merrifield and G. Z. Yang},
  title    = {A General Framework for Context-Specific Image Segmentation Using Reinforcement Learning},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2013},
  volume   = {32},
  number   = {5},
  pages    = {943-956},
  month    = {May},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2013.2252431},
  keywords = {Internet;biomedical MRI;cardiology;image segmentation;learning (artificial intelligence);medical image processing;adaptive model;context-specific image segmentation;context-specific segmentation;implicit model;large state-action space;learning in situ;medical image segmentation;online reinforcement learning framework;specific user intention;user interaction;Algorithm design and analysis;Context;Image segmentation;Learning;Muscles;Shape;Vectors;Cardiac image segmentation;context-specific segmentation;reinforcement learning;statistical shape model;Algorithms;Artificial Intelligence;Cardiac Imaging Techniques;Cardiomyopathy, Hypertrophic;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Imaging;Models, Cardiovascular;Reproducibility of Results},
}

@Article{Porras2013p1217-1224,
  author   = {A. R. Porras and G. Piella and A. Berruezo and C. Hoogendoorn and D. Andreu and J. Fernandez-Armenta and M. Sitges and A. F. Frangi},
  title    = {Interventional Endocardial Motion Estimation from Electroanatomical Mapping Data: Application to Scar Characterization},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2013},
  volume   = {60},
  number   = {5},
  pages    = {1217-1224},
  month    = {May},
  issn     = {0018-9294},
  doi      = {10.1109/TBME.2012.2230327},
  keywords = {biomechanics;biomedical MRI;deformation;electrocardiography;medical disorders;medical image processing;motion estimation;bilinear models;cardiac mechanics;cardiac pathologies;electrical voltage thresholds;electroanatomical mapping data;electroanatomical mapping system;endocardial geometry;endocardial strain estimation;interventional endocardial motion estimation;local electrograms;low voltage electrograms;maximum bipolar voltage;preoperative 3D magnetic resonance images;scar characterization;scar extent;scar location;scar presence;statistical atlas;synthetic data;ultrasound images;ventricular tachycardia ablation procedure;Catheters;Image reconstruction;Motion segmentation;Shape;Standards;Strain;Vectors;Cathter ablation;deformation estimation;electro-anatomical mapping data;scar characterization;ventricular tachycardia;Aged;Catheter Ablation;Cicatrix;Computer Simulation;Echocardiography;Electrocardiography;Endocardium;Humans;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Male;Middle Aged;Models, Cardiovascular;Reproducibility of Results;Signal Processing, Computer-Assisted;Tachycardia, Ventricular},
}

@Article{Hoogendoorn2013p28-44,
  author   = {C. Hoogendoorn and N. Duchateau and D. Sanchez-Quintana and T. Whitmarsh and F. M. Sukno and M. De Craene and K. Lekadir and A. F. Frangi},
  title    = {A High-Resolution Atlas and Statistical Model of the Human Heart From Multislice CT},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2013},
  volume   = {32},
  number   = {1},
  pages    = {28-44},
  month    = {Jan},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2012.2230015},
  keywords = {cardiology;computerised tomography;image registration;medical image processing;physiological models;3D+time multi-slice computed tomography sequences;cardiac phases;cardiac physiology;high-resolution atlas;human heart;multislice CT;nonrigid image registration;population mean image;spatial normalization;spatio-temporal statistical model;subject-specfíc cardiac motion;surface mesh representation warping;temporal image registration;Biomedical imaging;Heart;Image resolution;Image segmentation;Shape;Sociology;Statistics;Atlases;computational physiology;computed tomography;heart;population analysis;probabilistic and statistical methods;registration;segmentation;Atlases as Topic;Heart;Humans;Image Processing, Computer-Assisted;Models, Cardiovascular;Models, Statistical;Reproducibility of Results;Retrospective Studies;Tomography, X-Ray Computed},
}

@Article{Morales2013p119-129,
  author   = {H. G. Morales and I. Larrabide and A. J. Geers and L. San Roman and J. Blasco and J. M. Macho and A. F. Frangi},
  title    = {A Virtual Coiling Technique for Image-Based Aneurysm Models by Dynamic Path Planning},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2013},
  volume   = {32},
  number   = {1},
  pages    = {119-129},
  month    = {Jan},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2012.2219626},
  keywords = {biomedical equipment;coils;computational fluid dynamics;haemodynamics;path planning;patient treatment;physiological models;shear flow;CFD simulations;aneurysm cavities;clinical information;coil distributions;coiled aneurysms;computational algorithm modeling;computational fluid dynamics;dynamic path planning;endovascular devices;image-based aneurysm model;inserted coils;intraaneurysmal velocity;intravascular hemodynamics;macroscopic behavior;packing density;virtual coiling technique;wall shear stress;Aneurysm;Biomedical imaging;Coils;Computational modeling;Hemodynamics;Heuristic algorithms;Solid modeling;Cerebral aneurysm;computational fluid dynamics (CFD);endovascular coiling;image-based models;validation;Algorithms;Analysis of Variance;Cerebral Angiography;Computer Simulation;Hemodynamics;Humans;Image Processing, Computer-Assisted;Intracranial Aneurysm;Models, Cardiovascular;Reproducibility of Results;Statistics, Nonparametric},
}

@Article{Cerutti2012p4-7,
  author   = {S. Cerutti and A. Madabhushi and S. K. Shah and K. H. Chon},
  title    = {Editorial: TBME Letters Special Section on Multiscale Biomedical Signal and Image Modeling and Analysis},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2012},
  volume   = {59},
  number   = {1},
  pages    = {4-7},
  month    = {Jan},
  issn     = {0018-9294},
  doi      = {10.1109/TBME.2011.2178350},
  keywords = {Biomedical signal processing;Image analysis;Signal analysis;Special issues and sections;Algorithms;Animals;Computer Simulation;Diagnosis, Computer-Assisted;Humans;Image Interpretation, Computer-Assisted;Models, Biological;Signal Processing, Computer-Assisted},
}

@Article{Sebastian2011p3479-3482,
  author   = {R. Sebastian and V. Zimmerman and D. Romero and A. F. Frangi},
  title    = {Construction of a Computational Anatomical Model of the Peripheral Cardiac Conduction System},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2011},
  volume   = {58},
  number   = {12},
  pages    = {3479-3482},
  month    = {Dec},
  issn     = {0018-9294},
  doi      = {10.1109/TBME.2011.2166553},
  keywords = {bioelectric phenomena;biological tissues;biomechanics;cardiology;cellular biophysics;physiological models;statistical distributions;His bundle;Linden-mayer systems;computational anatomical model construction;distal sections;electrical activation sequences;histology;left bundle branches;multiscale cardiac electromechanic models;peripheral cardiac conduction system;physiological characteristics;rule-based method;statistical distributions;stochastic variability;ventricular model;Biological system modeling;Computational modeling;Heart;Humans;Materials;Mathematical model;Physiology;Biophysical modeling;cardiac conduction system (CCS);cardiac electrophysiology;Computer Simulation;Electrocardiography;Endocardium;Heart Conduction System;Heart Ventricles;Humans;Models, Cardiovascular},
}

@Article{Whitmarsh2011p2101-2114,
  author   = {T. Whitmarsh and L. Humbert and M. De Craene and L. M. Del Rio Barquero and A. F. Frangi},
  title    = {Reconstructing the 3D Shape and Bone Mineral Density Distribution of the Proximal Femur From Dual-Energy X-Ray Absorptiometry},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2011},
  volume   = {30},
  number   = {12},
  pages    = {2101-2114},
  month    = {Dec},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2011.2163074},
  keywords = {X-ray absorption;X-ray imaging;bone;density measurement;diseases;image reconstruction;image registration;medical image processing;shape measurement;statistical analysis;3D BMD distribution reconstruction;3D shape reconstruction;DXA image;QCT scans;areal bone mineral density;dual energy X-ray absorptiometry;image projection;intensity based 3D-2D registration process;osteoporosis diagnosis;proximal femur;quantitative computed tomography scans;reconstruction experiments;statistical model;Active appearance model;Active shape model;Bones;Computed tomography;Deformable models;Image reconstruction;Image registration;Three dimensional displays;Active appearance model;active shape model;deformable models;image reconstruction;image registration;Absorptiometry, Photon;Adult;Aged;Bone Density;Female;Femur;Humans;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Linear Models;Male;Middle Aged;Phantoms, Imaging;Reproducibility of Results},
}

@Article{Pashaei2011p2956-2960,
  author   = {A. Pashaei and D. Romero and R. Sebastian and O. Camara and A. F. Frangi},
  title    = {Fast Multiscale Modeling of Cardiac Electrophysiology Including Purkinje System},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2011},
  volume   = {58},
  number   = {10},
  pages    = {2956-2960},
  month    = {Oct},
  issn     = {0018-9294},
  doi      = {10.1109/TBME.2011.2162841},
  keywords = {bioelectric phenomena;cardiology;computerised tomography;Eikonal-type equations;Purkinje system;Purkinje-ventricular junctions;atrioventricular delay;cardiac conduction system;cardiac electrophysiology;cardiac myocytes;computed tomography;fast multiscale modeling;heart electrophysiology;patient-specific biventricular geometry;ventricle electrical activation;Biological system modeling;Computational modeling;Delay;Heart;Histograms;Myocardium;Rhythm;Cardiac conduction system;Purkinje Ventricular Junction;cardiac electrophysiology;fast marching method;multiscale modelling;Electrocardiography;Heart Conduction System;Humans;Male;Middle Aged;Models, Cardiovascular;Myocytes, Cardiac;Purkinje Fibers;Tomography, X-Ray Computed},
}

@Article{Benkner2010p1365-1377,
  author   = {S. Benkner and A. Arbona and G. Berti and A. Chiarini and R. Dunlop and G. Engelbrecht and A. F. Frangi and C. M. Friedrich and S. Hanser and P. Hasselmeyer and R. D. Hose and J. Iavindrasana and M. Köhler and L. L. Iacono and G. Lonsdale and R. Meyer and B. Moore and H. Rajasekaran and P. E. Summers and A. Wöhrer and S. Wood},
  title    = {#x0040;neurIST: Infrastructure for Advanced Disease Management Through Integration of Heterogeneous Data, Computing, and Complex Processing Services},
  journal  = {IEEE Transactions on Information Technology in Biomedicine},
  year     = {2010},
  volume   = {14},
  number   = {6},
  pages    = {1365-1377},
  month    = {Nov},
  issn     = {1089-7771},
  doi      = {10.1109/TITB.2010.2049268},
  keywords = {grid computing;knowledge based systems;medical computing;neurophysiology;ontologies (artificial intelligence);@neurIST system;advanced disease management;biomedical research;clinical care;complex processing service;computing service;heterogeneous data service;knowledge-based guidance;semantically mediated grid infrastructure;treatment planning;treatment research;Aneurysm;Biomedical computing;Biomedical imaging;Computational modeling;Diseases;Distributed computing;Grid computing;Hoses;Humans;Peer to peer computing;Aneurysms;architecture;biomechanical simulation;biomedical grid;ontology;Aneurysm;Biomedical Research;Computer Communication Networks;Computer Security;Database Management Systems;Disease Management;Europe;Humans;Information Dissemination;Medical Informatics},
}

@Article{Basavanhally2010p642-653,
  author   = {A. N. Basavanhally and S. Ganesan and S. Agner and J. P. Monaco and M. D. Feldman and J. E. Tomaszewski and G. Bhanot and A. Madabhushi},
  title    = {Computerized Image-Based Detection and Grading of Lymphocytic Infiltration in HER2+ Breast Cancer Histopathology},
  journal  = {IEEE Transactions on Biomedical Engineering},
  year     = {2010},
  volume   = {57},
  number   = {3},
  pages    = {642-653},
  month    = {March},
  issn     = {0018-9294},
  doi      = {10.1109/TBME.2009.2035305},
  keywords = {Markov processes;biological organs;biological tissues;cancer;cellular biophysics;computer aided analysis;feature extraction;gynaecology;image classification;medical image processing;mesh generation;support vector machines;3D embedding space;HER2+ breast cancer histopathology;Markov random field algorithms;Varma-Zisserman texton-based classification scheme;computerized image-based detection;distant recurrence;graph embedding;high-dimensional feature vector;lymphocytes;lymphocytic infiltration;lymphocytic infiltration grading;nodal metastasis;Breast cancer;Cancer detection;Computer aided diagnosis;Diseases;Markov random fields;Metastasis;Support vector machine classification;Support vector machines;Tree graphs;Visualization;Breast cancer (BC);classification;digital pathology;feature extraction;image analysis;lymphocytic infiltration (LI);nonlinear dimensionality reduction;prognosis;segmentation;texture;Algorithms;Artificial Intelligence;Breast Neoplasms;Diagnosis, Computer-Assisted;Female;Humans;Lymphocytes, Tumor-Infiltrating;Neoplasm Staging;Prognosis;Receptor, erbB-2;Reproducibility of Results},
}

@Article{Butakoff2006p1847-1857,
  author   = {C. Butakoff and A. F. Frangi},
  title    = {A Framework for Weighted Fusion of Multiple Statistical Models of Shape and Appearance},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2006},
  volume   = {28},
  number   = {11},
  pages    = {1847-1857},
  month    = {Nov},
  issn     = {0162-8828},
  doi      = {10.1109/TPAMI.2006.215},
  keywords = {computer vision;covariance matrices;statistical analysis;AR databases;EQUINOX databases;XM2VTS databases;active appearance models;covariance matrix;eigenspace fusion method;facial verification tests;multiple statistical models;unbiased mean;weighted fusion;Active appearance model;Active shape model;Context modeling;Covariance matrix;Databases;Fuses;Image analysis;Jacobian matrices;Shape control;Testing;AAM;ASM;model fusion;segmentation.;statistical model;Algorithms;Artificial Intelligence;Cluster Analysis;Computer Simulation;Face;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Statistical;Pattern Recognition, Automated;Subtraction Technique},
}

@Article{Hartkens2003p82-92,
  author   = {T. Hartkens and D. L. G. Hill and A. D. Castellano-Smith and D. J. Hawkes and C. R. Maurer and A. J. Martin and W. A. Hall and H. Liu and C. L. Truwit},
  title    = {Measurement and analysis of brain deformation during neurosurgery},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2003},
  volume   = {22},
  number   = {1},
  pages    = {82-92},
  month    = {Jan},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2002.806596},
  keywords = {biomechanics;biomedical MRI;brain;image registration;image segmentation;medical image processing;surgery;20 mm;biopsy;brain deformation;brain surface;brain surface shift;craniotomy;deeper brain structure;deformation patterns;direction of gravity;functional procedures;image-guided surgery systems;interventional magnetic resonance images;intraoperative brain deformation;ipsi-lateral hemisphere;lateral ventricles;lesion;limited intraoperative information;manual segmentation;neurosurgery;nonrigid registration;principal direction of displacement;resection procedures;simple computational algorithms;simple rules;skull;volume change;Biopsy;Brain;Gravity;Lesions;Magnetic analysis;Magnetic resonance;Neurosurgery;Skull;Surgery;Volume measurement;Adult;Aged;Aged, 80 and over;Algorithms;Brain;Brain Diseases;Cerebral Ventricles;Child, Preschool;Craniotomy;Female;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Magnetic Resonance Imaging;Male;Middle Aged;Models, Biological;Monitoring, Intraoperative;Motion;Reproducibility of Results;Sensitivity and Specificity;Subtraction Technique;Surgery, Computer-Assisted},
}

@Article{Frangi2018p673-679,
  author   = {A. F. Frangi and S. A. Tsaftaris and J. L. Prince},
  title    = {Simulation and Synthesis in Medical Imaging},
  journal  = {IEEE Transactions on Medical Imaging},
  year     = {2018},
  volume   = {37},
  number   = {3},
  pages    = {673-679},
  month    = {March},
  issn     = {0278-0062},
  doi      = {10.1109/TMI.2018.2800298},
  keywords = {biomedical imaging;medical image processing;cardiology;histopathology;mainstream diagnostic medical imaging modalities;mechanistic image generation;medical image generation;neurosciences;oncology;phenomenological image generation;retinopathy;Computational modeling;Data models;Image generation;Magnetic resonance imaging;Phantoms;Physiology;Simulation;Special issues and sections;Data-driven;hypothesis-driven;machine learning;modeling},
}

@Article{Deng2018p1-9,
  author   = {D. Deng and W. Qu and W. He and Y. Wu and X. Liu and X. Peng},
  title    = {Phase Retrieval for Digital Holographic Microscopy With Defocused Holograms},
  journal  = {IEEE Photonics Journal},
  year     = {2018},
  volume   = {10},
  number   = {1},
  pages    = {1-9},
  month    = {Feb},
  doi      = {10.1109/JPHOT.2017.2782674},
  keywords = {holographic optical elements;image reconstruction;microlenses;optical arrays;4f system;DHM;algebraic equation;defocused holograms;defocusing distance;digital holographic microscopy;electronically tunable lens;microlens array;off-axis hologram;on-axis hologram;phase distributions;phase retrieval;water drop;Image reconstruction;Lenses;Mathematical model;Microscopy;Phase measurement;Proposals;Holography;microscopy;phase measurement},
}

@Article{Robin2015p2854-2861,
  author   = {A. Robin and K. Cawse-Nicholson and A. Mahmood and M. Sears},
  title    = {Estimation of the Intrinsic Dimension of Hyperspectral Images: Comparison of Current Methods},
  journal  = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year     = {2015},
  volume   = {8},
  number   = {6},
  pages    = {2854-2861},
  month    = {June},
  issn     = {1939-1404},
  doi      = {10.1109/JSTARS.2015.2432460},
  keywords = {geophysical image processing;hyperspectral imaging;remote sensing;HSI;ID estimation methods;hyperspectral image;intrinsic dimension estimation;noise approximation methods;noise spectral correlation;Approximation methods;Correlation;Covariance matrices;Eigenvalues and eigenfunctions;Estimation;Hybrid fiber coaxial cables;Noise;Correlated noise;hyperspectral;intrinsic dimension (ID);unmixing},
}

@TechReport{Horn2015,
  author      = {Berthold K.P. Horn},
  title       = {COMPUTATIONAL IMAGING},
  institution = {MIT},
  year        = {2005},
  abstract    = {Research breakthroughs in 2D image analysis/synthesis, coupled with the growth of digital photography as a practical and artistic medium, are creating a convergence between vision, graphics, and photography. A similar trend is occurring with digital video. At the same time, new sensing modalities and faster CPUs have given rise to new computational imaging techniques in many scientific disciplines. Finally, just as CAD/CAM and visualization were the driving markets for computer graphics research in the 1970s and 1980s, and entertainment and gaming are the driving markets today, a driving market 10 years from now will be consumer digital photography and video. In light of these trends, the time is right to hold a symposium on computational photography and video. The area is old enough that we understand what the symposium is about, young enough that we can still argue about it, old enough that its practioners can fill an auditorium, and young enough that they still fit in one.},
  file        = {Horn2015.pdf:Horn2015.pdf:PDF;:Horn2015 - COMPUTATIONAL IMAGING.html:URL},
  keywords    = {rank3},
}

@Article{Deng2017p302-310,
  author        = {Deng, B and Chen, S and Luo, Cheng-Gao and Qin, Yu-liang and Wang, Hongqiang and Li, Xiaoyong},
  title         = {Review of Terahertz coded-aperture imaging},
  year          = {2017},
  volume        = {36},
  pages         = {302-310},
  month         = {06},
  __markedentry = {[junhu:]},
  booktitle     = {Hongwai Yu Haomibo Xuebao/无线轨道角动量通信与雷达目标成像技术研究},
  doi           = {10.11972/j.issn.1001-9014.2017.03.010},
  file          = {Deng2017p302-310.pdf:Deng2017p302-310.pdf:PDF},
  keywords      = {rank5},
}

@Misc{王东进2011p,
  author   = {王东进 and 马远鹏 and 陆广华 and 尹治平 and 何学智 and 孟青泉 and 刘畅畅},
  title    = {微波凝视成像关联方法},
  abstract = {本发明公开了一种微波凝视成像关联方法，包括以下步骤：通过随机辐射场对目标区域物体进行照射，在物体面上形成辐射场分布；通过多通道或单通道进行散射场接收，并对目标区域物体的成像物理过程进行电磁场分析，以得到物体面对应的整个成像区域范围内的时空两维辐射场函数；依据所述时空两维辐射场函数统计时空两维随机辐射场的相关特性；以及根据所述统计特性，对散射场和随机辐射场进行关联处理以反演得到目标区域物体的成像。本发明能够联合散射场和时空两维随机辐射场实现高分辨的目标成像。},
  date     = {2011-01-04},
  number   = {CN201110000698.3},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201110000698.3},
}

@Misc{郭圆月2017p,
  author   = {郭圆月 and 王东进 and 陈卫东 and 夏瑞 and 邓杰 and 李泓旻},
  title    = {微波凝视关联成像对地观测方法},
  abstract = {本发明公开了一种基于静轨卫星和浮空器平台协同的微波凝视关联成像对地观测方法，包括：通过静轨卫星平台中的收发一体式微波凝视关联成像系统，进行一次微波凝视关联成像，得到观测区域大范围低分辨成像结果，并确定重点目标区域；利用基于静轨卫星平台和浮空器平台进行同步接收的广域收发分置与任务协同的二次微波凝视关联成像，最终得到重点目标区域的高分辨成像结果。该方法可以实现全天时、全天候、大范围、低分辨观测普查与小范围热点区域重点目标的高分辨微波凝视成像，适用于军事战场侦查、抗震救灾等对地遥感应用场景。},
  date     = {2017-07-25},
  number   = {CN201710612376.1},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201710612376.1},
}

@Misc{陆广华2015p,
  author   = {陆广华 and 张海龙 and 王东进 and 陈卫东 and 周凌云 and 刘发林 and 陈畅 and 孟青泉 and 罗春生 and 骆皓月 and 朱景涛 and 关剑 and 刘波 and 张健霖},
  title    = {一种动目标微波凝视关联成像的方法},
  abstract = {本发明公开了一种动目标微波凝视关联成像的方法，确定雷达角度分辨率和天线到成像平面之间的距离，并由此计算得到雷达在成像平面处的方位向分辨率；根据计算得到的方位向分辨率，并结合目标的运动速度，以保证运动目标没有跨分辨单元走动为准则计算出所允许的最大时间切片长度；将所述最大时间切片长度内的目标散射回波和演算所得的随机辐射场矩阵进行关联处理，反演和重构出待测区域的目标图像，实现动目标微波凝视关联成像。通过该方法可以解决凝视成像时间过长时运动目标跨分辨单元走动所造成的成像模糊问题，从而实现动目标的微波凝视关联成像。},
  date     = {2015-06-08},
  number   = {CN201510312017.5},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201510312017.5},
}

@Misc{郭圆月2017pa,
  author   = {郭圆月 and 袁博 and 王东进 and 陈卫东 and 邓杰 and 夏瑞 and 李泓旻},
  title    = {低信噪比条件下的微波凝视关联成像方法},
  abstract = {本发明公开了一种低信噪比条件下的微波凝视关联成像方法，包括：微波随机辐射源阵列各个发射单元同步发射长时宽且随机调频脉冲信号；在天线波束覆盖区域内形成随机辐射场，与观测目标相互作用，产生散射回波；由单路接收机同步接收散射回波信号，再进行并行脉冲压缩处理；由阈值门限优化选择的散射回波信号样本，并与相应时刻基于并行脉冲压缩处理的修正随机辐射场，共同构建新型关联成像模型；基于新型关联成像模型，通过关联成像算法，反演得到观测目标图像。该方法能够在低回波信噪比的条件下，实现对目标的高分辨成像。},
  date     = {2017-11-22},
  number   = {CN201711175023.6},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201711175023.6},
}

@Misc{熊文昌2016p,
  author   = {熊文昌 and 王伟伟 and 杨晓超 and 张欣 and 李渝 and 林晨晨},
  title    = {一种基于解析面元的微波关联成像仿真方法},
  abstract = {本发明一种基于解析面元的微波关联成像仿真方法。该方法首先构建了目标3D模型场景，根据观测参数获取相应的目标场景空间信息，并计算目标场景的单次散射系数与多次散射系数，得到观测场景的散射系数分布，然后根据随机天线波束在成像平面中的辐射场计算目标场景的回波信号，最终将辐射场与回波信号进行关联处理得到仿真图像结果。该方法实现了关联成像中随机辐射场条件下的快速模拟过程，给出了面向分布式场景关联成像高效仿真的解决方案，通过该方法能够加深对整个关联成像链路中的成像机理与散射机制的理解，为关联成像雷达系统设计与指标论证提供支撑，同时也能应用于后期关联成像图像评估与图像解译等方面，具有重要的应用价值。},
  date     = {2016-10-27},
  number   = {CN201610964609.X},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201610964609.X},
}

@Misc{王东进2015p,
  author   = {王东进 and 刘波 and 陈卫东 and 郭圆月 and 田超 and 孟青泉},
  title    = {一种便于提取目标轮廓的微波凝视关联成像处理方法},
  abstract = {本发明公开了一种便于提取目标轮廓的微波凝视关联成像处理方法，该方法包括：利用电磁散射理论和雷达参数建立微波凝视关联成像的线性模型；利用总变差正则化方法对所述微波凝视关联成像的线性模型重构，获得微波凝视关联成像的目标重构模型；设定正则化参数进行迭代反演成像，获得稳定高分辨率的微波凝视关联反演图像。通过采用本发明公开的方法能够有效解决随机辐射场矩阵的病态性问题，有利于保持目标的边缘特性，特别适用目标轮廓清晰且与周边环境对比度大的成像场景。},
  date     = {2015-04-09},
  number   = {CN201510166287.X},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201510166287.X},
}

@Misc{郭圆月2014p,
  author   = {郭圆月 and 王东进 and 陈卫东 and 陆广华 and 陈畅 and 田超},
  title    = {一种基于浮空平台密集阵列天线的微波凝视关联成像系统与成像方法},
  abstract = {本发明公开了一种基于浮空平台密集阵列天线的微波凝视关联成像系统与成像方法，所述系统包括浮空平台、密集阵列天线辐射单元、接收单元、随机辐射场演算单元，关联成像单元。在浮空平台下部或两侧搭载密集排布阵列天线，辐射单元辐射非相关、正交随机信号，在目标区域形成微波凝视关联成像所需的时、空两维随机性辐射场，与观测目标相互作用后形成的散射回波信号由接收单元采集接收，而随机辐射场由随机辐射场演算单元预先得到，两者通过关联成像单元进行关联处理，得到目标的反演图像。在浮空成像平台有限空间的条件下，提高微波辐射场的时、空随机特性，实现对目标的高质量、超分辨关联成像。},
  date     = {2014-03-14},
  file     = {郭圆月2014p.pdf:郭圆月2014p.pdf:PDF},
  number   = {CN201410098619.0},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201410098619.0},
}

@Misc{郭圆月2015p,
  author   = {郭圆月 and 王东进 and 陆广华 and 刘发林 and 孟青泉 and 刘波},
  title    = {一种基于强度关联的微波凝视高分辨成像方法},
  abstract = {本发明公开了一种基于强度关联的微波凝视高分辨成像方法，该方法通过联合微波辐射场与所接收散射回波的二阶强度关联，使得原本耦合在一起的目标信息分离开来，从而在凝视情况下重构高分辨目标像；与随机辐射场一阶分布相比，其观测空间不同位置二阶强度分布的时间变化率大幅减小，因此该成像方法可有效消除微波一阶关联成像中的辐射场相位敏感问题，并极大地降低关联成像对硬件系统同步误差的要求，为微波凝视关联高分辨率成像雷达的实际工程应用提供了一条可行的途径。},
  date     = {2015-01-30},
  number   = {CN201510052108.X},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201510052108.X},
}

@Misc{秦玉亮2017p,
  author   = {秦玉亮 and 程永强 and 周小利 and 王宏强 and 范波 and 李彦鹏 and 曹凯程},
  title    = {一种存在阵元幅相误差时的微波关联成像方法},
  abstract = {本发明提供一种存在阵元幅相误差时的微波关联成像方法。技术方案包括以下步骤：第一步：接收雷达回波，设微波关联成像系统包括N个发射阵元和1个接收阵元，发射阵元同时发射一组相互独立的发射信号；第二步：划分网格，对成像区域进行均匀网格划分，网格大小由成像分辨率决定；第三步：推演辐射场，利用迭代方法计算辐射场参考信号；第四步：目标重构，上述迭代结计算目标散射系数矢量；第五步：估计幅相误差；第六步：如果迭代结果满足要求，利用目标散射系数矢量进行成像。本发明在存在幅相误差时可以对目标进行高精度成像。},
  date     = {2017-03-06},
  number   = {CN201710129281.4},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201710129281.4},
}

@Misc{李军2014p,
  author   = {李军 and 李小敏 and 朱圣棋 and 邵自立 and 廖桂生 and 吕利 and 马玉芳},
  title    = {基于雷达旋转发射阵列的微波关联成像方法},
  abstract = {本发明公开了一种基于雷达旋转发射阵列的微波关联成像方法，涉及雷达信息获取与处理技术领域，其步骤为：步骤1，设定雷达旋转发射天线；步骤2，设定雷达的探测面，将该探测面划分成多个探测单元；步骤3，求取时间延迟；步骤4，利用时间延迟求取导向矢量，得到阵列流形矩阵；步骤5，设定回波信号向量；步骤6，构建辐射场向量；步骤7，建立雷达接收的M个脉冲下的原始回波向量与辐射场向量的关联形式；步骤8，在目标函数的约束条件求解目标反射系数向量的目标函数，得到目标反射系数向量；步骤9，得到重排的目标反射系数向量矩阵，即目标的成像矩阵。本发明提高辐射场空时随机性和空间自由度，实现对大场景目标的高分辨率成像。},
  date     = {2014-09-03},
  number   = {CN201410446365.7},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201410446365.7},
}

@Misc{王霄鹏2014p,
  author   = {王霄鹏 and 林子怀 and 刘扬},
  title    = {基于随机天线阵列和微波关联成像原理的高分辨率穿墙成像系统和方法},
  abstract = {本发明公开了一种基于随机天线阵列和微波关联成像原理的高分辨率穿墙成像系统和方法。使用以等间距排列且行列数相等的天线阵列作为发射部分，通过各阵元天线随机的开闭对单一信号源进行随机采样，投射到被成像区域，形成具有类似于赝热光源时空随机波动性和统计独立性的微波场，通过一次探测获得高分辨率成像结果，简化微波关联成像系统的设计和制造难度，降低成本，提高系统的稳定性和抗干扰性能，为微波关联成像的大规模应用和普及创造了条件。成像方法可以获得被墙体遮挡的室内目标和室内区域的高分辨率图像，且对墙体带来的信号衰减作用不敏感，具有强抗噪声性能，提高探测装置的隐蔽性和操作人员的战场生存性，具有巨大的应用价值。},
  date     = {2014-09-29},
  number   = {CN201410512686.2},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201410512686.2},
}

@Misc{程永强2017p,
  author   = {程永强 and 王宏强 and 周小利 and 秦玉亮 and 李彦鹏 and 范波 and 曹凯程},
  title    = {一种随机跳频微波关联成像波形设计方法},
  abstract = {本发明提供一种随机跳频微波关联成像波形设计方法。技术方案包括以下步骤：第一步：划分网格，对成像平面进行均匀网格划分。初始化迭代参数，生成初始跳频编码矩阵；第二步：推演辐射场，计算每次迭代的随机跳频信号和网格中心对应的参考信号，并形成参考信号矩阵；第三步：求解参考矩阵的条件数；第四步：更新跳频编码矩阵；第五步：如果收敛则结束技术方案，否则返回第二步进行迭代。本发明可不断改善辐射场的随机性，最终达到提高成像性能的目的。},
  date     = {2017-03-06},
  number   = {CN201710129279.7},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201710129279.7},
}

@Misc{李军2013p,
  author   = {李军 and 伊孟磊 and 廖桂生 and 董晓飞 and 刘长赞 and 邵自力},
  title    = {基于稀疏阵列的微波关联成像系统与成像方法},
  abstract = {本发明公开了一种基于稀疏阵列的微波关联成像系统与成像方法，主要解决现有技术在雷达天线与目标没有非径向相对运动时成像效果差，分辨率低的问题。该系统包括：发射天线(1)、目标(2)、接收机(3)和信号处理器(5)，发射天线(1)由稀布阵列天线构成，各阵元发射不同的微波编码信号在空间非相干叠加形成微波辐射场，通过该微波辐射场对目标(2)进行照射产生目标散射回波，存储目标(2)表面的微波辐射场(4)，接收机(3)采用单天线、单通道接收目标散射回波；接收机(3)接收到的目标散射回波和预存的微波辐射场(4)通过信号处理器(5)处理，得到目标的成像。本发明能够在雷达天线与目标没有非径向相对运动时，实现对目标的无模糊、超分辨成像，可用于机载前视雷达、球载雷达对目标的超分辨成像。},
  date     = {2013-05-08},
  number   = {CN201310167360.6},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201310167360.6},
}

@Misc{李军2015p,
  author   = {李军 and 郑煜 and 李小敏 and 廖桂生 and 赵启勇 and 马玉芳},
  title    = {基于辅助阵元的微波关联成像雷达幅相误差校正方法},
  abstract = {本发明的提供一种基于辅助阵元的微波关联成像雷达幅相误差校正方法，以估计微波关联成像雷达的幅相误差，进而通过对幅相误差进行补偿获得较为理想的时空辐射场。包括：步骤1：微波关联成像雷达的发射天线阵列发射多种波形，接收天线阵列接收对应的多种回波数据，对回波数据进行匹配滤波，并顺序排列得到回波数据矩阵；步骤2：对回波数据矩阵中的元素进行分组；步骤3：估计数据协方差矩阵；步骤4：进行目标角度估计，得到目标的方向向量；步骤5：分别对发射天线阵列的幅度误差和相位误差进行估计，得到对应的误差估计值；步骤6，根据发射天线阵列的幅度误差估计值和相位误差估计值，分别对发射天线阵列的幅度和相位进行校正。},
  date     = {2015-06-25},
  number   = {CN201510359715.0},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201510359715.0},
}

@Misc{郭圆月2013p,
  author   = {郭圆月 and 王东进 and 田超 and 何学智},
  title    = {一种基于不同码速随机跳频的微波凝视关联成像装置},
  abstract = {本发明公开一种基于不同码速随机跳频的微波凝视关联成像装置，包括随机辐射单元根据总控单元发送的控制信息生成微波脉冲信号并发射，微波脉冲信号在目标区域形成时空两维随机特性的微波辐射场，目标区域观测目标的散射回波由接收单元接收，关联成像单元将散射回波与微波辐射场进行关联处理得到反演图像观测目标；每个辐射天线发射的微波脉冲信号的脉冲周期和脉冲重复频率相同，微波脉冲信号包括多个随机跳频子脉冲，其频点为带宽范围内随机选择，不同辐射天线发射的微波脉冲信号的随机跳频子脉冲跳频码速不同且跳频图案正交。在低码速发射、低速采集和较低带宽的条件下，从工程上实现了微波凝视关联成像所需的、较为理想的时空两维随机辐射场。},
  date     = {2013-12-30},
  file     = {郭圆月2013p.pdf:郭圆月2013p.pdf:PDF},
  number   = {CN201310743516.0},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201310743516.0},
}

@Misc{王东进2015pa,
  author   = {王东进 and 孟青泉 and 刘发林 and 郭圆月 and 田超 and 刘波},
  title    = {一种微波凝视关联成像随机辐射阵元空间排布的优化方法},
  abstract = {本发明公开了一种微波凝视关联成像随机辐射阵元空间排布的优化方法，该方法包括：获取随机辐射源阵面面积、阵元的口径与最小间距，以及阵元的数量；以阵元分布熵最大化为准则利用遗传算法进行优化，获得以阵元分布熵的最大排布方式。通过采用本发明公开的方法，能够提高辐射场的随机性，实现高分辨率成像。},
  date     = {2015-02-09},
  number   = {CN201510066895.3},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201510066895.3},
}

@Misc{王东进2015pb,
  author   = {王东进 and 田超 and 郭圆月 and 陈卫东 and 刘波 and 孟青泉},
  title    = {微波凝视关联成像系统中时空随机辐射场的远场测量方法},
  abstract = {本发明公开了一种微波凝视关联成像系统中时空随机辐射场的远场测量方法，其包括：在成像区域中选取M个测量点以及一参考点，在相同的辐照条件下对第一个测量点处的辐射场与参考点处的辐射场进行同步连续的无扰测量及记录；在不改变辐射系统构型与激励信号的情况下，更换下一个测量点，并对该测量点处的辐射场与参考点处的辐射场进行同步连续的无扰测量及记录，直到遍历所有测量点；以参考点处记录的辐射场变化为时间维匹配基准，将所有测量点处的记录的辐射场在时间维对齐；提取不同时间片段测量点处的辐射场分布，获得辐射场随时间与空间两维变化的信息。该方法能够准确测量辐射场时间维和空间维的变化，可用于辐射场标定或者关联成像。},
  date     = {2015-02-09},
  number   = {CN201510067466.8},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201510067466.8},
}

@Misc{王东进2015pc,
  author   = {王东进 and 孟青泉 and 郭圆月 and 陆广华 and 刘波 and 田超},
  title    = {微波凝视关联成像系统的随机辐射阵元排布定量表征方法},
  abstract = {本发明公开了一种微波凝视关联成像系统的随机辐射阵元排布定量表征方法，该方法通过阵元相对位置矢量的模长与相位在取值范围内分布的均匀性来描述阵元排布随机性；由于辐射阵元的空间排布越随机，阵元分布熵越大，可以有效对阵元空间排布的随机性进行定量表征，并且以阵元分布熵最大为准则，采用优化算法可得到最优的阵元空间排布，进而实现高分辨率成像。},
  date     = {2015-02-09},
  number   = {CN201510066892.X},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201510066892.X},
}

@Misc{王东进2011pa,
  author   = {王东进 and 徐浩 and 陈卫东 and 周凌云 and 杨予昊 and 周海飞},
  title    = {微波凝视成像的方法},
  abstract = {本发明实施例提出了一种基于时、空两维随机辐射场和关联处理的微波凝视成像方法，包括：特殊要求天线口面场对波束覆盖的目标区域进行随机辐射，形成具备时、空两维随机分布特征的辐射场要求同时满足时间维和空间维的非相关特性；辐射场与被探测目标相互作用后，由接收机接收回波散射场信号通过接收散射场与已知辐射场的关联成像处理，提取出待测区域的目标空间信息分布，实现微波凝视成像。本发明提出的上述方案，通过时、空两维辐射场的关联微波凝视成像，克服了传统实孔径雷达空间分辨率取决天线孔径的缺陷，能实现高分辨的微波凝视成像。},
  date     = {2011-01-04},
  number   = {CN201110000699.8},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=patent&id=CN201110000699.8},
}

@PhdThesis{罗春生2016p,
  author   = {罗春生},
  title    = {运动目标微波关联稀疏成像技术研究},
  school   = {中国科学技术大学},
  year     = {2016},
  abstract = {基于时空两维随机辐射场的微波关联成像利用随机辐射源在成像区域内形成时空两维随机的辐射场，经随机辐射场与目标的相互作用，得到包含目标信息的不同时刻回波，通过随机辐射场与观测回波的关联处理和信息融合，获得目标的高分辨率雷达像。
　　本文在微波关联成像体制下，以非合作运动目标为研究对象，利用目标的空间稀疏性，引入压缩感知理论，对目标进行速度估计，并对辐射场演算进行运动补偿，最后通过精确的辐射场与目标回波的关联处理，得到非合作运动稀疏目标的高分辨率雷达成像。
　　首先，本文对运动目标的微波关联成像进行建模，并对高速运动目标进行了合理的近似。由于在建模过程中对成像场景进行了网格划分，不可避免地带来网格偏差问题，因此本文分析了网格偏差对成像结果和目标速度估计的影响，并利用网格偏差的特点，提出了一种网格偏差的校正方法，通过仿真实验证实该算法对网格偏差校正的有效性。
　　其次，研究了匀速目标的微波关联稀疏成像方法，分析了目标运动对微波关联成像的影响。为了消除目标运动带来的影响，本文提供了两种思路:1）对运动目标进行速度估计，对辐射场矩阵进行速度补偿后，关联处理得到目标像。2）目标速度估计和成像交替迭代，通过交替迭代更新反演结果和目标速度，最终得到目标估计速度和目标像。通过仿真实验证实了两种思路的可行性，并验证了所提方法能够精确地估计出运动目标的速度信息。
　　最后，在匀速目标的微波关联稀疏成像的研究基础上，对高速运动目标进行了合理的近似，得到高速目标的微波关联成像模型。针对高速运动目标的微波关联成像问题，文中提出两种解决思路:1）对目标的运动状态进行大量的统计，通过某种准则或者适应值，在已知的目标初速度和加速度范围内进行快速搜索，最终在该矩阵中选取合适的观测矩阵来进行成像。2）对目标速度和加速度信息进行交替估计求解。通过仿真实验验证了所提高速运动目标成像方法对目标运动参数估计的准确性。},
  file     = {罗春生2016p.pdf:罗春生2016p.pdf:PDF},
  keywords = {微波关联成像 运动目标 压缩感知 速度估计 网格失配 空间稀疏性 高分辨率雷达},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=Y3020502},
}

@PhdThesis{张海龙2015p,
  author   = {张海龙},
  title    = {动目标微波凝视关联成像中稀疏重构技术研究},
  school   = {中国科学技术大学},
  year     = {2015},
  abstract = {为了更好地从回波中提取出目标信息，提高雷达成像分辨率是最主要的途径之一。基于时空两维随机辐射场的微波凝视关联成像方法能够在方位向上获得超越孔径衍射极限的分辨率，动目标微波凝视关联成像是一种新的获取动目标超分辨特性的成像方法，但是静止目标的关联处理方法不适用于运动目标。在地基雷达的空中凝视照射区域，运动目标往往具有稀疏分布特性，本文正是利用该稀疏先验信息，重点开展以微波凝视关联成像理论为基础的运动目标稀疏重构技术研究。
　　论文首先分析了目标运动对微波凝视关联成像的影响。在静止目标成像模型的基础上，从成像物理过程出发，建立了动目标微波凝视关联成像模型，并结合目标稀疏分布特性，将正交匹配追踪(Orthogonal Matching Pursuit，OMP)、稀疏贝叶斯学习(Sparse Bayesian Learning，SBL)和欠定系统局域解法(FocalUnderdetermined System Solver，FOCUSS)等经典的稀疏重构算法应用于动目标微波凝视关联成像系统，仿真分析了目标运动对经典稀疏重构算法在微波凝视关联成像中的应用所带来的影响。
　　其次，研究了动目标微波凝视关联稀疏成像算法。在动目标的成像场景中，若不考虑目标运动的影响将导致经典的稀疏重构算法失效，为此，论文提出了两种动目标微波凝视关联稀疏成像算法:(1)针对随机跳频体制，利用发射信号随机跳变的特点进行速度预估计，对辐射场矩阵进行运动补偿，然后关联处理得到目标像;(2)从贝叶斯最大后验角度出发，对经典SBL算法进行修改，迭代估计得到动目标像以及运动速度，并仿真验证了所提算法可同时获得精确的速度估计值和高分辨率图像。
　　最后，研究了动目标微波凝视关联成像中的网格失配（Off-Grid）问题。在将压缩感知理论应用于微波凝视关联成像时，无论网格划分的如何细致，都会存在网格失配问题。针对该问题，本文提出了两种解决方法:(1)在随机跳频体制下，先由其速度预估计方法进行运动补偿，再利用网格点位置和网格偏差具有相同稀疏结构的特性，对经典OMP算法进行修改，校正网格失配偏差;(2)将动目标成像问题转化为连续参数估计问题，利用目标稀疏先验信息，设计优化函数，直接求解散射点位置，避免了经典稀疏重构算法对网格的依赖性，而且仿真结果显示当存在Off-Grid误差时，该方法获得了较好的稀疏反演结果。},
  file     = {张海龙2015p.pdf:张海龙2015p.pdf:PDF},
  keywords = {运动目标 微波凝视关联成像 稀疏重构 压缩感知},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=Y2807262},
}

@PhdThesis{马远鹏2013p,
  author   = {马远鹏},
  title    = {基于时空两维随机辐射场的微波凝视关联成像初探},
  school   = {中国科学技术大学},
  year     = {2013},
  abstract = {在本论文中，微波凝视成像指的是在雷达平台与目标相对静止不动的情况下，通过雷达辐照得到目标图像的成像方式。传统微波凝视成像的分辨率受限于天线孔径，波束覆盖范围内的目标无法得到分辨。因此，本论文探索并提出了一种新的微波凝视成像方法，以获取波束覆盖范围内目标更多的信息，从而实现超越波束分辨限制的目标成像。
　　传统微波凝视成像雷达无法实现波束内分辨的原因可以归结于波束内辐射场分布缺乏差异性的变化，即传统微波凝视成像不同时刻的辐射场空间分布之间保持一致，因此仅能构造单个独立的观测方程获取目标成像信息。而通过时空两维随机辐射场的设计，可以构造多个独立观测方程，即可获得波束内的目标分辨信息。根据该思想，本文提出了微波凝视关联成像的新方法。不同时刻的观测之间存在一定的交叠，需联合已知的时空两维随机辐射场与接收回波进行关联处理，即可实现耦合目标信息的分离提取，从而实现超越传统波束分辨的目标成像。对理想时空两维随机辐射场下的微波凝视关联成像推导、分析以及相应的仿真验证了新方法的可行性。
　　在微波凝视关联成像的研究中，时空两维随机辐射场的空间差异性是关键，它不仅决定了后续关联处理后所能获得的成像分辨率，同时也是微波凝视成像系统中辐射源设计的依据。因此，本论文以此为中心进行了初步的探索。
　　第三章对时空两维随机辐射场空间差异性与口面场统计特性进行了研究，并通过仿真获得了关于不同参数条件下辐射场空间相干度以及辐射场矩阵秩变化关系的初步结论。
　　第四章则推导了微波凝视关联成像中目标信息的提取方法，并从矩阵方程以及成像系统这两个等价的角度，分别定义了微波凝视关联成像的分辨率描述方法。其中，从矩阵方程的角度，利用微波凝视关联成像独立辐射场样本数作为中间量定义了分辨率，而从成像系统角度，则综合考虑到微波凝视关联成像等效点扩散函数的全局特性，提出了新的分辨率定义。
　　第五章针对基于时空两维随机辐射场的微波凝视关联成像存在时间同步精度要求高以及辐射场非稳态变化的难题，探索并提出了一种对时间同步精度要求较低的新的成像方法——基于分时积累的微波凝视关联成像方法。},
  file     = {马远鹏2013p.pdf:马远鹏2013p.pdf:PDF},
  keywords = {微波凝视成像 时空两维随机辐射场 关联处理 整体分辨率 分时积累 雷达平台},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=Y2698010},
}

@PhdThesis{查国峰2016p,
  author   = {查国峰},
  title    = {运动目标微波关联成像技术研究},
  school   = {国防科学技术大学},
  year     = {2016},
  file     = {查国峰2016p.pdf:查国峰2016p.pdf:PDF},
  keywords = {运动目标 微波 关联},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=D01232631},
}

@PhdThesis{杨皓天2016p,
  author   = {杨皓天},
  title    = {基于一维波前调制技术的微波凝视成像体制及成像算法研究},
  school   = {上海交通大学},
  year     = {2016},
  abstract = {合成孔径雷达（SAR）是目前遥感成像领域的主要技术形式，具有全天时、全天候、全球覆盖成像观测能力等优点。但是作为合成虚拟孔径的必须手段，合成孔径雷达体制下的微波成像技术以辐射单元与目标间的可精确测量的相对运动为基本条件，这样的条件使得合成孔径雷达必须要经过一定的运动周期才能覆盖全部探测场景，探测场景面积同重访周期成正比。这一问题使得合成孔径雷达无法满足长期实时监视较大场景的要求。
　　本文提出了一种基于一维波前调制的微波凝视成像体制，这一体制基于现有雷达体制建立，参考了光学的成像理论，在距离向上采用经典的脉冲压缩技术实现高距离向分辨率，而在方位向上借鉴光学中的关联成像思想，通过不相关的一维波前调制技术耦合目标场景散射信息并利用关联处理将散射信息提取，实现高分辨成像。另外，本文对凝视成像算法进行了仿真实验，并对噪声方面的性能分析和成像质量方面的分析进行了研究，针对波前的构造进行了接收天线构造波前的试验。最后，本文提出了一种兼容合成孔径信息的凝视成像处理技术，利用此类技术使得凝视成像系统可以一方面与场景之间存在缓慢的相对运动，依靠合成孔径体制进行低分辨率成像，另一方面可以利用凝视成像技术进一步提升合成孔径体制下获得的图像。},
  file     = {杨皓天2016p.pdf:杨皓天2016p.pdf:PDF},
  keywords = {合成孔径雷达 一维波前调制 成像算法 图像处理},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=D01188377},
}

@PhdThesis{王瑞2015p,
  author   = {王瑞},
  title    = {基于距离向脉冲压缩和方位向波前调制的微波凝视成像体制},
  school   = {上海交通大学},
  year     = {2015},
  abstract = {合成孔径雷达具备全天时、全天候高分辨成像能力，是目前微波成像传感器的主要技术形式。SAR体制的基本原理要求雷达传感器与目标场景之间需要相对运动，这样的条件约束使得SAR体制在探测大场景时重访周期较长，无法实现较大场景的长期实时观测。因此发展相对静止条件下的高时空分辨率成像技术是目前微波成像领域的迫切需求。
　　本文提出了一种基于距离向脉冲压缩和方位向波前调制的微波凝视成像新体制。这一体制的系统架构以现有雷达体制为基础，仅在发射天线前端增加一个波前调制系统，成像处理在距离向上沿用经典的脉冲压缩技术，但在方位向上借鉴光学中的关联成像思想，通过多次不相关的一维波前调制获取目标散射信息，并通过关联处理对散射信息进行提取，从而实现高分辨率成像。本文重点研究了一维波前调制凝视成像体制的系统架构、波前调制技术、成像处理算法以及与SAR体制原理的对比。
　　另外，本文对一维波前调制凝视成像技术进行了仿真验证，并从噪声影响方面和成像质量方面对新凝视成像技术的性能进行了分析。最后，本文提出了一种目标变化检测算法，在场景探测成像的基础上增加了场景变化更新模式，使一维波前调制凝视成像体制更加灵活，扩大了其应用范围。},
  file     = {王瑞2015p.pdf:王瑞2015p.pdf:PDF},
  keywords = {微波凝视成像 波前调制 脉冲压缩 目标变化检测 合成孔径雷达},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=D828958},
}

@PhdThesis{周海飞2011p,
  author   = {周海飞},
  title    = {基于时空随机辐射场的微波凝视成像新方法及其辐射源特性研究},
  school   = {中国科学技术大学},
  year     = {2011},
  abstract = {在选用地球同步轨道卫星、浮空气球平台等相对地面静止的平台对某一区域进行长时间定点凝视高分辨遥感成像时，传统的微波凝视成像，由于横向分辨率受限于天线孔径，分辨率不高，SAR和ISAR能够获得横向上的高分辨，但是二者横向分辨率的获得依赖于雷达与目标的相对运动，限制了其在上述场合的应用。因此探索一种能够实现凝视条件下的高分辨成像方法是十分必要的。
　　
本文研究了一种全新的微波凝视成像方法——基于时空随机辐射场的微波凝视成像方法，进行了高分辨成像的初步探索，在理论上基于时空随机辐射场的微波凝视成像方法获得的空间分辨率可以突破天线孔径的限制，大大提高了分辨率。
　　
首先论文研究了基于时空随机辐射场的微波凝视成像新方法的基本原理。提出时空两维随机分布的辐射场是实现高分辨微波凝视成像的前提；分析了在时空随机辐射场作用下，目标信息提取与解耦的方法：将接收到的散射回波和与之相对应的时空随机辐射场进行强度关联处理。
　　
其次论文详细讨论了基于时空随机辐射场的微波凝视成像的成像过程，建立了从信号产生，辐射，散射，接收到关联处理的成像模型。深入分析了成像过程中信号的相关变化；从两个过程步建立了时空随机辐射场与辐射源的关系的模型：（1）推导了辐射源与时空随机分布口面场的关系，（2）建立了口面场经空间传播后的时空随机辐射场的数学模型；推导了随机辐射场下的散射场表达式；提出了微波强度关联为基于时空随机辐射场下的目标信息提取以及解耦的方法。
　　
最后论文研究了基于时空随机辐射场的微波凝视成像中随机辐射源的特性。详细讨论了辐射源分别辐射理想的随机信号，带限随机信号下时空随机特性；分析了辐射源的空间构型（辐射源的个数和辐射源的口径）对辐射场时空随机性的影响；从整个成像的角度，推导了随机辐射源的参数对基于时空随机辐射场的微波凝视成像的影响。},
  file     = {周海飞2011p.pdf:周海飞2011p.pdf:PDF},
  keywords = {辐射源特性 微波凝视成像 时空随机辐射场 高分辨成像},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=D141529},
}

@PhdThesis{邹静2014p,
  author   = {邹静},
  title    = {基于微波传感器的质量流率测量},
  school   = {武汉理工大学},
  year     = {2014},
  abstract = {固体颗粒的质量流率测量在化工生产、煤炭运输、食品加工等领域发挥着重要的作用。尽管国内外提出不同测量方法，例如直接测量法，电容法，声学传感测量法，层析成像法等，但在提高测量精度，实现实时在线测量等方面仍有欠缺。近些年，微波测量法作为一种新兴的测量方法，由于其强穿透性、响应时间短、系统便于安装且成本较低，越来越得到人们重视。但微波浓度测量中水分含量限制测量精度、大量颗粒的信号的提取和处理等问题仍是需要解决的难题。针对这些问题，本文基于微波浓度-速度测量固体颗粒质量流率的原理，研究了利用微波测速系统测量粒子速度，通过理论推导和仿真改善浓度测量方法，进而解决固体颗粒质量流率测量的核心问题。主要研究工作和结果是：
　　1.对于湿度对浓度测量的影响，形成了从电波传播理论出发，将混合物各相浓度与衰减系数、相移系数相关联进行解决的方案，编制了由幅度衰减和相位偏移得到混合物中各相浓度的C++模拟仿真程序。得到了水浓度固定为0.283时，由微波幅度和相位信息确定固体和气体的体积分数的算法；
　　2.由多普勒效应出发测量固体颗粒的速度，当颗粒数量较多时，测得的多普勒信号具有不同频率成分，无法反映粒子流的运动速度，针对该问题，本文采用快速傅里叶变换对信号进行离散频域化，并对不同频移的信号取幅值求平均，这样可以测量得到大量颗粒运动的平均速度；试验中大量颗粒的平均速度小于理论速度，通过对原有时域信号的频域化，提取出单个颗粒运动对应频移，根据多普勒原理，推导出单个颗粒运动的速度公式。通过对单个颗粒以及多个颗粒分别进行试验，分析影响颗粒运动速度的因素，其中，颗粒之间的相互作用是减小固体颗粒速度的主要因素，其次是管道的碰撞、空气的摩擦。
　　3.在利用微波浓度-速度法测量固体颗粒质量流量的过程中可以得到功率信号，研究分析质量和功率的关系，经过试验测量拟合出线性方程，微波功率-质量法作为一个探索，可以对浓度-速度法测得的质量流率进行验证。在测量过程中，通过试验分析并验证天线的安装位置对测量功率的影响，针对该问题，提出了系统改善措施。},
  keywords = {固体颗粒 质量流率测量 微波传感器},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=D617221},
}

@PhdThesis{卫涛2008p,
  author   = {卫涛},
  title    = {导体目标的超宽带微波成像研究},
  school   = {西南交通大学},
  year     = {2008},
  abstract = {导体目标的超宽带微波成像，在军事、民用中，有着重要的应用价值。在隐身材料广泛采用的情况下，以往的窄带雷达其性能受到非常大的影响。而隐身材料很难做到在宽的频率范围内有着同样好的吸收性能，那么使用超宽带脉冲信号，对目标进行探测，可以有效地实现反隐身。在民用勘测中，使用单站雷达对目标进行探测，有易于安装、机动灵活、便于运输等优点，因此单站成像是微波成像实际实现中非常有价值的方式。
本文中，提出了基于优化算法的超宽带脉冲单站微波成像方法，来实现对导体目标的成像。有以下几个特点：
1．对散射场仅需要后向散射方向的信号，探测雷达仅需一部，单发单收即可进行成像。
2．使用优化方法时，通过对散射信号和探测信号的处理，可以实现对目标尺寸的预估计，并以此来实现对未知目标尺寸的范围设置，使得成像方法进入实用成为可能。
3．对超宽带信号有效频带内各个频率都进行匹配，能够充分利用超宽带信息。并且给出目标正面相对吻合的像。
微波成像是逆散射问题，对于散射与逆散射，可使用相同的积分方程来描述入射场、散射场以及目标形状参数之间的关系。两者存在的一个重要的区别，在已知目标形状等参数时可以直接计算散射场，但无法直接由散射场获得目标形状等信息。当积分方程不进行任何近似时，使用优化算法求解是实现微波成像的有效方法。在使用优化算法进行时域超宽带脉冲单站微波成像时，需要解决如下问题：1．确定单站雷达获得的超宽带信息与目标形状或电磁参数之间的关系。2．目标形状尺寸预计的问题。3．形状描述函数的选择与推广。4．时域算法中网格的尺寸和数目的确定以及成像计算量的控制。5．优化算法有效性和适应性的问题。
论文第2章详细论述了描述散射关系的积分方程的数值离散模型，并讨论了在不同情况下，成像的简化处理。在时域情况下，分析了通过散射场与入射场处理所获得的信息与目标形状之间的关系，建立了与频域下数值离散结果相一致的模型并给出求解时的差异。当目标周长与入射波波长接近时，详细描述了波长与周长之间差异所造成的回波幅度的不同，给出了目标周长的估计方法，以此作为目标形状尺寸估计的基础。综合以上分析，建立了时域超宽带脉冲单站成像的数学模型及计算机实现流程，并且尽可能地减少了不同模块间的关联及耦合，以便于进一步优化。
第3章详细分析了优化算法，讨论了传统优化算法的优缺点及随机优化方法。对随机优化算法，从总体上分析了算法的类型与性能的关系，并对性能测试，给出了明确的标准。在解空间边界越界时，给出不同优化阶段的处理方案。最后测试不同的算法，并按照测试标准，给出详细结果。由于优化算法与待求解问题之间无耦合关系，其结论可以直接引入到成像中。
第4章论述目标尺寸的估计，讨论在二维和三维情况下，目标形状函数的确定。由于目标尺寸参数的范围设置与尺寸估计及形状函数相关，在分析了确定的形状函数情况下，参数的范围可由估计值定量确定。
第5章描述时域成像的实施中最重要的环节，即时域算法中计算区域网格数量和网格尺寸的确定以及优化算法的在成像问题上的改进。在以第4章内容为基础，给出极限情况下计算区域的大小。网格尺寸按照估计尺寸与成像的精度比例关系，可自动确定。由此，确定了数值计算的整个空间。在成像计算中成像精度可按照需求进行调整，入射时间序列按照实际探测信号的带宽和成像精度自动重新生成，成像计算量也同时确定。在无任何目标尺寸先验知识情况下，可以自动进行成像设置并在成像时间和精度之间进行调节。由于形状函数的系数对应着时域算法中的目标轮廓，中间涉及到数值的离散化，通常优化算法实数编码的高精度在此并无意义。并且在工程设计中，不稳定解是需要过滤掉的。因此，设定精度的整数编码优化算法，可以有效地解决这些问题。在不降低成像质量的前提下，可以提高搜索效率。另外，对时域算法，远场计算需要通过封闭面的二次计算获得。本文提出基于信号抽样的快速近—远场转换，该方法与时域算法计算的问题、坐标系无关，是一种通用的快速转换，在多站散射计算、天线设计中的效果明显。
第6章综述全文，实现超宽带脉冲单站微波成像。给出二维和三维的不同精度的成像结果，讨论成像实验。在特殊场合下，快速成像的结果和分析。
综合各环节的改进，超宽带脉冲单站微波成像，可有效地实现目标像的反演。单站微波成像，使成像要求降到最低程度，更利于本方法的实际应用。优化方法的改进，使成像速度更快，在同样的时间内，成像效果更好。},
  file     = {卫涛2008p.pdf:卫涛2008p.pdf:PDF},
  keywords = {导体目标 超宽带 单站微波成像 优化算法 数值离散模型 雷达},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=Y1430658},
}

@PhdThesis{袁玉2014p,
  author   = {袁玉},
  title    = {微波凝视关联成像辐射特性分析及辐射校正方法研究},
  school   = {中国科学院大学},
  year     = {2014},
  abstract = {微波凝视关联成像是强度关联技术在传统实孔径雷达基础上的扩展，通过发射时空两维随机辐射场，并与接收的目标回波强度数据进行关联成像，可解决实孔径雷达成像分辨率受限于天线孔径的问题，提高图像分辨率，同时实现全天时全天候的定点凝视成像。该技术可与现有合成孔径雷达成像技术形成互补，是一项颇具应用潜力的新型对地观测技术。目前，该项技术的研究主要集中在成像机理、数据获取和图像重构方面，对于该新型成像技术应用于对地观测领域所面临的数据辐射特性分析、辐射校正处理方法、遥感应用模式等问题还有待研究。
　　微波凝视关联成像由于其特殊的成像机理，高质量数据的获取取决于成像系统所构建的微波辐射场的随机性以及数据处理中对辐射场的演算精度。成像过程中，微波辐射场的随机性和准确性受到系统参数、观测条件等成像参数的影响;图像重构采用循环迭代算法，难以实现物理意义明确的成像参数对数据辐射特性影响的解析表达，且循环迭代过程计算耗时巨大。本论文针对上述问题开展研究，从成像机理与成像模型出发，结合系统设计参数和实际观测条件，分析影响数据辐射特性和图像质量的关键因素，为高随机微波辐射场的构建以及遥感应用模式提供参考;在上述分析和借鉴传统微波图像辐射校正的基础上，研究数据辐射校正方法，有效提高辐射场演算精度并实现图像辐射校正。论文的主要研究成果如下:
　　(1)在详细阐述微波凝视关联成像机理和模型的基础上，对当前主要的几种关联成像重构算法的重构性能进行了分析，并面向目标探测应用，针对均匀地物背景下的目标，提出了一种提高成像效率的图像重构策略，该策略可在轻度损失图像重构精度的情况下提高数据成像处理速度。
　　(2)基于微波凝视关联成像模型，采用仿真分析方法，从观测矩阵随机性和图像辐射质量两个方面，分析微波凝视关联成像系统的典型系统参数、目标场景参数以及场景误差量对数据辐射特性的影响，总结归纳出可有效改善数据辐射质量的关键因素，以及不同应用场景下的系统设计参数需求。
　　(3)在深入研究微波强度关联成像数据处理方法和分析图像辐射质量的基础上，针对天线方向图指向误差的问题，分析其校正方法;针对实际成像场景中常见的地形起伏影响，给出了相应的数据辐射校正处理方法:针对图像重构前的辐射场校正处理，提出了基于DEM数据的辐射场校正方法，该方法相较于直接采用天线平台高度计算辐射场的方法可以显著提高辐射场的演算精度和图像重构精度;针对重构图像的辐射校正处理，在分析微波凝视关联图像与传统微波图像辐射特性的共性特征的基础上，借鉴传统微波图像辐射校正方法，给出了相应的微波凝视关联图像辐射校正方法。},
  keywords = {微波凝视关联成像 辐射特性 辐射校正 实孔径雷达 遥感应用模式},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=Y2674469},
}

@PhdThesis{赵巍2016p,
  author   = {赵巍},
  title    = {新型光学成像与微波光子探测技术研究},
  school   = {中国科学院大学},
  year     = {2016},
  abstract = {激光成像与探测技术具有高灵敏度、可获得三维信息、方便调制与控制等优点，在远距离目标探测、生物与医学成像、激光雷达等领域具有广泛应用，是当前光电探测技术的重要发展方向之一。随着研究的不断深入，对光学成像技术的探测灵敏度以及复杂环境下获取图像的能力提出了更高的要求。现有的微波探测技术主要基于电子学处理方法，实现实时宽带探测很困难，已经成为微波探测与处理技术进一步发展的主要技术瓶颈。激光成像结合光参量放大技术以及新型的关联探测技术，能够提供多种性能优良的高效高灵敏探测手段。另外，激光作为载波通过电光调制加载微波信号，然后利用光谱烧孔对光载微波信号进行处理，是一种大带宽高分辨率的微波光子探测与处理方法。
　　针对目前光学成像与微波探测技术的发展需求，本论文对高效高灵敏光参量成像技术、新型关联成像技术以及基于光谱烧孔的宽带微波信号光处理技术等进行了探索研究，主要取得了以下创新性成果:
　　1、对高效高灵敏光参量成像技术进行了研究。在物理建模与数值仿真的基础上，首次采用准相位匹配晶体实现增益高达55 dB的光参量图像放大，该方案可实现纳秒级的光学信号增强，促进光参量成像技术的实用化，相关工作己发表在Applied Optics，54，9172(2015)。基于光参量放大的高增益与频率上转换特点，首次采用外接圆模型优化设计空间滤波装置，有效抑制参量荧光背景，使非制冷CCD对近红外信号的探测灵敏度达到每像素7.4个光子，相关工作己发表在物理学报，65，01429(2016)。此外，还进行了相位共轭成像实验探索，成功修正成像过程中散射介质造成的波前畸变。
　　2、研究了新型关联成像技术。完成新型关联成像模拟仿真和实验设计，搭建关联成像实验控制系统，实现自动投影与数据采集。完成Hadamard差分投影、压缩感知等高效率关联成像方案的探索与实验验证。首次提出并实验验证了新型线扫描关联成像方式，该方案可减少计算量一个量级以上，有效提高成像速度（发明专利申请号:201510080990.9）。提出了非线性光学与关联成像结合的高灵敏探测方法，利用光参量变频和大气传输窗口，实现回波信号探测效率的最大化(发明专利申请号:201410323509.X)。
　　3、对基于光谱烧孔的宽带微波信号光处理技术进行了研究。国内首次开展晶体光谱烧孔PDH稳频技术研究，实验证明该技术的有效性，为微波信号光处理系统提供了高稳定窄线宽写入激光源，并为整个系统的小型化和实用化打下基础。研究了基于光纤标准具的高线性度扫频激光系统，提高探测准确性。完成实验系统设计与集成，实现带宽12 GHz、分辨率1.3 MHz的微波信号探测与处理。开展信号畸变修复理论与实验研究，基于布洛赫方程解释信号畸变来源，并采用傅里叶变换域相位修复以及实际信号互相关两种方法，实现对信号畸变的有效修复，将微波信号光处理系统的频率分辨率提升至百kHz量级。设计并提出基于光谱烧孔的宽带连续调谐光载微波滤波装置，具有可灵活调谐、可重构等优点(发明专利申请号:201610262574.5)。},
  keywords = {激光成像 激光探测 关联成像 光谱烧孔 光参量放大},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=Y3106864},
}

@Article{陈建平2012p196--198,
  author   = {陈建平 and 朱文贵 and 张刚},
  title    = {一种微波关联成像的新方法},
  journal  = {海军航空工程学院学报},
  year     = {2012},
  number   = {2},
  pages    = {196--198},
  abstract = {将强度关联量子成像理论引入到雷达成像技术中,提出了一种全新的微波关联成像方法.向目标发射多个幅度、相位可控的单元信号,同时记录各个信号的状态并结合距离信息制作“成像底版”,通过对回波信号和“成像底版”的关联结果进行数理统计后可实现雷达高分辨成像},
  doi      = {10.3969/j.issn.1673-1522.2012.02.018},
  keywords = {微波关联成像 量子成像 强度关联},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=perio&id=hjhkgcxyxb201202018},
}

@Article{邵鹏2014p450--456,
  author   = {邵鹏 and 许然 and 李浩林 and 李亚超 and 邢孟道},
  title    = {Bj(o)rck-Schmidt正交化微波凝视成像方法的研究},
  journal  = {信号处理},
  year     = {2014},
  number   = {4},
  pages    = {450--456},
  abstract = {微波凝视成像作为一种新的成像模式,依靠多个相互独立的天线阵元发射随机信号,在空间形成时空两维随机辐射场,将回波信号形成的辐射场与预存的随机辐射场进行关联处理,从而实现成像.由于电磁信号在空间形成的辐射场具有很强的相关性,因此在进行直接关联处理后,得到图像的副瓣很高.本文针对上述问题提出对预存辐射场分别进行Schmidt及Bj(o)rck-Schmidt正交化处理,减小了邻近单元散射电磁信号的相关性,从而抑制了目标的副瓣,图像的信噪比得到提高,最终获得良好聚焦的图像.文中给出了直接关联处理及Schmidt和Bj(o)rck-Schmidt两种正交化方法性能的对比,同时对预存辐射场正交化处理后的信号特性进行了分析.仿真实验证明了Bj(o)rck-Schmidt正交化方法可以明显降低目标的副瓣,进而说明了该方法的有效性.},
  doi      = {10.3969/j.issn.1003-0530.2014.04.012},
  keywords = {凝视成像 时空两维随机辐射场 Bj(o)rck-Schmidt正交化 关联处理},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=perio&id=xhcl201404012},
}

@Article{田超2016p78--82,
  author   = {田超 and 张健霖 and 陈卫东 and 王东进},
  title    = {微波大功率变脉冲放大器的研制},
  journal  = {现代雷达},
  year     = {2016},
  number   = {12},
  pages    = {78--82},
  abstract = {针对基于悬浮平台微波凝视关联成像系统对变脉冲宽度和大峰值功率的需求,研制了一款X波段变脉冲固态功率放大器.描述该放大器组件中高速漏极调制及保护电路和射频开关的实现方案,分析大功率高速漏极调制电路输出电压脉冲的影响因素,优化调制电路的负载设计,并解决功放输出射频脉冲的包络凹陷问题.经试验验证:研制的功率放大器具有散热性好,稳定工作时间长,最窄脉宽20 ns,上升下降沿均小于3 ns,峰值功率大于40W的射频脉冲输出等特点;其漏极调制电路输出24 V电压脉冲,上升沿小于20 ns,下降沿约60 ns.},
  doi      = {10.16592/j.cnki.1004-7859.2016.12.016},
  keywords = {变脉冲功率放大器 高速漏极调制 射频开关 功率合成},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=perio&id=xdld201612016},
}

@Article{袁玉2015p155--162,
  author   = {袁玉 and 李传荣 and 李晓辉 and 周勇胜 and 马灵玲},
  title    = {微波强度关联图像辐射性能敏感性分析},
  journal  = {遥感技术与应用},
  year     = {2015},
  number   = {1},
  pages    = {155--162},
  abstract = {微波强度关联成像技术通过发射时空两维随机辐射场,并与接收的目标回波强度数据进行关联以实现超天线孔径限制的微波成像.作为一种新型静止雷达成像技术,其不同模型参数对于重构图像辐射性能影响尚不明确.基于微波强度关联成像模型,通过改变模型参数设置,可以获得观测矩阵和重构图像的辐射特性变化趋势,以此分析不同参数设置下图像的辐射性能.分析结果表明:改进天线阵元数目、带宽等模型参数,能有效提高图像辐射性能,尤其是大场景高分辨率的成像区域;增大天线平台高度和网格长度,图像辐射性能有所降低;对于地物均匀的场景,系统设计要求相对较低.分析结果将有助于改善系统设计参数.},
  doi      = {10.11873/j.issn.1004-0323.2015.1.0155},
  keywords = {微波成像 强度关联图像 辐射性能},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=perio&id=ygjsyyy201501021},
}

@PhdThesis{何学智2013p,
  author   = {何学智},
  title    = {微波凝视关联成像的信息处理方法与仿真},
  school   = {中国科学技术大学},
  year     = {2013},
  abstract = {微波凝视关联成像是指利用位于静止平台的雷达对固定区域进行成像，其可以实现对特定区域的连续凝视观测和成像。传统的凝视成像，也即实孔径成像，其角度分辨率受实际天线阵列孔径的约束，限制了其在实际中的应用。因此研究一种既能实现凝视成像，又能突破传统孔径限制的角分辨率的成像系统，对于开拓成像雷达的应用范围具有重要意义。
　　
论文研究一种全新的基于时空两维随机辐射场的微波凝视关联成像体制，通过构造时空两维随机辐射场，继而获得更多的对目标信息的观测样本，最后联合接收回波与演算所得的辐射场做关联处理，实现波束内的目标分辨。论文的第一部分工作首先从物理过程出发，利用时域电磁推导方法，初步建立了微波凝视关联成像的数学模型，对比了分析传统辐射场和时空两维随机辐射场的区别。从成像系统自由度和最优分辨两个角度提出利用辐射场的有效特征值个数来表征辐射场的时空两维随机性。最后根据上述理论分析，提出了一种基于随机跳频实现随机辐射场的方法。
　　
由于辐射场的时空两维随机特性，因此不同于传统的直接成像方式，这里需要联合演算所得的时空两维随机辐射场和接收的散射回波做信息处理才能获得反演的目标图像。另外，复杂的多收发阵列结构也使得许多现有成像算法难以直接应用到微波凝视关联成像的信息处理中。论文的第二部分工作将微波凝视关联成像的信息处理看作一个逆散射问题的求解，提出了基于Gram-Schmidt正交化的信息处理方法，其先对辐射场进行Gram-Schmidt正交化处理，再与回波做相关运算得到反演结果。为了解决有噪情况下反演的不适定性问题，提出了基于TSVD、Tikhonov、Total Variation正则化的信息处理方法，最后通过仿真验证了所提信息处理方法的有效性。
　　
论文第三部分针对稀疏目标场景，研究基于压缩感知(compressive sensing，CS)的信息处理方法。在已知目标的稀疏先验信息情况下，可以利用较少的辐射场样本与相应回波做信息处理就可以获得更高的空间分辨率。论文首先对CS数学模型和微波凝视关联成像模型进行细致的对比分析，指出现有的CS重建算法应用于微波凝视关联成像的信息处理时会存在散射点的Off-Grid误差问题。针对该问题，论文从贪婪迭代求解和Bayesian统计优化两个角度分别提出了基于迭代L(0)范数的最小二乘成像算法和基于迭代最大后验的稀疏自适应校正反演算法，仿真验证了所提算法的有效性。
　　
论文的前三部分工作都是针对凝视成像区域内只有静止目标的情况，第四部分工作则研究运动目标的微波凝视关联成像信息处理方法。首先分析了目标运动对前述信息处理方法性能的影响，针对运动目标场景，提出了基于更新过完备字典的运动成像算法以及基于速度估计的自适应稀疏反演成像算法，并通过仿真验证了所提信息处理方法的有效性，从而进一步完善对微波凝视关联成像信息处理方法的研究。},
  file     = {何学智2013p.pdf:何学智2013p.pdf:PDF},
  keywords = {rank4},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=Y2354180},
}

@PhdThesis{李东泽2014,
  author   = {李东泽},
  title    = {雷达关联成像技术研究},
  school   = {国防科学技术大学},
  year     = {2014},
  abstract = {关联成像是光学领域研究前沿的新兴热点问题之一，能够实现非定域性成像，一经提出就引起了广泛的讨论和研究。本文借鉴光学关联成像的基本原理，基于波前随机调制、波束内超分辨的创新构思，探索一种不依赖、且不受限于目标相对运动的雷达关联成像技术，与 SAR/ISAR成像形成互补，为现有雷达成像技术中对静止\准静止目标以及非合作目标成像等瓶颈问题提供崭新的视角和解决思路。本研究主要内容包括：
　　⑴研究了雷达关联成像的基本理论，对关联成像应用于微波雷达系统的基本结构、信号波形以及波束内超分辨原理等基础问题进行了研究。具体内容包括：分析了热光关联成像原理，从雷达信号处理的角度得出关联成像实现的前提条件；提出采用时空不相关的探测信号实现雷达关联成像的方式。对比了雷达关联成像和热光关联成像的差异，并分析了二者在成像根本原理上的一致性；提出了阵列结构发射正交-时间不相关信号的波前调制方法，推导证明了这种方法能够在探测区域产生具有时空不相关特征的雷达信号覆盖；对比了雷达关联成像与传统 SAR/ISAR以及阵列雷达成像方法，进一步诠释了雷达关联成像不依赖于多普勒频率的波束内超分辨原理。结合数值模拟实验说明了雷达关联成像利用单脉冲回波能够获得静止、合作以及非合作目标的清晰图像。
　　⑵研究了雷达关联成像的空间模糊函数，对名义分辨率、波形设计、阵列构型和抗干扰性能进行了分析。具体内容包括：给出了雷达关联成像的空间模糊函数，推导了名义分辨率的解析表达式，阐明了雷达系统参数与分辨能力之间的关系；给出了零载频假设下的分辨率表示，从而量化评估阵列构型对分辨率的影响；提出了噪声调制波形和混沌调制波形，该种波形能够天然地满足雷达关联成像对正交性和时间不相关性的要求；针对典型的雷达成像干扰形式，分析了雷达关联成像的抗干扰性，理论和实验都说明由于采用了具有时空不相关特征的探测信号，这种成像技术具有突出的抗干扰性能。
　　⑶研究了基于参数化模型的图像重构方法。由于探测信号的空间不相关特征受到微波系统条件限制，热光关联成像中基本的相关重构法并不能在雷达关联成像中获得高分辨率。本章由此提出了参数化模型下的重构方法，对成像方程的构造和重构条件进行了分析，并提出了分步式重构方法以降低计算复杂度。重点分析了在三维区域构造时空不相关探测信号的条件，由此在参数化模型下研究了雷达关联成像的三维图像重构。
　　⑷对模型失配条件下的成像算法展开了研究，具体内容包括：分析了模型失配的产生原因，即目标运动和初始网格失配；研究了模型失配条件下的信号模型，给出了其主要影响因素：目标运动速率、初始网格偏移、探测信号的时空不相关特征以及目标散射系数矢量；分析了现有算法在模型失配条件下的局限性，给出了图像重构的两种方案；针对运动目标引起的模型失配，研究了基于稀疏恢复的图像重构算法。针对高速运动目标给出了基于参数估计和基于多维参数联合估计的成像方案；分析了雷达关联成像中初始网格失配效应的特殊性，并分析了现有网格优化算法的局限性，从而提出了相关-参数化联合重构算法，在保证分辨率的同时有效增强了模型失配条件下算法的稳健性。并且，提出了基于匹配滤波的联合重构算法，将传统雷达成像与关联成像初步结合，在提高算法效率的同时，能够为模型失配条件下的误差估计提供有效先验信息，提高图像重构质量。},
  file     = {李东泽2014.pdf:李东泽2014.pdf:PDF},
  keywords = {rank4},
  url      = {http://g.wanfangdata.com.cn/details/detail.do?_type=degree&id=D675547},
}

@Comment{jabref-meta: databaseType:bibtex;}
